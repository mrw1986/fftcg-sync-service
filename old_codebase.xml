This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-22T22:28:25.887Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
package.json
src/config/firebase.ts
src/global.d.ts
src/index.ts
src/services/cardSync.ts
src/services/priceSync.ts
src/test/testEndpoints.ts
src/test/testImageHandler.ts
src/test/testSync.ts
src/test/validateSync.ts
src/types/express.d.ts
src/types/index.ts
src/types/node.d.ts
src/utils/batch.ts
src/utils/cache.ts
src/utils/error.ts
src/utils/imageCache.ts
src/utils/imageCompressor.ts
src/utils/imageHandler.ts
src/utils/imageValidator.ts
src/utils/logger.ts
src/utils/progress.ts
src/utils/request.ts
src/utils/syncLogger.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     tsconfigRootDir: __dirname,
19:     sourceType: "module",
20:     createDefaultProgram: true,
21:   },
22:   ignorePatterns: [
23:     "/lib/**/*",
24:     "/generated/**/*",
25:     "node_modules/",
26:     "*.cjs",
27:   ],
28:   plugins: [
29:     "@typescript-eslint",
30:     "import",
31:   ],
32:   rules: {
33:     "quotes": ["error", "double"],
34:     "import/no-unresolved": 0,
35:     "indent": ["error", 2],
36:     "max-len": ["error", {"code": 120}],
37:     "@typescript-eslint/no-explicit-any": "off",
38:     "@typescript-eslint/no-unused-vars": ["error", {
39:       "argsIgnorePattern": "^_",
40:       "varsIgnorePattern": "^_",
41:     }],
42:     "valid-jsdoc": 0,
43:     "require-jsdoc": 0,
44:   },
45:   overrides: [
46:     {
47:       files: ["*.js", "*.cjs"],
48:       rules: {
49:         "@typescript-eslint/no-var-requires": "off",
50:       },
51:     },
52:   ],
53: };
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "clean": "rimraf lib",
 5:     "lint": "eslint --ext .js,.ts .",
 6:     "lint:fix": "eslint --ext .js,.ts . --fix",
 7:     "build": "npm run clean && tsc",
 8:     "build:watch": "tsc --watch",
 9:     "serve": "npm run build && firebase emulators:start --only functions,firestore,storage",
10:     "shell": "npm run build && firebase functions:shell",
11:     "start": "npm run shell",
12:     "deploy": "npm run lint:fix && firebase deploy --only functions",
13:     "logs": "firebase functions:log",
14:     "lint:fix:force": "eslint . --ext .js,.ts --fix --config .eslintrc.fix.js",
15:     "test:images": "ts-node src/test/testImageHandler.ts"
16:   },
17:   "engines": {
18:     "node": "18"
19:   },
20:   "main": "lib/index.js",
21:   "dependencies": {
22:     "axios": "^1.7.7",
23:     "firebase-admin": "^12.0.0",
24:     "firebase-functions": "^6.1.0",
25:     "lru-cache": "^7.14.1",
26:     "sharp": "^0.33.1"
27:   },
28:   "devDependencies": {
29:     "@types/express": "^4.17.21",
30:     "@types/node": "^18.19.64",
31:     "@typescript-eslint/eslint-plugin": "^6.0.0",
32:     "@typescript-eslint/parser": "^6.0.0",
33:     "eslint": "^8.0.0",
34:     "eslint-config-google": "^0.14.0",
35:     "eslint-plugin-import": "^2.25.4",
36:     "firebase-functions-test": "^3.1.0",
37:     "rimraf": "^5.0.0",
38:     "typescript": "^4.9.5"
39:   },
40:   "private": true
41: }
</file>

<file path="src/config/firebase.ts">
 1: // functions/src/config/firebase.ts
 2: 
 3: import * as admin from "firebase-admin";
 4: 
 5: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 6: const db = admin.firestore(app);
 7: 
 8: // Enable ignoreUndefinedProperties and other settings
 9: db.settings({
10:   ignoreUndefinedProperties: true,
11:   timestampsInSnapshots: true,
12: });
13: 
14: const storage = admin.storage(app);
15: 
16: export {db, storage};
17: 
18: export const COLLECTION = {
19:   CARDS: "cards",
20:   PRICES: "prices",
21:   SYNC_METADATA: "syncMetadata",
22:   LOGS: "logs",
23:   CARD_HASHES: "cardHashes",
24:   PRICE_HASHES: "priceHashes",
25:   IMAGE_METADATA: "imageMetadata",
26: };
27: 
28: export const STORAGE = {
29:   BUCKETS: {
30:     CARD_IMAGES: "fftcg-sync-service.firebasestorage.app",
31:   },
32:   PATHS: {
33:     IMAGES: "card-images",
34:   },
35: };
36: 
37: export const BASE_URL = "https://tcgcsv.com";
38: export const FFTCG_CATEGORY_ID = "24";
39: 
40: export const runtimeOpts = {
41:   timeoutSeconds: 540,
42:   memory: "1GiB",
43: } as const;
</file>

<file path="src/global.d.ts">
1: // / <reference types="node" />
2: // / <reference types="express" />
</file>

<file path="src/index.ts">
 1: import {onRequest} from "firebase-functions/v2/https";
 2: import {onSchedule} from "firebase-functions/v2/scheduler";
 3: import {Request, Response} from "express";
 4: import {syncCards} from "./services/cardSync";
 5: import {syncPrices} from "./services/priceSync";
 6: import {runtimeOpts} from "./config/firebase";
 7: import {SyncOptions} from "./types";
 8: 
 9: // Scheduled card sync
10: exports.scheduledCardSync = onSchedule({
11:   schedule: "0 21 * * *", // Daily at 21:00 UTC
12:   timeZone: "UTC",
13:   memory: runtimeOpts.memory,
14:   timeoutSeconds: runtimeOpts.timeoutSeconds,
15:   retryCount: 3,
16: }, async (_context) => {
17:   await syncCards();
18: });
19: 
20: // Manual card sync endpoint for testing
21: exports.testCardSync = onRequest({
22:   timeoutSeconds: runtimeOpts.timeoutSeconds,
23:   memory: runtimeOpts.memory,
24:   maxInstances: 1,
25: }, async (req: Request, res: Response) => {
26:   const options: SyncOptions = {
27:     dryRun: true,
28:     limit: req.query.limit ? parseInt(req.query.limit as string) : 5,
29:     groupId: req.query.groupId as string,
30:   };
31: 
32:   const result = await syncCards(options);
33:   res.json(result);
34: });
35: 
36: exports.manualCardSync = onRequest({
37:   timeoutSeconds: runtimeOpts.timeoutSeconds,
38:   memory: runtimeOpts.memory,
39:   maxInstances: 1,
40: }, async (_req: Request, res: Response) => {
41:   const result = await syncCards({dryRun: false});
42:   res.json(result);
43: });
44: 
45: // Scheduled price sync
46: exports.scheduledPriceSync = onSchedule({
47:   schedule: "30 21 * * *", // Daily at 21:30 UTC
48:   timeZone: "UTC",
49:   memory: runtimeOpts.memory,
50:   timeoutSeconds: runtimeOpts.timeoutSeconds,
51:   retryCount: 3,
52: }, async (_context) => {
53:   await syncPrices();
54: });
55: 
56: // Manual price sync endpoint for testing
57: exports.testPriceSync = onRequest({
58:   timeoutSeconds: runtimeOpts.timeoutSeconds,
59:   memory: runtimeOpts.memory,
60:   maxInstances: 1,
61: }, async (req: Request, res: Response) => {
62:   const options: SyncOptions = {
63:     dryRun: req.query.dryRun === "true",
64:     limit: req.query.limit ? parseInt(req.query.limit as string) : undefined,
65:     groupId: req.query.groupId as string,
66:     productId: req.query.productId ? parseInt(req.query.productId as string) : undefined,
67:     showAll: req.query.showAll === "true",
68:   };
69: 
70:   const result = await syncPrices(options);
71:   res.json(result);
72: });
73: 
74: // For manually triggering full price sync
75: exports.manualPriceSync = onRequest({
76:   timeoutSeconds: runtimeOpts.timeoutSeconds,
77:   memory: runtimeOpts.memory,
78:   maxInstances: 1,
79: }, async (_req: Request, res: Response) => {
80:   const result = await syncPrices();
81:   res.json(result);
82: });
83: 
84: // Health check endpoint
85: exports.healthCheck = onRequest({
86:   timeoutSeconds: 10,
87:   memory: "128MiB",
88: }, async (_req: Request, res: Response) => {
89:   res.json({
90:     status: "healthy",
91:     timestamp: new Date().toISOString(),
92:     version: "1.0.0",
93:   });
94: });
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: 
  3: import axios, {AxiosError} from "axios";
  4: import {db, COLLECTION, FFTCG_CATEGORY_ID, BASE_URL} from "../config/firebase";
  5: import {
  6:   CardProduct,
  7:   SyncOptions,
  8:   SyncMetadata,
  9:   GenericError,
 10:   CardPrice,
 11:   BatchProcessingStats,
 12: } from "../types";
 13: import {cardCache, getCacheKey} from "../utils/cache";
 14: import {logError, logInfo, logWarning} from "../utils/logger";
 15: import * as crypto from "crypto";
 16: import {SyncLogger} from "../utils/syncLogger";
 17: import {ImageHandler} from "../utils/imageHandler";
 18: 
 19: const MAX_RETRIES = 3;
 20: const BASE_DELAY = 1000;
 21: 
 22: interface RequestOptions {
 23:   retryCount?: number;
 24:   customDelay?: number;
 25:   metadata?: Record<string, unknown>;
 26: }
 27: 
 28: class SyncError extends Error implements GenericError {
 29:   code?: string;
 30: 
 31:   constructor(
 32:     message: string,
 33:     code?: string,
 34:     public details?: Record<string, unknown>
 35:   ) {
 36:     super(message);
 37:     this.name = "SyncError";
 38:     this.code = code;
 39:   }
 40: 
 41:   toGenericError(): GenericError {
 42:     return {
 43:       name: this.name,
 44:       message: this.message,
 45:       code: this.code,
 46:       stack: this.stack,
 47:     };
 48:   }
 49: }
 50: 
 51: async function makeRequest<T>(
 52:   endpoint: string,
 53:   options: RequestOptions = {}
 54: ): Promise<T> {
 55:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
 56: 
 57:   try {
 58:     await new Promise((resolve) => setTimeout(resolve, customDelay));
 59:     const url = `${BASE_URL}/${endpoint}`;
 60: 
 61:     await logInfo(`Making request to: ${url}`, {
 62:       attempt: retryCount + 1,
 63:       maxRetries: MAX_RETRIES,
 64:       endpoint,
 65:       ...options.metadata,
 66:     });
 67: 
 68:     const response = await axios.get<T>(url, {
 69:       timeout: 30000,
 70:       headers: {
 71:         "Accept": "application/json",
 72:         "User-Agent": "FFTCG-Sync-Service/1.0",
 73:       },
 74:     });
 75: 
 76:     return response.data;
 77:   } catch (error) {
 78:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
 79:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
 80:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
 81:         error: error.message,
 82:         url: `${BASE_URL}/${endpoint}`,
 83:         attempt: retryCount + 1,
 84:         maxRetries: MAX_RETRIES,
 85:       });
 86: 
 87:       return makeRequest<T>(endpoint, {
 88:         ...options,
 89:         retryCount: retryCount + 1,
 90:         customDelay: delay,
 91:       });
 92:     }
 93: 
 94:     throw new SyncError(
 95:       error instanceof Error ? error.message : "Unknown request error",
 96:       error instanceof AxiosError ? error.code : "UNKNOWN_ERROR",
 97:       {endpoint, ...options.metadata}
 98:     );
 99:   }
100: }
101: 
102: function getDataHash(data: any): string {
103:   return crypto.createHash("md5")
104:     .update(JSON.stringify(data, Object.keys(data).sort()))
105:     .digest("hex");
106: }
107: 
108: interface BatchOptions {
109:   batchSize?: number;
110:   onBatchComplete?: (stats: BatchProcessingStats) => Promise<void>;
111: }
112: 
113: async function processBatch<T>(
114:   items: T[],
115:   processor: (batch: T[]) => Promise<void>,
116:   options: BatchOptions = {}
117: ): Promise<void> {
118:   const {
119:     batchSize = 500,
120:     onBatchComplete,
121:   } = options;
122: 
123:   const totalBatches = Math.ceil(items.length / batchSize);
124:   let processedCount = 0;
125: 
126:   for (let i = 0; i < items.length; i += batchSize) {
127:     const batch = items.slice(i, i + batchSize);
128:     await processor(batch);
129:     processedCount += batch.length;
130: 
131:     if (onBatchComplete) {
132:       await onBatchComplete({
133:         total: items.length,
134:         processed: processedCount,
135:         successful: processedCount,
136:         failed: 0,
137:         skipped: 0,
138:       });
139:     }
140: 
141:     await logInfo(
142:       `Processed batch ${Math.floor(i / batchSize) + 1}/${totalBatches} (${processedCount}/${items.length} items)`
143:     );
144: 
145:     if (i + batchSize < items.length) {
146:       await new Promise((resolve) => setTimeout(resolve, 100));
147:     }
148:   }
149: }
150: 
151: async function processGroupProducts(
152:   group: any,
153:   options: SyncOptions,
154:   metadata: SyncMetadata,
155:   existingHashes: Map<string, string>,
156:   imageHandler: ImageHandler,
157:   logger?: SyncLogger
158: ): Promise<number> {
159:   const groupId = group.groupId.toString();
160:   let processedCards = 0;
161: 
162:   try {
163:     const [productsResponse, pricesResponse] = await Promise.all([
164:       makeRequest<{ results: CardProduct[] }>(
165:         `${FFTCG_CATEGORY_ID}/${groupId}/products`,
166:         {metadata: {groupId, groupName: group.name}}
167:       ),
168:       makeRequest<{ results: CardPrice[] }>(
169:         `${FFTCG_CATEGORY_ID}/${groupId}/prices`,
170:         {metadata: {groupId, groupName: group.name}}
171:       ),
172:     ]);
173: 
174:     const products = productsResponse.results;
175:     const prices = pricesResponse.results;
176: 
177:     if (logger) {
178:       await logger.logGroupDetails(groupId, products.length, prices.length);
179:     }
180: 
181:     const groupHash = getDataHash(products);
182:     const existingHash = existingHashes.get(groupId);
183: 
184:     if (logger && options.dryRun) {
185:       for (const product of products) {
186:         if (options.limit && processedCards >= options.limit) break;
187: 
188:         const cardPrices = prices.filter((p) => p.productId === product.productId);
189:         await logger.logCardDetails({
190:           id: product.productId,
191:           name: product.name,
192:           groupId: product.groupId.toString(),
193:           normalPrice: cardPrices.find((p) => p.subTypeName === "Normal")?.midPrice,
194:           foilPrice: cardPrices.find((p) => p.subTypeName === "Foil")?.midPrice,
195:           imageUrl: product.imageUrl,
196:           rawPrices: cardPrices.map((p) => ({
197:             type: p.subTypeName,
198:             price: p.midPrice,
199:             groupId: groupId,
200:           })),
201:         });
202:         processedCards++;
203:       }
204:     }
205: 
206:     if (!options.dryRun && (!existingHash || existingHash !== groupHash)) {
207:       metadata.groupsUpdated++;
208: 
209:       await processBatch(products, async (batch) => {
210:         const writeBatch = db.batch();
211:         const imagePromises: Promise<any>[] = [];
212: 
213:         for (const product of batch) {
214:           if (options.limit && processedCards >= options.limit) break;
215: 
216:           if (!options.skipImages) {
217:             imagePromises.push(
218:               imageHandler.processImage(
219:                 product.imageUrl,
220:                 groupId,
221:                 product.productId
222:               )
223:             );
224:           }
225: 
226:           const cardRef = db.collection(COLLECTION.CARDS)
227:             .doc(product.productId.toString());
228: 
229:           writeBatch.set(cardRef, {
230:             ...product,
231:             lastUpdated: new Date(),
232:             groupHash,
233:           }, {merge: true});
234: 
235:           cardCache.set(getCacheKey("card", product.productId), product);
236:           processedCards++;
237:         }
238: 
239:         if (imagePromises.length > 0) {
240:           const imageResults = await Promise.allSettled(imagePromises);
241: 
242:           imageResults.forEach((result, index) => {
243:             if (result.status === "fulfilled") {
244:               const product = batch[index];
245:               const cardRef = db.collection(COLLECTION.CARDS)
246:                 .doc(product.productId.toString());
247: 
248:               writeBatch.update(cardRef, {
249:                 storageImageUrl: result.value.url,
250:                 imageMetadata: result.value.metadata,
251:               });
252: 
253:               if (result.value.updated) {
254:                 metadata.imagesUpdated = (metadata.imagesUpdated || 0) + 1;
255:               }
256:             }
257:           });
258: 
259:           metadata.imagesProcessed = (metadata.imagesProcessed || 0) + imagePromises.length;
260:         }
261: 
262:         const hashRef = db.collection(COLLECTION.CARD_HASHES)
263:           .doc(groupId);
264:         writeBatch.set(hashRef, {
265:           hash: groupHash,
266:           lastUpdated: new Date(),
267:         });
268: 
269:         await writeBatch.commit();
270:       }, {
271:         batchSize: 100,
272:         onBatchComplete: async (stats) => {
273:           await logInfo("Batch processing progress", stats);
274:         },
275:       });
276: 
277:       await logInfo(`Updated ${processedCards} cards from group ${groupId}`, {
278:         imagesProcessed: metadata.imagesProcessed,
279:         imagesUpdated: metadata.imagesUpdated,
280:       });
281:     } else {
282:       await logInfo(`No updates needed for group ${groupId} (unchanged)`);
283:     }
284: 
285:     metadata.cardCount += products.length;
286:     return processedCards;
287:   } catch (error) {
288:     const syncError = error instanceof Error ?
289:       new SyncError(error.message, "GROUP_PROCESSING_ERROR", {groupId}) :
290:       new SyncError("Unknown group processing error", "UNKNOWN_ERROR", {groupId});
291: 
292:     const errorMessage = `Error processing group ${groupId}: ${syncError.message}`;
293:     metadata.errors.push(errorMessage);
294:     await logError(syncError.toGenericError(), "processGroupProducts");
295:     return processedCards;
296:   }
297: }
298: 
299: export async function syncCards(options: SyncOptions = {}): Promise<SyncMetadata> {
300:   const logger = new SyncLogger({
301:     type: options.dryRun ? "manual" : "scheduled",
302:     limit: options.limit,
303:     dryRun: options.dryRun,
304:     groupId: options.groupId,
305:     batchSize: 25,
306:   });
307: 
308:   const imageHandler = new ImageHandler();
309: 
310:   await logger.start();
311: 
312:   const startTime = Date.now();
313:   const metadata: SyncMetadata = {
314:     lastSync: new Date(),
315:     status: "in_progress",
316:     cardCount: 0,
317:     type: options.dryRun ? "manual" : "scheduled",
318:     groupsProcessed: 0,
319:     groupsUpdated: 0,
320:     errors: [],
321:     imagesProcessed: 0,
322:     imagesUpdated: 0,
323:   };
324: 
325:   try {
326:     const groupsResponse = await makeRequest<{ results: any[] }>(
327:       `${FFTCG_CATEGORY_ID}/groups`,
328:       {metadata: {operation: "fetchGroups"}}
329:     );
330: 
331:     const groups = groupsResponse.results;
332:     await logger.logGroupFound(groups.length);
333: 
334:     let processedCards = 0;
335:     const existingHashes = new Map<string, string>();
336: 
337:     const hashesSnapshot = await db.collection(COLLECTION.CARD_HASHES).get();
338:     hashesSnapshot.forEach((doc) => {
339:       existingHashes.set(doc.id, doc.data().hash);
340:     });
341: 
342:     if (options.dryRun) {
343:       await logger.logManualSyncStart();
344:     }
345: 
346:     for (const group of groups) {
347:       if (options.groupId && group.groupId.toString() !== options.groupId) continue;
348: 
349:       metadata.groupsProcessed++;
350:       const groupProcessedCards = await processGroupProducts(
351:         group,
352:         options,
353:         metadata,
354:         existingHashes,
355:         imageHandler,
356:         logger
357:       );
358: 
359:       processedCards += groupProcessedCards;
360:       if (options.limit && processedCards >= options.limit) break;
361:     }
362: 
363:     metadata.status = metadata.errors.length > 0 ? "completed_with_errors" : "success";
364: 
365:     await logger.logSyncResults({
366:       success: processedCards,
367:       failures: metadata.errors.length,
368:       groupId: options.groupId,
369:       type: options.dryRun ? "Manual" : "Scheduled",
370:       imagesProcessed: metadata.imagesProcessed,
371:       imagesUpdated: metadata.imagesUpdated,
372:     });
373:   } catch (error) {
374:     const syncError = error instanceof Error ?
375:       new SyncError(error.message, "SYNC_MAIN_ERROR") :
376:       new SyncError("Unknown sync error", "UNKNOWN_ERROR");
377: 
378:     metadata.status = "failed";
379:     metadata.errors.push(syncError.message);
380:     await logError(syncError.toGenericError(), "syncCards:main");
381:   }
382: 
383:   metadata.lastSync = new Date();
384:   metadata.duration = Date.now() - startTime;
385: 
386:   if (!options.dryRun) {
387:     await db.collection(COLLECTION.SYNC_METADATA)
388:       .add(metadata);
389:   }
390: 
391:   await logger.finish();
392:   return metadata;
393: }
</file>

<file path="src/services/priceSync.ts">
  1: import axios, {AxiosError} from "axios";
  2: import {db, COLLECTION, FFTCG_CATEGORY_ID, BASE_URL} from "../config/firebase";
  3: import {
  4:   CardPrice,
  5:   SyncOptions,
  6:   SyncMetadata,
  7:   PriceData,
  8:   GenericError,
  9:   CardProduct,
 10: } from "../types";
 11: import {logError, logInfo, logWarning} from "../utils/logger";
 12: import {SyncLogger} from "../utils/syncLogger";
 13: import * as crypto from "crypto";
 14: 
 15: const MAX_RETRIES = 3;
 16: const BASE_DELAY = 1000;
 17: 
 18: interface RequestOptions {
 19:   retryCount?: number;
 20:   customDelay?: number;
 21:   metadata?: Record<string, unknown>;
 22: }
 23: 
 24: class SyncError extends Error implements GenericError {
 25:   code?: string;
 26: 
 27:   constructor(
 28:     message: string,
 29:     code?: string,
 30:     public details?: Record<string, unknown>
 31:   ) {
 32:     super(message);
 33:     this.name = "SyncError";
 34:     this.code = code;
 35:   }
 36: 
 37:   toGenericError(): GenericError {
 38:     return {
 39:       name: this.name,
 40:       message: this.message,
 41:       code: this.code,
 42:       stack: this.stack,
 43:     };
 44:   }
 45: }
 46: 
 47: async function makeRequest<T>(
 48:   endpoint: string,
 49:   options: RequestOptions = {}
 50: ): Promise<T> {
 51:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
 52: 
 53:   try {
 54:     await new Promise((resolve) => setTimeout(resolve, customDelay));
 55:     const url = `${BASE_URL}/${endpoint}`;
 56: 
 57:     await logInfo(`Making request to: ${url}`, {
 58:       attempt: retryCount + 1,
 59:       maxRetries: MAX_RETRIES,
 60:       endpoint,
 61:       ...options.metadata,
 62:     });
 63: 
 64:     const response = await axios.get<T>(url, {
 65:       timeout: 30000,
 66:       headers: {
 67:         "Accept": "application/json",
 68:         "User-Agent": "FFTCG-Sync-Service/1.0",
 69:       },
 70:     });
 71: 
 72:     return response.data;
 73:   } catch (error) {
 74:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
 75:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
 76:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
 77:         error: error.message,
 78:         url: `${BASE_URL}/${endpoint}`,
 79:         attempt: retryCount + 1,
 80:         maxRetries: MAX_RETRIES,
 81:       });
 82: 
 83:       return makeRequest<T>(endpoint, {
 84:         ...options,
 85:         retryCount: retryCount + 1,
 86:         customDelay: delay,
 87:       });
 88:     }
 89: 
 90:     throw new SyncError(
 91:       error instanceof Error ? error.message : "Unknown request error",
 92:       error instanceof AxiosError ? error.code : "UNKNOWN_ERROR",
 93:       {endpoint, ...options.metadata}
 94:     );
 95:   }
 96: }
 97: 
 98: function getDataHash(data: any): string {
 99:   return crypto.createHash("md5")
100:     .update(JSON.stringify(data, Object.keys(data).sort()))
101:     .digest("hex");
102: }
103: 
104: function processPrices(prices: CardPrice[]): Record<number, PriceData> {
105:   const priceMap: Record<number, PriceData> = {};
106: 
107:   prices.forEach((price) => {
108:     if (!priceMap[price.productId]) {
109:       priceMap[price.productId] = {
110:         lastUpdated: new Date(),
111:       };
112:     }
113: 
114:     if (price.subTypeName === "Normal") {
115:       priceMap[price.productId].normal = price;
116:     } else {
117:       priceMap[price.productId].foil = price;
118:     }
119:   });
120: 
121:   return priceMap;
122: }
123: 
124: async function processBatch<T>(
125:   items: T[],
126:   processor: (batch: T[]) => Promise<void>,
127:   batchSize: number = 500
128: ): Promise<void> {
129:   for (let i = 0; i < items.length; i += batchSize) {
130:     const batch = items.slice(i, i + batchSize);
131:     await processor(batch);
132:     await new Promise((resolve) => setTimeout(resolve, 100));
133:   }
134: }
135: 
136: async function processGroupPrices(
137:   group: any,
138:   options: SyncOptions,
139:   metadata: SyncMetadata,
140:   logger?: SyncLogger
141: ): Promise<void> {
142:   const groupId = group.groupId.toString();
143: 
144:   try {
145:     // If specific productId is provided, first verify the card exists
146:     if (options.productId) {
147:       const card = await db.collection(COLLECTION.CARDS)
148:         .doc(options.productId.toString())
149:         .get();
150: 
151:       if (!card.exists) {
152:         throw new SyncError(
153:           `Card with ID ${options.productId} not found`,
154:           "CARD_NOT_FOUND",
155:           {productId: options.productId}
156:         );
157:       }
158: 
159:       const cardData = card.data();
160:       if (cardData?.groupId?.toString() !== groupId) {
161:         return; // Skip this group if it doesn't contain the requested product
162:       }
163:     }
164: 
165:     // Fetch both products and prices for detailed logging
166:     const [productsResponse, pricesResponse] = await Promise.all([
167:       makeRequest<{ results: CardProduct[] }>(
168:         `${FFTCG_CATEGORY_ID}/${groupId}/products`,
169:         {metadata: {groupId, groupName: group.name}}
170:       ),
171:       makeRequest<{ results: CardPrice[] }>(
172:         `${FFTCG_CATEGORY_ID}/${groupId}/prices`,
173:         {metadata: {groupId, groupName: group.name}}
174:       ),
175:     ]);
176: 
177:     const products = productsResponse.results;
178:     let prices = pricesResponse.results;
179: 
180:     if (logger) {
181:       await logger.logGroupDetails(groupId, products.length, prices.length);
182:     }
183: 
184:     // Filter for specific product if requested
185:     if (options.productId) {
186:       prices = prices.filter((p) => p.productId === options.productId);
187:       if (prices.length === 0) {
188:         throw new SyncError(
189:           `No prices found for product ${options.productId}`,
190:           "NO_PRICES_FOUND",
191:           {productId: options.productId}
192:         );
193:       }
194:     }
195: 
196:     const priceHash = getDataHash(prices);
197:     const hashDoc = await db.collection(COLLECTION.PRICE_HASHES)
198:       .doc(groupId)
199:       .get();
200: 
201:     const existingHash = hashDoc.exists ? hashDoc.data()?.hash : null;
202: 
203:     // Log detailed price information if logger is available
204:     if (logger && options.dryRun) {
205:       for (const product of products) {
206:         const cardPrices = prices.filter((p) => p.productId === product.productId);
207:         if (cardPrices.length > 0) {
208:           await logger.logCardDetails({
209:             id: product.productId,
210:             name: product.name,
211:             groupId: groupId,
212:             normalPrice: cardPrices.find((p) => p.subTypeName === "Normal")?.midPrice,
213:             foilPrice: cardPrices.find((p) => p.subTypeName === "Foil")?.midPrice,
214:             rawPrices: cardPrices.map((p) => ({
215:               type: p.subTypeName,
216:               price: p.midPrice,
217:               groupId: groupId,
218:             })),
219:           });
220:         }
221:       }
222:     }
223: 
224:     if (!options.dryRun && (!existingHash || existingHash !== priceHash)) {
225:       metadata.groupsUpdated++;
226:       const processedPrices = processPrices(prices);
227: 
228:       await processBatch(
229:         Object.entries(processedPrices),
230:         async (batch) => {
231:           const writeBatch = db.batch();
232: 
233:           for (const [productId, priceData] of batch) {
234:             if (options.limit && metadata.cardCount >= options.limit) break;
235: 
236:             const priceRef = db.collection(COLLECTION.PRICES)
237:               .doc(productId);
238:             writeBatch.set(priceRef, priceData, {merge: true});
239: 
240:             metadata.cardCount++;
241:           }
242: 
243:           // Update hash
244:           const hashRef = db.collection(COLLECTION.PRICE_HASHES)
245:             .doc(groupId);
246:           writeBatch.set(hashRef, {
247:             hash: priceHash,
248:             lastUpdated: new Date(),
249:           });
250: 
251:           await writeBatch.commit();
252:         }
253:       );
254: 
255:       await logInfo(`Updated ${metadata.cardCount} prices from group ${groupId}`);
256:     } else {
257:       await logInfo(`No updates needed for group ${groupId} (unchanged)`);
258:     }
259:   } catch (error) {
260:     const syncError = error instanceof SyncError ? error :
261:       error instanceof Error ?
262:         new SyncError(error.message, "GROUP_PROCESSING_ERROR", {groupId}) :
263:         new SyncError("Unknown group processing error", "UNKNOWN_ERROR", {groupId});
264: 
265:     const errorMessage = `Error processing group ${groupId}: ${syncError.message}`;
266:     metadata.errors.push(errorMessage);
267:     await logError(syncError.toGenericError(), "processGroupPrices");
268:   }
269: }
270: 
271: export async function syncPrices(options: SyncOptions = {}): Promise<SyncMetadata> {
272:   const logger = new SyncLogger({
273:     type: options.dryRun ? "both" : "scheduled",
274:     limit: options.limit,
275:     dryRun: options.dryRun,
276:     groupId: options.groupId,
277:     batchSize: 25,
278:   });
279: 
280:   await logger.start();
281: 
282:   const startTime = Date.now();
283:   const metadata: SyncMetadata = {
284:     lastSync: new Date(),
285:     status: "in_progress",
286:     cardCount: 0,
287:     type: options.dryRun ? "manual" : "scheduled",
288:     groupsProcessed: 0,
289:     groupsUpdated: 0,
290:     errors: [],
291:   };
292: 
293:   try {
294:     const groupsResponse = await makeRequest<{ results: any[] }>(
295:       `${FFTCG_CATEGORY_ID}/groups`,
296:       {metadata: {operation: "fetchGroups"}}
297:     );
298: 
299:     const groups = groupsResponse.results;
300:     await logger.logGroupFound(groups.length);
301: 
302:     if (options.dryRun) {
303:       await logger.logManualSyncStart();
304:     }
305: 
306:     if (options.groupId) {
307:       const group = groups.find((g) => g.groupId.toString() === options.groupId);
308:       if (!group) {
309:         throw new SyncError(
310:           `Group ${options.groupId} not found`,
311:           "GROUP_NOT_FOUND",
312:           {groupId: options.groupId}
313:         );
314:       }
315:       groups.length = 0;
316:       groups.push(group);
317:     }
318: 
319:     for (const group of groups) {
320:       metadata.groupsProcessed++;
321:       await processGroupPrices(group, options, metadata, logger);
322: 
323:       if (options.limit && metadata.cardCount >= options.limit) break;
324:     }
325: 
326:     metadata.status = metadata.errors.length > 0 ? "completed_with_errors" : "success";
327: 
328:     await logger.logSyncResults({
329:       success: metadata.cardCount,
330:       failures: metadata.errors.length,
331:       groupId: options.groupId,
332:       type: options.dryRun ? "Manual" : "Scheduled",
333:     });
334:   } catch (error) {
335:     const syncError = error instanceof SyncError ? error :
336:       error instanceof Error ?
337:         new SyncError(error.message, "SYNC_MAIN_ERROR") :
338:         new SyncError("Unknown sync error", "UNKNOWN_ERROR");
339: 
340:     metadata.status = "failed";
341:     metadata.errors.push(syncError.message);
342:     await logError(syncError.toGenericError(), "syncPrices:main");
343:   }
344: 
345:   metadata.lastSync = new Date();
346:   metadata.duration = Date.now() - startTime;
347: 
348:   if (!options.dryRun) {
349:     await db.collection(COLLECTION.SYNC_METADATA)
350:       .add(metadata);
351:   }
352: 
353:   await logger.finish();
354:   return metadata;
355: }
</file>

<file path="src/test/testEndpoints.ts">
 1: import axios, {isAxiosError} from "axios";
 2: 
 3: const FIREBASE_REGION = "us-central1";
 4: const PROJECT_ID = "fftcg-sync-service";
 5: const BASE_URL = `https://${FIREBASE_REGION}-${PROJECT_ID}.cloudfunctions.net`;
 6: 
 7: interface SyncResponse {
 8:   lastSync: Date;
 9:   status: string;
10:   cardCount: number;
11:   type: string;
12:   groupsProcessed: number;
13:   groupsUpdated: number;
14:   errors: string[];
15:   duration?: number;
16: }
17: 
18: async function testEndpoints() {
19:   try {
20:     // Test card sync
21:     console.log("\nTesting card sync...");
22:     const cardResponse = await axios.get<SyncResponse>(`${BASE_URL}/testCardSync`, {
23:       params: {
24:         limit: 5,
25:         dryRun: true,
26:         groupId: "23783", // Example group ID
27:       },
28:     });
29:     console.log("Card sync results:", JSON.stringify(cardResponse.data, null, 2));
30: 
31:     // Test price sync
32:     console.log("\nTesting price sync...");
33:     const priceResponse = await axios.get<SyncResponse>(`${BASE_URL}/testPriceSync`, {
34:       params: {
35:         groupId: "23783", // Example group ID
36:         dryRun: true,
37:         limit: 5,
38:       },
39:     });
40:     console.log("Price sync results:", JSON.stringify(priceResponse.data, null, 2));
41: 
42:     // Test health check
43:     console.log("\nTesting health check...");
44:     const healthResponse = await axios.get(`${BASE_URL}/healthCheck`);
45:     console.log("Health check response:", JSON.stringify(healthResponse.data, null, 2));
46:   } catch (error) {
47:     if (isAxiosError(error)) {
48:       console.error("Test failed:", error.response?.data || error.message);
49:       console.error("Status:", error.response?.status);
50:       console.error("Headers:", error.response?.headers);
51:     } else {
52:       console.error("Test failed:", error);
53:     }
54:     process.exit(1);
55:   }
56: }
57: 
58: // Execute tests
59: console.log("Starting endpoint tests...");
60: testEndpoints().then(() => {
61:   console.log("All tests completed!");
62: }).catch(console.error);
</file>

<file path="src/test/testImageHandler.ts">
  1: // src/test/testImageHandler.ts
  2: 
  3: import {ImageHandler} from "../utils/imageHandler";
  4: import {ImageCompressor} from "../utils/imageCompressor";
  5: 
  6: const TEST_CASES = [
  7:   {
  8:     imageUrl: "https://tcgplayer-cdn.tcgplayer.com/product/477236_200w.jpg",
  9:     groupId: "23783",
 10:     productId: 477236,
 11:     description: "FFVII Boss Deck",
 12:   },
 13: ];
 14: 
 15: async function testImageProcessing() {
 16:   try {
 17:     console.log("\n=== Testing Image Handler ===");
 18:     const imageHandler = new ImageHandler();
 19: 
 20:     for (const testCase of TEST_CASES) {
 21:       console.log(`\nProcessing: ${testCase.description}`);
 22:       console.log("URLs:");
 23:       console.log(`- Original: ${testCase.imageUrl}`);
 24:       console.log(`- High-res: ${testCase.imageUrl.replace("_200w.jpg", "_400w.jpg")}`);
 25: 
 26:       // Test compression independently
 27:       console.log("\n=== Compression Test ===");
 28:       const response = await fetch(testCase.imageUrl);
 29:       const buffer = Buffer.from(await response.arrayBuffer());
 30: 
 31:       const [lowResResult, highResResult] = await Promise.all([
 32:         ImageCompressor.compress(buffer, false),
 33:         ImageCompressor.compress(buffer, true),
 34:       ]);
 35: 
 36:       console.log("Low-res:");
 37:       console.log(`- Original: ${(buffer.length / 1024).toFixed(2)}KB`);
 38:       console.log(`- Compressed: ${(lowResResult.buffer.length / 1024).toFixed(2)}KB`);
 39:       console.log(`- Reduction: ${((1 - lowResResult.buffer.length / buffer.length) * 100).toFixed(1)}%`);
 40:       console.log(`- Dimensions: ${lowResResult.info.width}x${lowResResult.info.height}`);
 41: 
 42:       console.log("\nHigh-res:");
 43:       console.log(`- Original: ${(buffer.length / 1024).toFixed(2)}KB`);
 44:       console.log(`- Compressed: ${(highResResult.buffer.length / 1024).toFixed(2)}KB`);
 45:       console.log(`- Reduction: ${((1 - highResResult.buffer.length / buffer.length) * 100).toFixed(1)}%`);
 46:       console.log(`- Dimensions: ${highResResult.info.width}x${highResResult.info.height}`);
 47: 
 48:       // Test full image processing
 49:       console.log("\n=== Full Processing Test ===");
 50:       const result = await imageHandler.processImage(
 51:         testCase.imageUrl,
 52:         testCase.groupId,
 53:         testCase.productId
 54:       );
 55: 
 56:       console.log("Processing Results:");
 57:       console.log(`- Status: ${result.updated ? "Updated" : "Unchanged"}`);
 58:       console.log(`- Original Size: ${(result.metadata.originalSize || 0) / 1024}KB`);
 59:       console.log(`- High-res Size: ${(result.metadata.highResSize || 0) / 1024}KB`);
 60:       console.log(`- Content Type: ${result.metadata.contentType}`);
 61:       console.log(`- Last Updated: ${result.metadata.updated.toISOString()}`);
 62: 
 63:       // Test cache behavior
 64:       console.log("\n=== Cache Test ===");
 65:       const cachedResult = await imageHandler.processImage(
 66:         testCase.imageUrl,
 67:         testCase.groupId,
 68:         testCase.productId
 69:       );
 70: 
 71:       console.log("Cache Results:");
 72:       console.log(`- Cached: ${!cachedResult.updated}`);
 73:       console.log(`- Original Size: ${(cachedResult.metadata.originalSize || 0) / 1024}KB`);
 74:       console.log(`- High-res Size: ${(cachedResult.metadata.highResSize || 0) / 1024}KB`);
 75:     }
 76: 
 77:     // Test cleanup
 78:     console.log("\n=== Cleanup Test (Dry Run) ===");
 79:     await imageHandler.cleanup(true);
 80: 
 81:     // Test error handling
 82:     console.log("\n=== Error Handling Test ===");
 83:     const invalidResult = await imageHandler.processImage(
 84:       "https://invalid-url.com/image.jpg",
 85:       TEST_CASES[0].groupId,
 86:       TEST_CASES[0].productId
 87:     );
 88: 
 89:     console.log("Error Results:");
 90:     console.log(`- Fallback: ${invalidResult.originalUrl === "https://invalid-url.com/image.jpg"}`);
 91:     console.log(`- Updated: ${invalidResult.updated}`);
 92:     console.log("- Error Handled: true");
 93:   } catch (error) {
 94:     console.error("\nTest failed:", error);
 95:     process.exit(1);
 96:   }
 97: }
 98: 
 99: async function runTests() {
100:   console.log("Starting Image Handler tests...");
101: 
102:   try {
103:     await testImageProcessing();
104:     console.log("\nAll Image Handler tests completed successfully!");
105:   } catch (error) {
106:     console.error("\nTests failed:", error);
107:     process.exit(1);
108:   }
109: }
110: 
111: // Execute the tests
112: runTests().catch(console.error);
</file>

<file path="src/test/testSync.ts">
 1: import axios, {isAxiosError} from "axios";
 2: import {SyncOptions, SyncMetadata} from "../types";
 3: 
 4: const PROJECT_ID = "fftcg-sync-service";
 5: const REGION = "us-central1";
 6: const BASE_URL = `https://${REGION}-${PROJECT_ID}.cloudfunctions.net`;
 7: 
 8: async function runSyncTest(
 9:   endpoint: string,
10:   options: SyncOptions,
11:   description: string
12: ): Promise<SyncMetadata> {
13:   console.log(`\nTesting ${description}...`);
14: 
15:   try {
16:     const response = await axios.get<SyncMetadata>(`${BASE_URL}/${endpoint}`, {
17:       params: options,
18:     });
19:     return response.data;
20:   } catch (error) {
21:     if (isAxiosError(error)) {
22:       console.error(`${description} failed:`, error.response?.data || error.message);
23:       throw error;
24:     }
25:     throw error;
26:   }
27: }
28: 
29: async function testSync() {
30:   try {
31:     // Test manual card sync
32:     const cardSyncResult = await runSyncTest("testCardSync", {
33:       limit: 5,
34:       dryRun: true,
35:       groupId: "23783",
36:     }, "Card Sync");
37: 
38:     console.log("Card Sync Results:", JSON.stringify(cardSyncResult, null, 2));
39: 
40:     // Test manual price sync
41:     const priceSyncResult = await runSyncTest("testPriceSync", {
42:       groupId: "23783",
43:       dryRun: true,
44:       limit: 5,
45:     }, "Price Sync");
46: 
47:     console.log("Price Sync Results:", JSON.stringify(priceSyncResult, null, 2));
48: 
49:     // Test full sync (if needed)
50:     if (process.env.TEST_FULL_SYNC === "true") {
51:       console.log("\nTesting full sync...");
52: 
53:       const fullSyncResult = await runSyncTest("manualCardSync", {
54:         dryRun: true,
55:       }, "Full Sync");
56: 
57:       console.log("Full Sync Results:", JSON.stringify(fullSyncResult, null, 2));
58:     }
59:   } catch (error) {
60:     console.error("Test failed:", error);
61:     process.exit(1);
62:   }
63: }
64: 
65: // Execute the test
66: console.log("Starting sync tests...");
67: testSync().then(() => {
68:   console.log("\nAll sync tests completed successfully!");
69: }).catch(console.error);
</file>

<file path="src/test/validateSync.ts">
  1: import * as admin from "firebase-admin";
  2: import {Timestamp} from "firebase-admin/firestore";
  3: import {ServiceAccount} from "firebase-admin";
  4: import * as path from "path";
  5: import * as fs from "fs/promises";
  6: import {COLLECTION} from "../config/firebase";
  7: 
  8: interface ValidationResult {
  9:   collection: string;
 10:   documentsChecked: number;
 11:   documentsValid: number;
 12:   errors: string[];
 13:   details?: Record<string, any>;
 14: }
 15: 
 16: interface ValidationOptions {
 17:   limit?: number;
 18:   verbose?: boolean;
 19:   groupId?: string;
 20: }
 21: 
 22: async function initializeFirebase(): Promise<FirebaseFirestore.Firestore> {
 23:   try {
 24:     const serviceAccountPath = path.resolve(__dirname, "../../../service_account_key.json");
 25:     const serviceAccountData = await fs.readFile(serviceAccountPath, "utf8");
 26:     const serviceAccount = JSON.parse(serviceAccountData) as ServiceAccount;
 27: 
 28:     if (!admin.apps.length) {
 29:       admin.initializeApp({
 30:         credential: admin.credential.cert(serviceAccount),
 31:       });
 32:     }
 33: 
 34:     return admin.firestore();
 35:   } catch (error) {
 36:     console.error("Failed to initialize Firebase:", error);
 37:     throw error;
 38:   }
 39: }
 40: 
 41: async function validateCollection(
 42:   db: FirebaseFirestore.Firestore,
 43:   collectionName: string,
 44:   validator: (doc: FirebaseFirestore.DocumentData) => boolean,
 45:   options: ValidationOptions = {}
 46: ): Promise<ValidationResult> {
 47:   const result: ValidationResult = {
 48:     collection: collectionName,
 49:     documentsChecked: 0,
 50:     documentsValid: 0,
 51:     errors: [],
 52:     details: {},
 53:   };
 54: 
 55:   try {
 56:     let query = db.collection(collectionName)
 57:       .orderBy("lastUpdated", "desc");
 58: 
 59:     if (options.limit) {
 60:       query = query.limit(options.limit);
 61:     }
 62: 
 63:     if (options.groupId && (collectionName === COLLECTION.CARDS || collectionName === COLLECTION.PRICES)) {
 64:       query = query.where("groupId", "==", options.groupId);
 65:     }
 66: 
 67:     const snapshot = await query.get();
 68:     result.documentsChecked = snapshot.size;
 69: 
 70:     snapshot.forEach((doc) => {
 71:       const data = doc.data();
 72:       try {
 73:         if (validator(data)) {
 74:           result.documentsValid++;
 75:           if (options.verbose) {
 76:             result.details![doc.id] = data;
 77:           }
 78:         } else {
 79:           result.errors.push(`Document ${doc.id} failed validation`);
 80:         }
 81:       } catch (error) {
 82:         result.errors.push(`Error validating ${doc.id}: ${error}`);
 83:       }
 84:     });
 85:   } catch (error) {
 86:     result.errors.push(`Error accessing collection: ${error}`);
 87:   }
 88: 
 89:   return result;
 90: }
 91: 
 92: async function validateSync(options: ValidationOptions = {}) {
 93:   console.log("Starting sync validation...");
 94:   console.log("Options:", JSON.stringify(options, null, 2));
 95: 
 96:   try {
 97:     const db = await initializeFirebase();
 98: 
 99:     // Validate cards
100:     const cardResult = await validateCollection(db, COLLECTION.CARDS, (data) => {
101:       return (
102:         typeof data.productId === "number" &&
103:         typeof data.name === "string" &&
104:         typeof data.lastUpdated === "object" &&
105:         data.lastUpdated instanceof Timestamp
106:       );
107:     }, options);
108: 
109:     // Validate prices
110:     const priceResult = await validateCollection(db, COLLECTION.PRICES, (data) => {
111:       return (
112:         data.lastUpdated instanceof Timestamp &&
113:         (!data.normal || typeof data.normal.midPrice === "number") &&
114:         (!data.foil || typeof data.foil.midPrice === "number")
115:       );
116:     }, options);
117: 
118:     // Validate sync metadata
119:     const metadataResult = await validateCollection(db, COLLECTION.SYNC_METADATA, (data) => {
120:       return (
121:         data.lastSync instanceof Timestamp &&
122:         typeof data.status === "string" &&
123:         typeof data.cardCount === "number" &&
124:         Array.isArray(data.errors)
125:       );
126:     }, options);
127: 
128:     // Print results
129:     console.log("\nValidation Results:");
130:     [cardResult, priceResult, metadataResult].forEach((result) => {
131:       console.log(`\n${result.collection}:`);
132:       console.log(`Documents Checked: ${result.documentsChecked}`);
133:       console.log(`Valid Documents: ${result.documentsValid}`);
134:       if (result.errors.length > 0) {
135:         console.log("Errors:");
136:         result.errors.forEach((error) => console.log(`- ${error}`));
137:       }
138:       if (options.verbose && result.details) {
139:         console.log("\nDetails:");
140:         console.log(JSON.stringify(result.details, null, 2));
141:       }
142:     });
143:   } catch (error) {
144:     console.error("Validation failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Execute validation with command line arguments
150: const args = process.argv.slice(2);
151: const options: ValidationOptions = {
152:   limit: args.includes("--limit") ? parseInt(args[args.indexOf("--limit") + 1]) : undefined,
153:   verbose: args.includes("--verbose"),
154:   groupId: args.includes("--groupId") ? args[args.indexOf("--groupId") + 1] : undefined,
155: };
156: 
157: validateSync(options).then(() => {
158:   console.log("\nValidation completed!");
159: }).catch(console.error);
</file>

<file path="src/types/express.d.ts">
1: // / <reference types="express" />
2: import * as express from "express";
3: export = express;
</file>

<file path="src/types/index.ts">
  1: // functions/src/types/index.ts
  2: 
  3: export interface GenericError extends Error {
  4:   code?: string;
  5:   message: string;
  6:   stack?: string;
  7: }
  8: 
  9: export interface CardProduct {
 10:   productId: number;
 11:   name: string;
 12:   cleanName: string;
 13:   imageUrl: string;
 14:   storageImageUrl?: string; // Added for Firebase Storage URL
 15:   categoryId: number;
 16:   groupId: number;
 17:   url: string;
 18:   modifiedOn: string;
 19:   imageCount: number;
 20:   imageMetadata?: ImageMetadata; // Added for image metadata
 21:   extendedData: Array<{
 22:     name: string;
 23:     displayName: string;
 24:     value: string;
 25:   }>;
 26: }
 27: 
 28: export interface CardPrice {
 29:   productId: number;
 30:   lowPrice: number;
 31:   midPrice: number;
 32:   highPrice: number;
 33:   marketPrice: number | null;
 34:   directLowPrice: number | null;
 35:   subTypeName: "Normal" | "Foil";
 36: }
 37: 
 38: export interface SyncOptions {
 39:   dryRun?: boolean;
 40:   limit?: number;
 41:   groupId?: string;
 42:   productId?: number;
 43:   showAll?: boolean;
 44:   skipImages?: boolean; // Added to optionally skip image processing
 45: }
 46: 
 47: export interface SyncMetadata {
 48:   lastSync: Date;
 49:   status: "in_progress" | "success" | "failed" | "completed_with_errors";
 50:   cardCount: number;
 51:   type: "manual" | "scheduled";
 52:   groupsProcessed: number;
 53:   groupsUpdated: number;
 54:   errors: string[];
 55:   duration?: number;
 56:   imagesProcessed?: number; // Added for image tracking
 57:   imagesUpdated?: number; // Added for image tracking
 58: }
 59: 
 60: export type CacheType = "card" | "price" | "image";
 61: 
 62: export interface PriceData {
 63:   normal?: CardPrice;
 64:   foil?: CardPrice;
 65:   lastUpdated: Date;
 66: }
 67: 
 68: // New interfaces for image handling
 69: export interface ImageMetadata {
 70:   contentType: string;
 71:   size: number;
 72:   updated: Date;
 73:   hash: string;
 74:   originalUrl: string;
 75:   highResUrl: string;
 76:   groupId?: string;
 77:   productId?: number;
 78:   lastUpdated?: Date;
 79:   originalSize?: number;
 80:   highResSize?: number;
 81: }
 82: export interface ImageProcessingResult {
 83:   url: string;
 84:   metadata: ImageMetadata;
 85:   updated: boolean;
 86: }
 87: 
 88: export interface ImageSyncStats {
 89:   processed: number;
 90:   updated: number;
 91:   failed: number;
 92:   skipped: number;
 93: }
 94: 
 95: // Update existing interfaces
 96: export interface LogData {
 97:   imageMetadata?: ImageMetadata;
 98:   imageSyncStats?: ImageSyncStats;
 99:   [key: string]: any;
100: }
101: 
102: // Cache interfaces
103: export interface CacheOptions {
104:   max: number;
105:   ttl: number;
106: }
107: 
108: export interface CacheEntry<T> {
109:   data: T;
110:   timestamp: number;
111:   expires: number;
112: }
113: 
114: // Error types
115: export interface ImageProcessingError extends GenericError {
116:   productId: number;
117:   groupId: string;
118:   originalUrl: string;
119:   type: "download" | "upload" | "metadata" | "unknown";
120: }
121: 
122: export type GenericObject = Record<string, any>;
123: 
124: // Batch processing types
125: export interface BatchProcessingStats {
126:   total: number;
127:   processed: number;
128:   successful: number;
129:   failed: number;
130:   skipped: number;
131: }
132: 
133: export interface BatchOptions {
134:   batchSize?: number;
135:   delayBetweenBatches?: number;
136:   onBatchComplete?: (stats: BatchProcessingStats) => Promise<void>;
137:   skipImages?: boolean;
138:   retryFailedImages?: boolean;
139: }
140: 
141: // Enhanced logging types for image processing
142: export interface ImageLogEntry {
143:   timestamp: Date;
144:   level: "INFO" | "WARNING" | "ERROR";
145:   message: string;
146:   context?: string;
147:   metadata?: ImageMetadata;
148:   error?: ImageProcessingError;
149:   stats?: ImageSyncStats;
150: }
151: 
152: // Storage types
153: export interface StoragePaths {
154:   original: string;
155:   processed: string;
156: }
157: 
158: export interface StorageOptions {
159:   contentType: string;
160:   metadata?: Record<string, string>;
161:   cacheControl?: string;
162: }
163: 
164: // Progress tracking for image processing
165: export interface ImageProcessingProgress {
166:   total: number;
167:   current: number;
168:   updated: number;
169:   failed: number;
170:   startTime: number;
171:   estimatedTimeRemaining?: number;
172: }
173: 
174: export interface ImageValidationError {
175:   code: "FILE_TOO_LARGE" | "INVALID_FORMAT" | "VALIDATION_ERROR";
176:   message: string;
177: }
</file>

<file path="src/types/node.d.ts">
1: // / <reference types="node" />
</file>

<file path="src/utils/batch.ts">
 1: import {logInfo} from "./logger";
 2: 
 3: export interface BatchProcessorOptions {
 4:   batchSize?: number;
 5:   delayBetweenBatches?: number;
 6:   onBatchComplete?: (processedCount: number, totalCount: number) => Promise<void>;
 7: }
 8: 
 9: export async function processBatch<TItem>(
10:   items: TItem[],
11:   processor: (batch: TItem[]) => Promise<void>,
12:   options: BatchProcessorOptions = {}
13: ): Promise<void> {
14:   const {
15:     batchSize = 500,
16:     delayBetweenBatches = 100,
17:     onBatchComplete,
18:   } = options;
19: 
20:   const totalBatches = Math.ceil(items.length / batchSize);
21:   let processedCount = 0;
22: 
23:   for (let i = 0; i < items.length; i += batchSize) {
24:     const batch = items.slice(i, i + batchSize);
25:     const batchNumber = Math.floor(i / batchSize) + 1;
26: 
27:     await processor(batch);
28:     processedCount += batch.length;
29: 
30:     if (onBatchComplete) {
31:       await onBatchComplete(processedCount, items.length);
32:     }
33: 
34:     logInfo(`Processed batch ${batchNumber}/${totalBatches} (${processedCount}/${items.length} items)`);
35: 
36:     if (i + batchSize < items.length) {
37:       await new Promise((resolve) => setTimeout(resolve, delayBetweenBatches));
38:     }
39:   }
40: }
</file>

<file path="src/utils/cache.ts">
 1: import LRUCache from "lru-cache";
 2: import {CacheType, CardProduct} from "../types";
 3: 
 4: const options = {
 5:   max: 500,
 6:   ttl: 1000 * 60 * 60, // 1 hour
 7: };
 8: 
 9: export const cardCache = new LRUCache<string, CardProduct>(options);
10: 
11: export const getCacheKey = (type: CacheType, id: number): string => {
12:   return `${type}:${id}`;
13: };
</file>

<file path="src/utils/error.ts">
 1: import {db, COLLECTION} from "../config/firebase";
 2: import {logError} from "./logger";
 3: 
 4: export interface ErrorReport {
 5:   timestamp: Date;
 6:   context: string;
 7:   error: string;
 8:   stackTrace?: string;
 9:   metadata?: Record<string, unknown>;
10:   severity: "ERROR" | "WARNING" | "CRITICAL";
11: }
12: 
13: export class DetailedError extends Error {
14:   constructor(
15:     message: string,
16:     public context: string,
17:     public metadata?: Record<string, unknown>,
18:     public severity: "ERROR" | "WARNING" | "CRITICAL" = "ERROR"
19:   ) {
20:     super(message);
21:     this.name = "DetailedError";
22:   }
23: }
24: 
25: export async function logDetailedError(
26:   error: Error,
27:   context: string,
28:   metadata?: Record<string, unknown>,
29:   severity: "ERROR" | "WARNING" | "CRITICAL" = "ERROR"
30: ): Promise<void> {
31:   const report: ErrorReport = {
32:     timestamp: new Date(),
33:     context,
34:     error: error.message,
35:     stackTrace: error.stack,
36:     metadata,
37:     severity,
38:   };
39: 
40:   // Log to Firestore
41:   await db.collection(COLLECTION.LOGS)
42:     .add(report);
43: 
44:   // Log using existing logger
45:   await logError(error, context);
46: }
</file>

<file path="src/utils/imageCache.ts">
  1: import LRUCache from "lru-cache";
  2: import {ImageMetadata} from "../types";
  3: import {logInfo} from "./logger";
  4: 
  5: interface CacheStats {
  6:   hits: number;
  7:   misses: number;
  8:   totalRequests: number;
  9: }
 10: 
 11: export class ImageCache {
 12:   private metadataCache: LRUCache<string, ImageMetadata>;
 13:   private bufferCache: LRUCache<string, Buffer>;
 14:   private existsCache: LRUCache<string, boolean>;
 15:   private stats: CacheStats = {
 16:     hits: 0,
 17:     misses: 0,
 18:     totalRequests: 0,
 19:   };
 20: 
 21:   constructor() {
 22:     this.metadataCache = new LRUCache<string, ImageMetadata>({
 23:       max: 1000,
 24:       ttl: 1000 * 60 * 60, // 1 hour
 25:       updateAgeOnGet: true,
 26:     });
 27: 
 28:     this.bufferCache = new LRUCache<string, Buffer>({
 29:       max: 100,
 30:       ttl: 1000 * 60 * 5, // 5 minutes
 31:       updateAgeOnGet: true,
 32:       maxSize: 50 * 1024 * 1024, // 50MB max cache size
 33:       sizeCalculation: (buffer) => buffer.length,
 34:     });
 35: 
 36:     this.existsCache = new LRUCache<string, boolean>({
 37:       max: 1000,
 38:       ttl: 1000 * 60 * 60, // 1 hour
 39:       updateAgeOnGet: true,
 40:     });
 41:   }
 42: 
 43:   getMetadataCacheKey(groupId: string, productId: number, isHighRes: boolean): string {
 44:     return `metadata:${groupId}:${productId}:${isHighRes ? "high" : "original"}`;
 45:   }
 46: 
 47:   getBufferCacheKey(url: string): string {
 48:     return `buffer:${url}`;
 49:   }
 50: 
 51:   getExistsCacheKey(groupId: string, productId: number, isHighRes: boolean): string {
 52:     return `exists:${groupId}:${productId}:${isHighRes ? "high" : "original"}`;
 53:   }
 54: 
 55:   async getMetadata(key: string): Promise<ImageMetadata | undefined> {
 56:     this.stats.totalRequests++;
 57:     const value = this.metadataCache.get(key);
 58:     if (value) {
 59:       this.stats.hits++;
 60:       await logInfo("Cache hit: metadata", {
 61:         key,
 62:         timestamp: new Date().toISOString(),
 63:       });
 64:     } else {
 65:       this.stats.misses++;
 66:     }
 67:     return value;
 68:   }
 69: 
 70:   async getBuffer(key: string): Promise<Buffer | undefined> {
 71:     this.stats.totalRequests++;
 72:     const value = this.bufferCache.get(key);
 73:     if (value) {
 74:       this.stats.hits++;
 75:       await logInfo("Cache hit: buffer", {
 76:         key,
 77:         size: value.length,
 78:         timestamp: new Date().toISOString(),
 79:       });
 80:     } else {
 81:       this.stats.misses++;
 82:     }
 83:     return value;
 84:   }
 85: 
 86:   getExists(key: string): boolean | undefined {
 87:     this.stats.totalRequests++;
 88:     const value = this.existsCache.get(key);
 89:     if (value !== undefined) {
 90:       this.stats.hits++;
 91:     } else {
 92:       this.stats.misses++;
 93:     }
 94:     return value;
 95:   }
 96: 
 97:   setMetadata(key: string, value: ImageMetadata): void {
 98:     this.metadataCache.set(key, value);
 99:   }
100: 
101:   setBuffer(key: string, value: Buffer): void {
102:     this.bufferCache.set(key, value);
103:   }
104: 
105:   setExists(key: string, value: boolean): void {
106:     this.existsCache.set(key, value);
107:   }
108: 
109:   clear(): void {
110:     this.metadataCache.clear();
111:     this.bufferCache.clear();
112:     this.existsCache.clear();
113:     this.stats = {
114:       hits: 0,
115:       misses: 0,
116:       totalRequests: 0,
117:     };
118:   }
119: 
120:   getStats(): CacheStats {
121:     return {...this.stats};
122:   }
123: }
124: 
125: export const imageCache = new ImageCache();
</file>

<file path="src/utils/imageCompressor.ts">
 1: // src/utils/imageCompressor.ts
 2: 
 3: import sharp from "sharp";
 4: import {logInfo} from "./logger";
 5: 
 6: export interface CompressionResult {
 7:   buffer: Buffer;
 8:   info: {
 9:     width: number;
10:     height: number;
11:     size: number;
12:     format: string;
13:     quality: number;
14:   };
15: }
16: 
17: export class ImageCompressor {
18:   private static readonly QUALITY = {
19:     HIGH_RES: 90,
20:     LOW_RES: 85,
21:   };
22: 
23:   private static readonly DIMENSIONS = {
24:     HIGH_RES: 400,
25:     LOW_RES: 200,
26:   };
27: 
28:   static async compress(
29:     buffer: Buffer,
30:     isHighRes: boolean = false
31:   ): Promise<CompressionResult> {
32:     try {
33:       const quality = isHighRes ? this.QUALITY.HIGH_RES : this.QUALITY.LOW_RES;
34:       const targetWidth = isHighRes ? this.DIMENSIONS.HIGH_RES : this.DIMENSIONS.LOW_RES;
35: 
36:       const originalInfo = await sharp(buffer).metadata();
37:       const originalSize = buffer.length;
38: 
39:       const image = sharp(buffer).jpeg({
40:         quality,
41:         progressive: true,
42:         mozjpeg: true,
43:       });
44: 
45:       if (originalInfo.width && originalInfo.width > targetWidth) {
46:         image.resize(targetWidth, null, {
47:           fit: "inside",
48:           withoutEnlargement: true,
49:         });
50:       }
51: 
52:       const compressedBuffer = await image.toBuffer();
53:       const compressedInfo = await sharp(compressedBuffer).metadata();
54: 
55:       await logInfo("Image compression complete", {
56:         originalSize,
57:         compressedSize: compressedBuffer.length,
58:         dimensions: `${compressedInfo.width}x${compressedInfo.height}`,
59:         quality,
60:         timestamp: new Date().toISOString(),
61:       });
62: 
63:       return {
64:         buffer: compressedBuffer,
65:         info: {
66:           width: compressedInfo.width || 0,
67:           height: compressedInfo.height || 0,
68:           size: compressedBuffer.length,
69:           format: compressedInfo.format || "jpeg",
70:           quality,
71:         },
72:       };
73:     } catch (error) {
74:       throw new Error(
75:         `Image compression failed: ${error instanceof Error ? error.message : "Unknown error"}`
76:       );
77:     }
78:   }
79: 
80:   static async isCompressible(buffer: Buffer): Promise<boolean> {
81:     try {
82:       const info = await sharp(buffer).metadata();
83:       return info.format === "jpeg" || info.format === "jpg";
84:     } catch {
85:       return false;
86:     }
87:   }
88: }
</file>

<file path="src/utils/imageHandler.ts">
  1: import axios, {AxiosError} from "axios";
  2: import {storage, STORAGE, COLLECTION, db} from "../config/firebase";
  3: import {logError, logInfo, logWarning} from "./logger";
  4: import * as crypto from "crypto";
  5: import {GenericError, ImageMetadata} from "../types";
  6: import {ImageValidator} from "./imageValidator";
  7: import {imageCache} from "./imageCache";
  8: import {ImageCompressor} from "./imageCompressor";
  9: 
 10: interface ImageProcessingResult {
 11:   originalUrl: string;
 12:   highResUrl: string;
 13:   metadata: ImageMetadata;
 14:   updated: boolean;
 15: }
 16: 
 17: export class ImageHandler {
 18:   private bucket = storage.bucket(STORAGE.BUCKETS.CARD_IMAGES);
 19: 
 20:   private getHighResUrl(imageUrl: string): string {
 21:     return imageUrl.replace(/_200w\.jpg$/, "_400w.jpg");
 22:   }
 23: 
 24:   private getStoragePath(groupId: string, productId: number, isHighRes: boolean = false): string {
 25:     const suffix = isHighRes ? "_400w" : "_200w";
 26:     return `${STORAGE.PATHS.IMAGES}/${groupId}/${productId}${suffix}.jpg`;
 27:   }
 28: 
 29:   private async getImageHash(imageBuffer: Buffer): Promise<string> {
 30:     return crypto.createHash("md5").update(imageBuffer).digest("hex");
 31:   }
 32: 
 33:   private async compressImage(buffer: Buffer, isHighRes: boolean): Promise<Buffer> {
 34:     try {
 35:       const result = await ImageCompressor.compress(buffer, isHighRes);
 36:       await logInfo("Image compression successful", {
 37:         originalSize: buffer.length,
 38:         compressedSize: result.buffer.length,
 39:         quality: result.info.quality,
 40:         dimensions: `${result.info.width}x${result.info.height}`,
 41:         timestamp: new Date().toISOString(),
 42:       });
 43:       return result.buffer;
 44:     } catch (error) {
 45:       await logWarning("Image compression skipped", {
 46:         error: error instanceof Error ? error.message : "Unknown error",
 47:         timestamp: new Date().toISOString(),
 48:       });
 49:       return buffer;
 50:     }
 51:   }
 52: 
 53:   private async downloadImage(url: string): Promise<Buffer> {
 54:     const cacheKey = imageCache.getBufferCacheKey(url);
 55:     const cachedBuffer = await imageCache.getBuffer(cacheKey);
 56: 
 57:     if (cachedBuffer) {
 58:       return cachedBuffer;
 59:     }
 60: 
 61:     try {
 62:       await logInfo("Attempting to download image", {
 63:         url,
 64:         timestamp: new Date().toISOString(),
 65:       });
 66: 
 67:       const response = await axios.get(url, {
 68:         responseType: "arraybuffer",
 69:         timeout: 30000,
 70:         headers: {
 71:           "Accept": "image/jpeg",
 72:           "User-Agent": "FFTCG-Sync-Service/1.0",
 73:         },
 74:       });
 75: 
 76:       const buffer = Buffer.from(response.data);
 77:       const validationError = await ImageValidator.validateImage(buffer);
 78: 
 79:       if (validationError) {
 80:         throw new Error(`Image validation failed: ${validationError.message}`);
 81:       }
 82: 
 83:       imageCache.setBuffer(cacheKey, buffer);
 84: 
 85:       await logInfo("Successfully downloaded and validated image", {
 86:         url,
 87:         size: buffer.length,
 88:         timestamp: new Date().toISOString(),
 89:       });
 90: 
 91:       return buffer;
 92:     } catch (error) {
 93:       await logWarning("Failed to download or validate image", {
 94:         url,
 95:         error: error instanceof Error ? error.message : "Unknown error",
 96:         timestamp: new Date().toISOString(),
 97:       });
 98:       throw error;
 99:     }
100:   }
101: 
102:   private async shouldUpdateImage(
103:     groupId: string,
104:     productId: number,
105:     imageBuffer: Buffer,
106:     isHighRes: boolean
107:   ): Promise<boolean> {
108:     const storagePath = this.getStoragePath(groupId, productId, isHighRes);
109:     const metadataCacheKey = imageCache.getMetadataCacheKey(groupId, productId, isHighRes);
110:     const existsCacheKey = imageCache.getExistsCacheKey(groupId, productId, isHighRes);
111: 
112:     try {
113:       const cachedMetadata = await imageCache.getMetadata(metadataCacheKey);
114:       if (cachedMetadata) {
115:         const newHash = await this.getImageHash(imageBuffer);
116:         return cachedMetadata.hash !== newHash;
117:       }
118: 
119:       const exists = imageCache.getExists(existsCacheKey);
120:       if (exists === false) return true;
121: 
122:       const [fileExists] = await this.bucket.file(storagePath).exists();
123:       imageCache.setExists(existsCacheKey, fileExists);
124: 
125:       if (!fileExists) return true;
126: 
127:       const [metadata] = await this.bucket.file(storagePath).getMetadata();
128:       const currentHash = metadata.metadata?.hash;
129:       const newHash = await this.getImageHash(imageBuffer);
130: 
131:       return currentHash !== newHash;
132:     } catch (error) {
133:       const genericError: GenericError = {
134:         message: error instanceof Error ? error.message : "Unknown error",
135:         name: error instanceof Error ? error.name : "UnknownError",
136:         code: error instanceof AxiosError ? error.code : undefined,
137:         stack: error instanceof Error ? error.stack : undefined,
138:       };
139:       await logError(genericError, "shouldUpdateImage");
140:       return true;
141:     }
142:   }
143: 
144:   private async saveMetadata(
145:     groupId: string,
146:     productId: number,
147:     metadata: ImageMetadata
148:   ): Promise<void> {
149:     const docRef = db.collection(COLLECTION.IMAGE_METADATA)
150:       .doc(`${groupId}_${productId}`);
151: 
152:     await docRef.set({
153:       ...metadata,
154:       groupId,
155:       productId,
156:       lastUpdated: new Date(),
157:     }, {merge: true});
158: 
159:     const metadataCacheKey = imageCache.getMetadataCacheKey(groupId, productId, false);
160:     imageCache.setMetadata(metadataCacheKey, metadata);
161:   }
162: 
163:   async processImage(
164:     imageUrl: string,
165:     groupId: string,
166:     productId: number
167:   ): Promise<ImageProcessingResult> {
168:     try {
169:       await logInfo("Processing image", {
170:         productId,
171:         groupId,
172:         originalUrl: imageUrl,
173:         highResUrl: this.getHighResUrl(imageUrl),
174:         timestamp: new Date().toISOString(),
175:         cacheStats: imageCache.getStats(),
176:       });
177: 
178:       const highResUrl = this.getHighResUrl(imageUrl);
179:       let originalBuffer: Buffer | null = null;
180:       let highResBuffer: Buffer | null = null;
181:       let updated = false;
182: 
183:       try {
184:         originalBuffer = await this.downloadImage(imageUrl);
185:         if (originalBuffer) {
186:           originalBuffer = await this.compressImage(originalBuffer, false);
187:         }
188:       } catch (error) {
189:         await logWarning("Original image download failed", {
190:           productId,
191:           url: imageUrl,
192:           error: error instanceof Error ? error.message : "Unknown error",
193:           timestamp: new Date().toISOString(),
194:         });
195:       }
196: 
197:       try {
198:         highResBuffer = await this.downloadImage(highResUrl);
199:         if (highResBuffer) {
200:           highResBuffer = await this.compressImage(highResBuffer, true);
201:         }
202:       } catch (error) {
203:         await logWarning("High-res image download failed", {
204:           productId,
205:           url: highResUrl,
206:           error: error instanceof Error ? error.message : "Unknown error",
207:           timestamp: new Date().toISOString(),
208:         });
209:       }
210: 
211:       if (!originalBuffer && !highResBuffer) {
212:         throw new Error(`Failed to download both image versions for product ${productId}`);
213:       }
214: 
215:       const metadata: ImageMetadata = {
216:         contentType: "image/jpeg",
217:         size: 0,
218:         updated: new Date(),
219:         hash: "",
220:         originalUrl: imageUrl,
221:         highResUrl: highResUrl,
222:         originalSize: originalBuffer?.length,
223:         highResSize: highResBuffer?.length,
224:       };
225: 
226:       if (originalBuffer) {
227:         const originalNeedsUpdate = await this.shouldUpdateImage(groupId, productId, originalBuffer, false);
228:         if (originalNeedsUpdate) {
229:           const originalPath = this.getStoragePath(groupId, productId, false);
230:           const originalHash = await this.getImageHash(originalBuffer);
231:           await this.bucket.file(originalPath).save(originalBuffer, {
232:             metadata: {
233:               contentType: "image/jpeg",
234:               metadata: {
235:                 hash: originalHash,
236:                 type: "original",
237:                 updatedAt: new Date().toISOString(),
238:               },
239:             },
240:           });
241:           updated = true;
242:           metadata.hash = originalHash;
243:           metadata.size = originalBuffer.length;
244:         }
245:       }
246: 
247:       if (highResBuffer) {
248:         const highResNeedsUpdate = await this.shouldUpdateImage(groupId, productId, highResBuffer, true);
249:         if (highResNeedsUpdate) {
250:           const highResPath = this.getStoragePath(groupId, productId, true);
251:           const highResHash = await this.getImageHash(highResBuffer);
252:           await this.bucket.file(highResPath).save(highResBuffer, {
253:             metadata: {
254:               contentType: "image/jpeg",
255:               metadata: {
256:                 hash: highResHash,
257:                 type: "highres",
258:                 updatedAt: new Date().toISOString(),
259:               },
260:             },
261:           });
262:           updated = true;
263:         }
264:       }
265: 
266:       await this.saveMetadata(groupId, productId, metadata);
267: 
268:       const [originalStorageUrl] = await this.bucket.file(
269:         this.getStoragePath(groupId, productId, false)
270:       ).getSignedUrl({
271:         action: "read",
272:         expires: "03-01-2500",
273:       });
274: 
275:       const [highResStorageUrl] = await this.bucket.file(
276:         this.getStoragePath(groupId, productId, true)
277:       ).getSignedUrl({
278:         action: "read",
279:         expires: "03-01-2500",
280:       });
281: 
282:       return {
283:         originalUrl: originalStorageUrl,
284:         highResUrl: highResStorageUrl,
285:         metadata,
286:         updated,
287:       };
288:     } catch (error) {
289:       const genericError: GenericError = {
290:         message: error instanceof Error ? error.message : "Unknown error",
291:         name: error instanceof Error ? error.name : "UnknownError",
292:         code: error instanceof AxiosError ? error.code : undefined,
293:         stack: error instanceof Error ? error.stack : undefined,
294:       };
295:       await logError({
296:         ...genericError,
297:         metadata: {
298:           productId,
299:           groupId,
300:           originalUrl: imageUrl,
301:           highResUrl: this.getHighResUrl(imageUrl),
302:           timestamp: new Date().toISOString(),
303:           cacheStats: imageCache.getStats(),
304:         },
305:       }, "processImage");
306:       return {
307:         originalUrl: imageUrl,
308:         highResUrl: this.getHighResUrl(imageUrl),
309:         metadata: {
310:           contentType: "image/jpeg",
311:           size: 0,
312:           updated: new Date(),
313:           hash: "",
314:           originalUrl: imageUrl,
315:           highResUrl: this.getHighResUrl(imageUrl),
316:         },
317:         updated: false,
318:       };
319:     }
320:   }
321: 
322:   async cleanup(dryRun = true): Promise<void> {
323:     try {
324:       const [files] = await this.bucket.getFiles({
325:         prefix: STORAGE.PATHS.IMAGES,
326:       });
327: 
328:       const activeImages = await db.collection(COLLECTION.IMAGE_METADATA).get();
329:       const activeImagePaths = new Set([
330:         ...activeImages.docs.map((doc) => this.getStoragePath(
331:           doc.data().groupId,
332:           doc.data().productId,
333:           false
334:         )),
335:         ...activeImages.docs.map((doc) => this.getStoragePath(
336:           doc.data().groupId,
337:           doc.data().productId,
338:           true
339:         )),
340:       ]);
341: 
342:       let deletedCount = 0;
343:       for (const file of files) {
344:         if (!activeImagePaths.has(file.name)) {
345:           if (!dryRun) {
346:             await file.delete();
347:           }
348:           deletedCount++;
349:         }
350:       }
351: 
352:       // Clear caches after cleanup
353:       if (!dryRun) {
354:         imageCache.clear();
355:       }
356: 
357:       await logInfo("Cleanup complete", {
358:         deletedCount,
359:         mode: dryRun ? "dry-run" : "actual",
360:         timestamp: new Date().toISOString(),
361:         cacheStats: imageCache.getStats(),
362:       });
363:     } catch (error) {
364:       const genericError: GenericError = {
365:         message: error instanceof Error ? error.message : "Unknown error",
366:         name: error instanceof Error ? error.name : "UnknownError",
367:         code: error instanceof AxiosError ? error.code : undefined,
368:         stack: error instanceof Error ? error.stack : undefined,
369:       };
370:       await logError(genericError, "cleanup");
371:     }
372:   }
373: }
</file>

<file path="src/utils/imageValidator.ts">
 1: import {ImageValidationError} from "../types";
 2: 
 3: export class ImageValidator {
 4:   private static readonly MAX_FILE_SIZE = 5 * 1024 * 1024; // 5MB
 5: 
 6:   static async validateImage(buffer: Buffer): Promise<ImageValidationError | null> {
 7:     try {
 8:       // Check file size
 9:       if (buffer.length > this.MAX_FILE_SIZE) {
10:         return {
11:           code: "FILE_TOO_LARGE",
12:           message: `Image exceeds maximum size of ${this.MAX_FILE_SIZE / 1024 / 1024}MB`,
13:         };
14:       }
15: 
16:       // Check file signature (magic numbers for JPEG)
17:       if (!this.isJpeg(buffer)) {
18:         return {
19:           code: "INVALID_FORMAT",
20:           message: "Image must be in JPEG format",
21:         };
22:       }
23: 
24:       return null;
25:     } catch (error) {
26:       return {
27:         code: "VALIDATION_ERROR",
28:         message: error instanceof Error ? error.message : "Unknown validation error",
29:       };
30:     }
31:   }
32: 
33:   private static isJpeg(buffer: Buffer): boolean {
34:     return (
35:       buffer[0] === 0xFF &&
36:       buffer[1] === 0xD8 &&
37:       buffer[buffer.length - 2] === 0xFF &&
38:       buffer[buffer.length - 1] === 0xD9
39:     );
40:   }
41: }
</file>

<file path="src/utils/logger.ts">
 1: import * as functions from "firebase-functions";
 2: import {db, COLLECTION} from "../config/firebase";
 3: import {GenericError, LogData, GenericObject} from "../types";
 4: 
 5: export const logger = functions.logger;
 6: 
 7: interface LogEntry {
 8:   timestamp: Date;
 9:   level: "INFO" | "WARNING" | "ERROR";
10:   message: string;
11:   context?: string;
12:   data?: Record<string, unknown>;
13: }
14: 
15: function cleanLogData(data: Record<string, unknown>): Record<string, unknown> {
16:   return Object.entries(data).reduce((acc, [key, value]) => {
17:     // Skip undefined and null values
18:     if (value !== undefined && value !== null) {
19:       if (value && typeof value === "object") {
20:         const cleaned = cleanLogData(value as Record<string, unknown>);
21:         // Only add non-empty objects
22:         if (Object.keys(cleaned).length > 0) {
23:           acc[key] = cleaned;
24:         }
25:       } else {
26:         // Convert any specialized types to plain values
27:         acc[key] = value instanceof Date ? value.toISOString() : value;
28:       }
29:     }
30:     return acc;
31:   }, {} as Record<string, unknown>);
32: }
33: 
34: async function saveLogEntry(entry: LogEntry): Promise<void> {
35:   const cleanEntry = {
36:     timestamp: entry.timestamp,
37:     level: entry.level,
38:     message: entry.message,
39:     ...(entry.context && {context: entry.context}),
40:     ...(entry.data && {data: cleanLogData(entry.data)}),
41:   };
42: 
43:   await db.collection(COLLECTION.LOGS).add(cleanEntry);
44: }
45: 
46: export const logError = async (error: GenericError | GenericObject, context: string) => {
47:   const errorData = cleanLogData({
48:     stack: error.stack,
49:     code: error.code,
50:     ...(error as GenericObject),
51:     timestamp: new Date().toISOString(),
52:   });
53: 
54:   const entry: LogEntry = {
55:     timestamp: new Date(),
56:     level: "ERROR",
57:     message: error.message || "Unknown error",
58:     context,
59:     data: errorData,
60:   };
61: 
62:   logger.error(entry.message, errorData);
63:   await saveLogEntry(entry);
64: };
65: 
66: export const logInfo = async (message: string, data?: LogData) => {
67:   const cleanedData = data ? cleanLogData({
68:     ...data,
69:     timestamp: new Date().toISOString(),
70:   }) : undefined;
71: 
72:   const entry: LogEntry = {
73:     timestamp: new Date(),
74:     level: "INFO",
75:     message,
76:     ...(cleanedData && Object.keys(cleanedData).length > 0 && {data: cleanedData}),
77:   };
78: 
79:   logger.info(message, cleanedData);
80:   await saveLogEntry(entry);
81: };
82: 
83: export const logWarning = async (message: string, data?: LogData) => {
84:   const cleanedData = data ? cleanLogData({
85:     ...data,
86:     timestamp: new Date().toISOString(),
87:   }) : undefined;
88: 
89:   const entry: LogEntry = {
90:     timestamp: new Date(),
91:     level: "WARNING",
92:     message,
93:     ...(cleanedData && Object.keys(cleanedData).length > 0 && {data: cleanedData}),
94:   };
95: 
96:   logger.warn(message, cleanedData);
97:   await saveLogEntry(entry);
98: };
</file>

<file path="src/utils/progress.ts">
 1: // src/utils/progress.ts
 2: 
 3: import {logInfo} from "./logger";
 4: 
 5: export interface ProgressStats {
 6:   current: number;
 7:   total: number;
 8:   percent: number;
 9:   elapsed: number;
10:   rate: number;
11:   remaining: number;
12:   eta: number;
13: }
14: 
15: export class EnhancedProgressTracker {
16:   private startTime: number;
17:   private current: number;
18:   private estimates: number[] = [];
19:   private lastUpdate: number;
20:   private updateInterval: number;
21: 
22:   constructor(
23:     private total: number,
24:     private description: string,
25:     options: { updateInterval?: number } = {}
26:   ) {
27:     this.startTime = Date.now();
28:     this.current = 0;
29:     this.lastUpdate = Date.now();
30:     this.updateInterval = options.updateInterval || 1000; // Default 1 second
31:   }
32: 
33:   private calculateStats(): ProgressStats {
34:     const now = Date.now();
35:     const elapsed = (now - this.startTime) / 1000;
36:     const percent = (this.current / this.total) * 100;
37:     const rate = this.current / elapsed;
38:     const remaining = this.total - this.current;
39:     const eta = remaining / rate;
40: 
41:     return {
42:       current: this.current,
43:       total: this.total,
44:       percent,
45:       elapsed,
46:       rate,
47:       remaining,
48:       eta,
49:     };
50:   }
51: 
52:   update(amount = 1): void {
53:     const now = Date.now();
54:     this.current += amount;
55: 
56:     // Only update log if enough time has passed
57:     if (now - this.lastUpdate >= this.updateInterval) {
58:       const stats = this.calculateStats();
59:       this.estimates.push(stats.eta);
60: 
61:       // Keep only last 10 estimates for averaging
62:       if (this.estimates.length > 10) {
63:         this.estimates.shift();
64:       }
65: 
66:       const avgEta = this.estimates.reduce((a, b) => a + b, 0) / this.estimates.length;
67: 
68:       logInfo(
69:         `${this.description}: ${stats.current}/${stats.total} ` +
70:         `(${stats.percent.toFixed(1)}%) - ${stats.remaining} remaining - ` +
71:         `ETA: ${avgEta.toFixed(1)}s - Rate: ${stats.rate.toFixed(1)}/s`
72:       );
73: 
74:       this.lastUpdate = now;
75:     }
76:   }
77: 
78:   getProgress(): ProgressStats {
79:     return this.calculateStats();
80:   }
81: }
</file>

<file path="src/utils/request.ts">
 1: import axios, {AxiosError} from "axios";
 2: import {logWarning} from "./logger";
 3: 
 4: export const MAX_RETRIES = 3;
 5: export const BASE_DELAY = 1000; // 1 second
 6: 
 7: export interface RequestOptions {
 8:   retryCount?: number;
 9:   customDelay?: number;
10:   metadata?: Record<string, unknown>;
11: }
12: 
13: export class RequestError extends Error {
14:   constructor(
15:     message: string,
16:     public originalError: Error,
17:     public context: string,
18:     public metadata?: Record<string, unknown>
19:   ) {
20:     super(message);
21:     this.name = "RequestError";
22:   }
23: }
24: 
25: export async function makeRequest<T>(
26:   endpoint: string,
27:   baseUrl: string,
28:   options: RequestOptions = {}
29: ): Promise<T> {
30:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
31: 
32:   try {
33:     await new Promise((resolve) => setTimeout(resolve, customDelay));
34:     const url = `${baseUrl}/${endpoint}`;
35:     const response = await axios.get<T>(url, {
36:       timeout: 30000, // 30 seconds timeout
37:       headers: {
38:         "Accept": "application/json",
39:         "User-Agent": "FFTCG-Sync-Service/1.0",
40:       },
41:     });
42: 
43:     return response.data;
44:   } catch (error) {
45:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
46:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
47:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
48:         url: `${baseUrl}/${endpoint}`,
49:         attempt: retryCount + 1,
50:         maxRetries: MAX_RETRIES,
51:         error: error.message,
52:         ...options.metadata,
53:       });
54: 
55:       return makeRequest<T>(endpoint, baseUrl, {
56:         ...options,
57:         retryCount: retryCount + 1,
58:         customDelay: delay,
59:       });
60:     }
61: 
62:     throw new RequestError(
63:       `Request failed after ${retryCount + 1} attempts`,
64:       error as Error,
65:       endpoint,
66:       options.metadata
67:     );
68:   }
69: }
</file>

<file path="src/utils/syncLogger.ts">
  1: interface CardDetails {
  2:   id: number;
  3:   name: string;
  4:   groupId: string;
  5:   normalPrice?: number;
  6:   foilPrice?: number;
  7:   rawPrices: Array<{
  8:     type: "Normal" | "Foil";
  9:     price: number;
 10:     groupId: string;
 11:   }>;
 12:   imageUrl?: string;
 13:   storageImageUrl?: string;
 14: }
 15: 
 16: interface SyncLoggerOptions {
 17:   type: "manual" | "scheduled" | "both";
 18:   limit?: number;
 19:   dryRun?: boolean;
 20:   groupId?: string;
 21:   batchSize?: number;
 22: }
 23: 
 24: interface SyncResults {
 25:   success: number;
 26:   failures: number;
 27:   groupId?: string;
 28:   type: "Manual" | "Scheduled";
 29:   imagesProcessed?: number;
 30:   imagesUpdated?: number;
 31: }
 32: 
 33: export class SyncLogger {
 34:   private startTime: number;
 35:   private cards: CardDetails[] = [];
 36:   private groups: Map<string, { products: number; prices: number }> = new Map();
 37: 
 38:   constructor(private options: SyncLoggerOptions) {
 39:     this.startTime = Date.now();
 40:   }
 41: 
 42:   async start(): Promise<void> {
 43:     console.log("\nStarting sync test...");
 44:     console.log(`Type: ${this.options.type}`);
 45:     if (this.options.limit) console.log(`Limit: ${this.options.limit} cards`);
 46:     console.log(`Dry Run: ${this.options.dryRun ? "true" : "false"}`);
 47:     console.log("\n=== Fetching Raw Data ===");
 48:   }
 49: 
 50:   async logGroupFound(totalGroups: number): Promise<void> {
 51:     console.log(`Found ${totalGroups} groups`);
 52:   }
 53: 
 54:   async logGroupDetails(groupId: string, products: number, prices: number): Promise<void> {
 55:     this.groups.set(groupId, {products, prices});
 56:     console.log(`Group ${groupId} has ${products} products and ${prices} prices`);
 57:   }
 58: 
 59:   async logCardDetails(details: CardDetails): Promise<void> {
 60:     this.cards.push(details);
 61:     if (this.cards.length === 1) {
 62:       console.log("\n=== Card Details ===");
 63:     }
 64: 
 65:     console.log(`Card: ${details.name} (${details.groupId || "UNKNOWN"})`);
 66:     console.log(`- ID: ${details.id}`);
 67:     console.log(`- Group ID: ${details.groupId || "UNKNOWN"}`);
 68: 
 69:     if (details.rawPrices.length > 0) {
 70:       console.log("- Raw Prices:");
 71:       details.rawPrices.forEach((price) => {
 72:         console.log(`  > ${price.type}: $${price.price.toFixed(2)} (Group: ${price.groupId})`);
 73:       });
 74:     }
 75: 
 76:     if (details.imageUrl) {
 77:       console.log(`- Image URL: ${details.imageUrl}`);
 78:       if (details.storageImageUrl) {
 79:         console.log(`- Storage URL: ${details.storageImageUrl}`);
 80:       }
 81:     }
 82: 
 83:     console.log(`- Normal Price: $${details.normalPrice?.toFixed(2) || "0.00"}`);
 84:     console.log(`- Foil Price: $${details.foilPrice?.toFixed(2) || "0.00"}`);
 85:     console.log("---");
 86:   }
 87: 
 88:   async logManualSyncStart(): Promise<void> {
 89:     console.log("\n=== Testing Manual Sync ===");
 90:     if (this.options.groupId) console.log(`Filtering for groups: ${this.options.groupId}`);
 91:     if (this.options.dryRun) console.log("DRY RUN MODE - No data will be modified");
 92:     if (this.options.limit) console.log(`Processing limited to ${this.options.limit} cards`);
 93:     if (this.options.batchSize) console.log(`Batch size: ${this.options.batchSize}`);
 94:     console.log();
 95:   }
 96: 
 97:   async logScheduledSyncStart(): Promise<void> {
 98:     console.log("\n=== Testing Scheduled Sync ===");
 99:   }
100: 
101:   async logSyncProgress(message: string): Promise<void> {
102:     console.log(message);
103:   }
104: 
105:   async logSyncResults(results: SyncResults): Promise<void> {
106:     const duration = (Date.now() - this.startTime) / 1000;
107: 
108:     console.log(`\n${results.type} Sync Results:`);
109:     console.log(`- Success: ${results.success}`);
110:     console.log(`- Failures: ${results.failures}`);
111:     console.log(`- Duration: ${duration.toFixed(1)} seconds`);
112:     if (results.groupId) console.log(`- Group ID: ${results.groupId}`);
113:     if (results.imagesProcessed) console.log(`- Images Processed: ${results.imagesProcessed}`);
114:     if (results.imagesUpdated) console.log(`- Images Updated: ${results.imagesUpdated}`);
115:   }
116: 
117:   async finish(): Promise<void> {
118:     console.log("\nTest completed!");
119:   }
120: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "extends": "./tsconfig.json",
3:   "include": [
4:     ".eslintrc.js",
5:     ".eslintrc.fix.js",
6:     ".eslintrc.base.cjs"
7:   ]
8: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "noImplicitReturns": true,
 5:     "noUnusedLocals": true,
 6:     "outDir": "lib",
 7:     "sourceMap": true,
 8:     "strict": true,
 9:     "target": "es2017",
10:     "esModuleInterop": true,
11:     "skipLibCheck": true,
12:     "typeRoots": [
13:       "./node_modules/@types",
14:       "./src/types"
15:     ],
16:     "types": ["node", "express"],
17:     "baseUrl": "./src"
18:   },
19:   "compileOnSave": true,
20:   "include": [
21:     "src/**/*",
22:     ".eslintrc.js",
23:     ".eslintrc.fix.js",
24:     ".eslintrc.base.cjs"
25:   ],
26:   "exclude": [
27:     "node_modules",
28:     "lib"
29:   ]
30: }
</file>

</repository_files>
