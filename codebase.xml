This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2024-11-22T00:08:03.407Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
package.json
src/config/firebase.ts
src/global.d.ts
src/index.ts
src/services/cardSync.ts
src/services/priceSync.ts
src/test/testEndpoints.ts
src/test/testImageHandler.ts
src/test/testSync.ts
src/test/validateSync.ts
src/types/express.d.ts
src/types/index.ts
src/types/node.d.ts
src/utils/batch.ts
src/utils/cache.ts
src/utils/error.ts
src/utils/imageHandler.ts
src/utils/logger.ts
src/utils/progress.ts
src/utils/request.ts
src/utils/syncLogger.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     tsconfigRootDir: __dirname,
19:     sourceType: "module",
20:     createDefaultProgram: true,
21:   },
22:   ignorePatterns: [
23:     "/lib/**/*",
24:     "/generated/**/*",
25:     "node_modules/",
26:     "*.cjs",
27:   ],
28:   plugins: [
29:     "@typescript-eslint",
30:     "import",
31:   ],
32:   rules: {
33:     "quotes": ["error", "double"],
34:     "import/no-unresolved": 0,
35:     "indent": ["error", 2],
36:     "max-len": ["error", {"code": 120}],
37:     "@typescript-eslint/no-explicit-any": "off",
38:     "@typescript-eslint/no-unused-vars": ["error", {
39:       "argsIgnorePattern": "^_",
40:       "varsIgnorePattern": "^_",
41:     }],
42:     "valid-jsdoc": 0,
43:     "require-jsdoc": 0,
44:   },
45:   overrides: [
46:     {
47:       files: ["*.js", "*.cjs"],
48:       rules: {
49:         "@typescript-eslint/no-var-requires": "off",
50:       },
51:     },
52:   ],
53: };
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "clean": "rimraf lib",
 5:     "lint": "eslint --ext .js,.ts .",
 6:     "lint:fix": "eslint --ext .js,.ts . --fix",
 7:     "build": "npm run clean && tsc",
 8:     "build:watch": "tsc --watch",
 9:     "serve": "npm run build && firebase emulators:start --only functions,firestore,storage",
10:     "shell": "npm run build && firebase functions:shell",
11:     "start": "npm run shell",
12:     "deploy": "npm run lint:fix && firebase deploy --only functions",
13:     "logs": "firebase functions:log",
14:     "lint:fix:force": "eslint . --ext .js,.ts --fix --config .eslintrc.fix.js",
15:     "test:images": "ts-node src/test/testImageHandler.ts"
16:   },
17:   "engines": {
18:     "node": "18"
19:   },
20:   "main": "lib/index.js",
21:   "dependencies": {
22:     "axios": "^1.7.7",
23:     "firebase-admin": "^12.0.0",
24:     "firebase-functions": "^6.1.0",
25:     "lru-cache": "^7.14.1"
26:   },
27:   "devDependencies": {
28:     "@types/express": "^4.17.21",
29:     "@types/node": "^18.19.64",
30:     "@typescript-eslint/eslint-plugin": "^6.0.0",
31:     "@typescript-eslint/parser": "^6.0.0",
32:     "eslint": "^8.0.0",
33:     "eslint-config-google": "^0.14.0",
34:     "eslint-plugin-import": "^2.25.4",
35:     "firebase-functions-test": "^3.1.0",
36:     "rimraf": "^5.0.0",
37:     "typescript": "^4.9.5"
38:   },
39:   "private": true
40: }
</file>

<file path="src/config/firebase.ts">
 1: // functions/src/config/firebase.ts
 2: 
 3: import * as admin from "firebase-admin";
 4: 
 5: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 6: const db = admin.firestore(app);
 7: 
 8: // Enable ignoreUndefinedProperties and other settings
 9: db.settings({
10:   ignoreUndefinedProperties: true,
11:   timestampsInSnapshots: true,
12: });
13: 
14: const storage = admin.storage(app);
15: 
16: export {db, storage};
17: 
18: export const COLLECTION = {
19:   CARDS: "cards",
20:   PRICES: "prices",
21:   SYNC_METADATA: "syncMetadata",
22:   LOGS: "logs",
23:   CARD_HASHES: "cardHashes",
24:   PRICE_HASHES: "priceHashes",
25:   IMAGE_METADATA: "imageMetadata",
26: };
27: 
28: export const STORAGE = {
29:   BUCKETS: {
30:     CARD_IMAGES: "fftcg-sync-service.firebasestorage.app",
31:   },
32:   PATHS: {
33:     IMAGES: "card-images",
34:   },
35: };
36: 
37: export const BASE_URL = "https://tcgcsv.com";
38: export const FFTCG_CATEGORY_ID = "24";
39: 
40: export const runtimeOpts = {
41:   timeoutSeconds: 540,
42:   memory: "1GiB",
43: } as const;
</file>

<file path="src/global.d.ts">
1: // / <reference types="node" />
2: // / <reference types="express" />
</file>

<file path="src/index.ts">
 1: import {onRequest} from "firebase-functions/v2/https";
 2: import {onSchedule} from "firebase-functions/v2/scheduler";
 3: import {Request, Response} from "express";
 4: import {syncCards} from "./services/cardSync";
 5: import {syncPrices} from "./services/priceSync";
 6: import {runtimeOpts} from "./config/firebase";
 7: import {SyncOptions} from "./types";
 8: 
 9: // Scheduled card sync
10: exports.scheduledCardSync = onSchedule({
11:   schedule: "0 21 * * *", // Daily at 21:00 UTC
12:   timeZone: "UTC",
13:   memory: runtimeOpts.memory,
14:   timeoutSeconds: runtimeOpts.timeoutSeconds,
15:   retryCount: 3,
16: }, async (_context) => {
17:   await syncCards();
18: });
19: 
20: // Manual card sync endpoint for testing
21: exports.testCardSync = onRequest({
22:   timeoutSeconds: runtimeOpts.timeoutSeconds,
23:   memory: runtimeOpts.memory,
24:   maxInstances: 1,
25: }, async (req: Request, res: Response) => {
26:   const options: SyncOptions = {
27:     dryRun: true,
28:     limit: req.query.limit ? parseInt(req.query.limit as string) : 5,
29:     groupId: req.query.groupId as string,
30:   };
31: 
32:   const result = await syncCards(options);
33:   res.json(result);
34: });
35: 
36: exports.manualCardSync = onRequest({
37:   timeoutSeconds: runtimeOpts.timeoutSeconds,
38:   memory: runtimeOpts.memory,
39:   maxInstances: 1,
40: }, async (_req: Request, res: Response) => {
41:   const result = await syncCards({dryRun: false});
42:   res.json(result);
43: });
44: 
45: // Scheduled price sync
46: exports.scheduledPriceSync = onSchedule({
47:   schedule: "30 21 * * *", // Daily at 21:30 UTC
48:   timeZone: "UTC",
49:   memory: runtimeOpts.memory,
50:   timeoutSeconds: runtimeOpts.timeoutSeconds,
51:   retryCount: 3,
52: }, async (_context) => {
53:   await syncPrices();
54: });
55: 
56: // Manual price sync endpoint for testing
57: exports.testPriceSync = onRequest({
58:   timeoutSeconds: runtimeOpts.timeoutSeconds,
59:   memory: runtimeOpts.memory,
60:   maxInstances: 1,
61: }, async (req: Request, res: Response) => {
62:   const options: SyncOptions = {
63:     dryRun: req.query.dryRun === "true",
64:     limit: req.query.limit ? parseInt(req.query.limit as string) : undefined,
65:     groupId: req.query.groupId as string,
66:     productId: req.query.productId ? parseInt(req.query.productId as string) : undefined,
67:     showAll: req.query.showAll === "true",
68:   };
69: 
70:   const result = await syncPrices(options);
71:   res.json(result);
72: });
73: 
74: // For manually triggering full price sync
75: exports.manualPriceSync = onRequest({
76:   timeoutSeconds: runtimeOpts.timeoutSeconds,
77:   memory: runtimeOpts.memory,
78:   maxInstances: 1,
79: }, async (_req: Request, res: Response) => {
80:   const result = await syncPrices();
81:   res.json(result);
82: });
83: 
84: // Health check endpoint
85: exports.healthCheck = onRequest({
86:   timeoutSeconds: 10,
87:   memory: "128MiB",
88: }, async (_req: Request, res: Response) => {
89:   res.json({
90:     status: "healthy",
91:     timestamp: new Date().toISOString(),
92:     version: "1.0.0",
93:   });
94: });
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: 
  3: import axios, {AxiosError} from "axios";
  4: import {db, COLLECTION, FFTCG_CATEGORY_ID, BASE_URL} from "../config/firebase";
  5: import {
  6:   CardProduct,
  7:   SyncOptions,
  8:   SyncMetadata,
  9:   GenericError,
 10:   CardPrice,
 11:   BatchProcessingStats,
 12: } from "../types";
 13: import {cardCache, getCacheKey} from "../utils/cache";
 14: import {logError, logInfo, logWarning} from "../utils/logger";
 15: import * as crypto from "crypto";
 16: import {SyncLogger} from "../utils/syncLogger";
 17: import {ImageHandler} from "../utils/imageHandler";
 18: 
 19: const MAX_RETRIES = 3;
 20: const BASE_DELAY = 1000;
 21: 
 22: interface RequestOptions {
 23:   retryCount?: number;
 24:   customDelay?: number;
 25:   metadata?: Record<string, unknown>;
 26: }
 27: 
 28: class SyncError extends Error implements GenericError {
 29:   code?: string;
 30: 
 31:   constructor(
 32:     message: string,
 33:     code?: string,
 34:     public details?: Record<string, unknown>
 35:   ) {
 36:     super(message);
 37:     this.name = "SyncError";
 38:     this.code = code;
 39:   }
 40: 
 41:   toGenericError(): GenericError {
 42:     return {
 43:       name: this.name,
 44:       message: this.message,
 45:       code: this.code,
 46:       stack: this.stack,
 47:     };
 48:   }
 49: }
 50: 
 51: async function makeRequest<T>(
 52:   endpoint: string,
 53:   options: RequestOptions = {}
 54: ): Promise<T> {
 55:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
 56: 
 57:   try {
 58:     await new Promise((resolve) => setTimeout(resolve, customDelay));
 59:     const url = `${BASE_URL}/${endpoint}`;
 60: 
 61:     await logInfo(`Making request to: ${url}`, {
 62:       attempt: retryCount + 1,
 63:       maxRetries: MAX_RETRIES,
 64:       endpoint,
 65:       ...options.metadata,
 66:     });
 67: 
 68:     const response = await axios.get<T>(url, {
 69:       timeout: 30000,
 70:       headers: {
 71:         "Accept": "application/json",
 72:         "User-Agent": "FFTCG-Sync-Service/1.0",
 73:       },
 74:     });
 75: 
 76:     return response.data;
 77:   } catch (error) {
 78:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
 79:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
 80:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
 81:         error: error.message,
 82:         url: `${BASE_URL}/${endpoint}`,
 83:         attempt: retryCount + 1,
 84:         maxRetries: MAX_RETRIES,
 85:       });
 86: 
 87:       return makeRequest<T>(endpoint, {
 88:         ...options,
 89:         retryCount: retryCount + 1,
 90:         customDelay: delay,
 91:       });
 92:     }
 93: 
 94:     throw new SyncError(
 95:       error instanceof Error ? error.message : "Unknown request error",
 96:       error instanceof AxiosError ? error.code : "UNKNOWN_ERROR",
 97:       {endpoint, ...options.metadata}
 98:     );
 99:   }
100: }
101: 
102: function getDataHash(data: any): string {
103:   return crypto.createHash("md5")
104:     .update(JSON.stringify(data, Object.keys(data).sort()))
105:     .digest("hex");
106: }
107: 
108: interface BatchOptions {
109:   batchSize?: number;
110:   onBatchComplete?: (stats: BatchProcessingStats) => Promise<void>;
111: }
112: 
113: async function processBatch<T>(
114:   items: T[],
115:   processor: (batch: T[]) => Promise<void>,
116:   options: BatchOptions = {}
117: ): Promise<void> {
118:   const {
119:     batchSize = 500,
120:     onBatchComplete,
121:   } = options;
122: 
123:   const totalBatches = Math.ceil(items.length / batchSize);
124:   let processedCount = 0;
125: 
126:   for (let i = 0; i < items.length; i += batchSize) {
127:     const batch = items.slice(i, i + batchSize);
128:     await processor(batch);
129:     processedCount += batch.length;
130: 
131:     if (onBatchComplete) {
132:       await onBatchComplete({
133:         total: items.length,
134:         processed: processedCount,
135:         successful: processedCount,
136:         failed: 0,
137:         skipped: 0,
138:       });
139:     }
140: 
141:     await logInfo(
142:       `Processed batch ${Math.floor(i / batchSize) + 1}/${totalBatches} (${processedCount}/${items.length} items)`
143:     );
144: 
145:     if (i + batchSize < items.length) {
146:       await new Promise((resolve) => setTimeout(resolve, 100));
147:     }
148:   }
149: }
150: 
151: async function processGroupProducts(
152:   group: any,
153:   options: SyncOptions,
154:   metadata: SyncMetadata,
155:   existingHashes: Map<string, string>,
156:   imageHandler: ImageHandler,
157:   logger?: SyncLogger
158: ): Promise<number> {
159:   const groupId = group.groupId.toString();
160:   let processedCards = 0;
161: 
162:   try {
163:     const [productsResponse, pricesResponse] = await Promise.all([
164:       makeRequest<{ results: CardProduct[] }>(
165:         `${FFTCG_CATEGORY_ID}/${groupId}/products`,
166:         {metadata: {groupId, groupName: group.name}}
167:       ),
168:       makeRequest<{ results: CardPrice[] }>(
169:         `${FFTCG_CATEGORY_ID}/${groupId}/prices`,
170:         {metadata: {groupId, groupName: group.name}}
171:       ),
172:     ]);
173: 
174:     const products = productsResponse.results;
175:     const prices = pricesResponse.results;
176: 
177:     if (logger) {
178:       await logger.logGroupDetails(groupId, products.length, prices.length);
179:     }
180: 
181:     const groupHash = getDataHash(products);
182:     const existingHash = existingHashes.get(groupId);
183: 
184:     if (logger && options.dryRun) {
185:       for (const product of products) {
186:         if (options.limit && processedCards >= options.limit) break;
187: 
188:         const cardPrices = prices.filter((p) => p.productId === product.productId);
189:         await logger.logCardDetails({
190:           id: product.productId,
191:           name: product.name,
192:           groupId: product.groupId.toString(),
193:           normalPrice: cardPrices.find((p) => p.subTypeName === "Normal")?.midPrice,
194:           foilPrice: cardPrices.find((p) => p.subTypeName === "Foil")?.midPrice,
195:           imageUrl: product.imageUrl,
196:           rawPrices: cardPrices.map((p) => ({
197:             type: p.subTypeName,
198:             price: p.midPrice,
199:             groupId: groupId,
200:           })),
201:         });
202:         processedCards++;
203:       }
204:     }
205: 
206:     if (!options.dryRun && (!existingHash || existingHash !== groupHash)) {
207:       metadata.groupsUpdated++;
208: 
209:       await processBatch(products, async (batch) => {
210:         const writeBatch = db.batch();
211:         const imagePromises: Promise<any>[] = [];
212: 
213:         for (const product of batch) {
214:           if (options.limit && processedCards >= options.limit) break;
215: 
216:           if (!options.skipImages) {
217:             imagePromises.push(
218:               imageHandler.processImage(
219:                 product.imageUrl,
220:                 groupId,
221:                 product.productId
222:               )
223:             );
224:           }
225: 
226:           const cardRef = db.collection(COLLECTION.CARDS)
227:             .doc(product.productId.toString());
228: 
229:           writeBatch.set(cardRef, {
230:             ...product,
231:             lastUpdated: new Date(),
232:             groupHash,
233:           }, {merge: true});
234: 
235:           cardCache.set(getCacheKey("card", product.productId), product);
236:           processedCards++;
237:         }
238: 
239:         if (imagePromises.length > 0) {
240:           const imageResults = await Promise.allSettled(imagePromises);
241: 
242:           imageResults.forEach((result, index) => {
243:             if (result.status === "fulfilled") {
244:               const product = batch[index];
245:               const cardRef = db.collection(COLLECTION.CARDS)
246:                 .doc(product.productId.toString());
247: 
248:               writeBatch.update(cardRef, {
249:                 storageImageUrl: result.value.url,
250:                 imageMetadata: result.value.metadata,
251:               });
252: 
253:               if (result.value.updated) {
254:                 metadata.imagesUpdated = (metadata.imagesUpdated || 0) + 1;
255:               }
256:             }
257:           });
258: 
259:           metadata.imagesProcessed = (metadata.imagesProcessed || 0) + imagePromises.length;
260:         }
261: 
262:         const hashRef = db.collection(COLLECTION.CARD_HASHES)
263:           .doc(groupId);
264:         writeBatch.set(hashRef, {
265:           hash: groupHash,
266:           lastUpdated: new Date(),
267:         });
268: 
269:         await writeBatch.commit();
270:       }, {
271:         batchSize: 100,
272:         onBatchComplete: async (stats) => {
273:           await logInfo("Batch processing progress", stats);
274:         },
275:       });
276: 
277:       await logInfo(`Updated ${processedCards} cards from group ${groupId}`, {
278:         imagesProcessed: metadata.imagesProcessed,
279:         imagesUpdated: metadata.imagesUpdated,
280:       });
281:     } else {
282:       await logInfo(`No updates needed for group ${groupId} (unchanged)`);
283:     }
284: 
285:     metadata.cardCount += products.length;
286:     return processedCards;
287:   } catch (error) {
288:     const syncError = error instanceof Error ?
289:       new SyncError(error.message, "GROUP_PROCESSING_ERROR", {groupId}) :
290:       new SyncError("Unknown group processing error", "UNKNOWN_ERROR", {groupId});
291: 
292:     const errorMessage = `Error processing group ${groupId}: ${syncError.message}`;
293:     metadata.errors.push(errorMessage);
294:     await logError(syncError.toGenericError(), "processGroupProducts");
295:     return processedCards;
296:   }
297: }
298: 
299: export async function syncCards(options: SyncOptions = {}): Promise<SyncMetadata> {
300:   const logger = new SyncLogger({
301:     type: options.dryRun ? "manual" : "scheduled",
302:     limit: options.limit,
303:     dryRun: options.dryRun,
304:     groupId: options.groupId,
305:     batchSize: 25,
306:   });
307: 
308:   const imageHandler = new ImageHandler();
309: 
310:   await logger.start();
311: 
312:   const startTime = Date.now();
313:   const metadata: SyncMetadata = {
314:     lastSync: new Date(),
315:     status: "in_progress",
316:     cardCount: 0,
317:     type: options.dryRun ? "manual" : "scheduled",
318:     groupsProcessed: 0,
319:     groupsUpdated: 0,
320:     errors: [],
321:     imagesProcessed: 0,
322:     imagesUpdated: 0,
323:   };
324: 
325:   try {
326:     const groupsResponse = await makeRequest<{ results: any[] }>(
327:       `${FFTCG_CATEGORY_ID}/groups`,
328:       {metadata: {operation: "fetchGroups"}}
329:     );
330: 
331:     const groups = groupsResponse.results;
332:     await logger.logGroupFound(groups.length);
333: 
334:     let processedCards = 0;
335:     const existingHashes = new Map<string, string>();
336: 
337:     const hashesSnapshot = await db.collection(COLLECTION.CARD_HASHES).get();
338:     hashesSnapshot.forEach((doc) => {
339:       existingHashes.set(doc.id, doc.data().hash);
340:     });
341: 
342:     if (options.dryRun) {
343:       await logger.logManualSyncStart();
344:     }
345: 
346:     for (const group of groups) {
347:       if (options.groupId && group.groupId.toString() !== options.groupId) continue;
348: 
349:       metadata.groupsProcessed++;
350:       const groupProcessedCards = await processGroupProducts(
351:         group,
352:         options,
353:         metadata,
354:         existingHashes,
355:         imageHandler,
356:         logger
357:       );
358: 
359:       processedCards += groupProcessedCards;
360:       if (options.limit && processedCards >= options.limit) break;
361:     }
362: 
363:     metadata.status = metadata.errors.length > 0 ? "completed_with_errors" : "success";
364: 
365:     await logger.logSyncResults({
366:       success: processedCards,
367:       failures: metadata.errors.length,
368:       groupId: options.groupId,
369:       type: options.dryRun ? "Manual" : "Scheduled",
370:       imagesProcessed: metadata.imagesProcessed,
371:       imagesUpdated: metadata.imagesUpdated,
372:     });
373:   } catch (error) {
374:     const syncError = error instanceof Error ?
375:       new SyncError(error.message, "SYNC_MAIN_ERROR") :
376:       new SyncError("Unknown sync error", "UNKNOWN_ERROR");
377: 
378:     metadata.status = "failed";
379:     metadata.errors.push(syncError.message);
380:     await logError(syncError.toGenericError(), "syncCards:main");
381:   }
382: 
383:   metadata.lastSync = new Date();
384:   metadata.duration = Date.now() - startTime;
385: 
386:   if (!options.dryRun) {
387:     await db.collection(COLLECTION.SYNC_METADATA)
388:       .add(metadata);
389:   }
390: 
391:   await logger.finish();
392:   return metadata;
393: }
</file>

<file path="src/services/priceSync.ts">
  1: import axios, {AxiosError} from "axios";
  2: import {db, COLLECTION, FFTCG_CATEGORY_ID, BASE_URL} from "../config/firebase";
  3: import {
  4:   CardPrice,
  5:   SyncOptions,
  6:   SyncMetadata,
  7:   PriceData,
  8:   GenericError,
  9:   CardProduct,
 10: } from "../types";
 11: import {logError, logInfo, logWarning} from "../utils/logger";
 12: import {SyncLogger} from "../utils/syncLogger";
 13: import * as crypto from "crypto";
 14: 
 15: const MAX_RETRIES = 3;
 16: const BASE_DELAY = 1000;
 17: 
 18: interface RequestOptions {
 19:   retryCount?: number;
 20:   customDelay?: number;
 21:   metadata?: Record<string, unknown>;
 22: }
 23: 
 24: class SyncError extends Error implements GenericError {
 25:   code?: string;
 26: 
 27:   constructor(
 28:     message: string,
 29:     code?: string,
 30:     public details?: Record<string, unknown>
 31:   ) {
 32:     super(message);
 33:     this.name = "SyncError";
 34:     this.code = code;
 35:   }
 36: 
 37:   toGenericError(): GenericError {
 38:     return {
 39:       name: this.name,
 40:       message: this.message,
 41:       code: this.code,
 42:       stack: this.stack,
 43:     };
 44:   }
 45: }
 46: 
 47: async function makeRequest<T>(
 48:   endpoint: string,
 49:   options: RequestOptions = {}
 50: ): Promise<T> {
 51:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
 52: 
 53:   try {
 54:     await new Promise((resolve) => setTimeout(resolve, customDelay));
 55:     const url = `${BASE_URL}/${endpoint}`;
 56: 
 57:     await logInfo(`Making request to: ${url}`, {
 58:       attempt: retryCount + 1,
 59:       maxRetries: MAX_RETRIES,
 60:       endpoint,
 61:       ...options.metadata,
 62:     });
 63: 
 64:     const response = await axios.get<T>(url, {
 65:       timeout: 30000,
 66:       headers: {
 67:         "Accept": "application/json",
 68:         "User-Agent": "FFTCG-Sync-Service/1.0",
 69:       },
 70:     });
 71: 
 72:     return response.data;
 73:   } catch (error) {
 74:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
 75:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
 76:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
 77:         error: error.message,
 78:         url: `${BASE_URL}/${endpoint}`,
 79:         attempt: retryCount + 1,
 80:         maxRetries: MAX_RETRIES,
 81:       });
 82: 
 83:       return makeRequest<T>(endpoint, {
 84:         ...options,
 85:         retryCount: retryCount + 1,
 86:         customDelay: delay,
 87:       });
 88:     }
 89: 
 90:     throw new SyncError(
 91:       error instanceof Error ? error.message : "Unknown request error",
 92:       error instanceof AxiosError ? error.code : "UNKNOWN_ERROR",
 93:       {endpoint, ...options.metadata}
 94:     );
 95:   }
 96: }
 97: 
 98: function getDataHash(data: any): string {
 99:   return crypto.createHash("md5")
100:     .update(JSON.stringify(data, Object.keys(data).sort()))
101:     .digest("hex");
102: }
103: 
104: function processPrices(prices: CardPrice[]): Record<number, PriceData> {
105:   const priceMap: Record<number, PriceData> = {};
106: 
107:   prices.forEach((price) => {
108:     if (!priceMap[price.productId]) {
109:       priceMap[price.productId] = {
110:         lastUpdated: new Date(),
111:       };
112:     }
113: 
114:     if (price.subTypeName === "Normal") {
115:       priceMap[price.productId].normal = price;
116:     } else {
117:       priceMap[price.productId].foil = price;
118:     }
119:   });
120: 
121:   return priceMap;
122: }
123: 
124: async function processBatch<T>(
125:   items: T[],
126:   processor: (batch: T[]) => Promise<void>,
127:   batchSize: number = 500
128: ): Promise<void> {
129:   for (let i = 0; i < items.length; i += batchSize) {
130:     const batch = items.slice(i, i + batchSize);
131:     await processor(batch);
132:     await new Promise((resolve) => setTimeout(resolve, 100));
133:   }
134: }
135: 
136: async function processGroupPrices(
137:   group: any,
138:   options: SyncOptions,
139:   metadata: SyncMetadata,
140:   logger?: SyncLogger
141: ): Promise<void> {
142:   const groupId = group.groupId.toString();
143: 
144:   try {
145:     // If specific productId is provided, first verify the card exists
146:     if (options.productId) {
147:       const card = await db.collection(COLLECTION.CARDS)
148:         .doc(options.productId.toString())
149:         .get();
150: 
151:       if (!card.exists) {
152:         throw new SyncError(
153:           `Card with ID ${options.productId} not found`,
154:           "CARD_NOT_FOUND",
155:           {productId: options.productId}
156:         );
157:       }
158: 
159:       const cardData = card.data();
160:       if (cardData?.groupId?.toString() !== groupId) {
161:         return; // Skip this group if it doesn't contain the requested product
162:       }
163:     }
164: 
165:     // Fetch both products and prices for detailed logging
166:     const [productsResponse, pricesResponse] = await Promise.all([
167:       makeRequest<{ results: CardProduct[] }>(
168:         `${FFTCG_CATEGORY_ID}/${groupId}/products`,
169:         {metadata: {groupId, groupName: group.name}}
170:       ),
171:       makeRequest<{ results: CardPrice[] }>(
172:         `${FFTCG_CATEGORY_ID}/${groupId}/prices`,
173:         {metadata: {groupId, groupName: group.name}}
174:       ),
175:     ]);
176: 
177:     const products = productsResponse.results;
178:     let prices = pricesResponse.results;
179: 
180:     if (logger) {
181:       await logger.logGroupDetails(groupId, products.length, prices.length);
182:     }
183: 
184:     // Filter for specific product if requested
185:     if (options.productId) {
186:       prices = prices.filter((p) => p.productId === options.productId);
187:       if (prices.length === 0) {
188:         throw new SyncError(
189:           `No prices found for product ${options.productId}`,
190:           "NO_PRICES_FOUND",
191:           {productId: options.productId}
192:         );
193:       }
194:     }
195: 
196:     const priceHash = getDataHash(prices);
197:     const hashDoc = await db.collection(COLLECTION.PRICE_HASHES)
198:       .doc(groupId)
199:       .get();
200: 
201:     const existingHash = hashDoc.exists ? hashDoc.data()?.hash : null;
202: 
203:     // Log detailed price information if logger is available
204:     if (logger && options.dryRun) {
205:       for (const product of products) {
206:         const cardPrices = prices.filter((p) => p.productId === product.productId);
207:         if (cardPrices.length > 0) {
208:           await logger.logCardDetails({
209:             id: product.productId,
210:             name: product.name,
211:             groupId: groupId,
212:             normalPrice: cardPrices.find((p) => p.subTypeName === "Normal")?.midPrice,
213:             foilPrice: cardPrices.find((p) => p.subTypeName === "Foil")?.midPrice,
214:             rawPrices: cardPrices.map((p) => ({
215:               type: p.subTypeName,
216:               price: p.midPrice,
217:               groupId: groupId,
218:             })),
219:           });
220:         }
221:       }
222:     }
223: 
224:     if (!options.dryRun && (!existingHash || existingHash !== priceHash)) {
225:       metadata.groupsUpdated++;
226:       const processedPrices = processPrices(prices);
227: 
228:       await processBatch(
229:         Object.entries(processedPrices),
230:         async (batch) => {
231:           const writeBatch = db.batch();
232: 
233:           for (const [productId, priceData] of batch) {
234:             if (options.limit && metadata.cardCount >= options.limit) break;
235: 
236:             const priceRef = db.collection(COLLECTION.PRICES)
237:               .doc(productId);
238:             writeBatch.set(priceRef, priceData, {merge: true});
239: 
240:             metadata.cardCount++;
241:           }
242: 
243:           // Update hash
244:           const hashRef = db.collection(COLLECTION.PRICE_HASHES)
245:             .doc(groupId);
246:           writeBatch.set(hashRef, {
247:             hash: priceHash,
248:             lastUpdated: new Date(),
249:           });
250: 
251:           await writeBatch.commit();
252:         }
253:       );
254: 
255:       await logInfo(`Updated ${metadata.cardCount} prices from group ${groupId}`);
256:     } else {
257:       await logInfo(`No updates needed for group ${groupId} (unchanged)`);
258:     }
259:   } catch (error) {
260:     const syncError = error instanceof SyncError ? error :
261:       error instanceof Error ?
262:         new SyncError(error.message, "GROUP_PROCESSING_ERROR", {groupId}) :
263:         new SyncError("Unknown group processing error", "UNKNOWN_ERROR", {groupId});
264: 
265:     const errorMessage = `Error processing group ${groupId}: ${syncError.message}`;
266:     metadata.errors.push(errorMessage);
267:     await logError(syncError.toGenericError(), "processGroupPrices");
268:   }
269: }
270: 
271: export async function syncPrices(options: SyncOptions = {}): Promise<SyncMetadata> {
272:   const logger = new SyncLogger({
273:     type: options.dryRun ? "both" : "scheduled",
274:     limit: options.limit,
275:     dryRun: options.dryRun,
276:     groupId: options.groupId,
277:     batchSize: 25,
278:   });
279: 
280:   await logger.start();
281: 
282:   const startTime = Date.now();
283:   const metadata: SyncMetadata = {
284:     lastSync: new Date(),
285:     status: "in_progress",
286:     cardCount: 0,
287:     type: options.dryRun ? "manual" : "scheduled",
288:     groupsProcessed: 0,
289:     groupsUpdated: 0,
290:     errors: [],
291:   };
292: 
293:   try {
294:     const groupsResponse = await makeRequest<{ results: any[] }>(
295:       `${FFTCG_CATEGORY_ID}/groups`,
296:       {metadata: {operation: "fetchGroups"}}
297:     );
298: 
299:     const groups = groupsResponse.results;
300:     await logger.logGroupFound(groups.length);
301: 
302:     if (options.dryRun) {
303:       await logger.logManualSyncStart();
304:     }
305: 
306:     if (options.groupId) {
307:       const group = groups.find((g) => g.groupId.toString() === options.groupId);
308:       if (!group) {
309:         throw new SyncError(
310:           `Group ${options.groupId} not found`,
311:           "GROUP_NOT_FOUND",
312:           {groupId: options.groupId}
313:         );
314:       }
315:       groups.length = 0;
316:       groups.push(group);
317:     }
318: 
319:     for (const group of groups) {
320:       metadata.groupsProcessed++;
321:       await processGroupPrices(group, options, metadata, logger);
322: 
323:       if (options.limit && metadata.cardCount >= options.limit) break;
324:     }
325: 
326:     metadata.status = metadata.errors.length > 0 ? "completed_with_errors" : "success";
327: 
328:     await logger.logSyncResults({
329:       success: metadata.cardCount,
330:       failures: metadata.errors.length,
331:       groupId: options.groupId,
332:       type: options.dryRun ? "Manual" : "Scheduled",
333:     });
334:   } catch (error) {
335:     const syncError = error instanceof SyncError ? error :
336:       error instanceof Error ?
337:         new SyncError(error.message, "SYNC_MAIN_ERROR") :
338:         new SyncError("Unknown sync error", "UNKNOWN_ERROR");
339: 
340:     metadata.status = "failed";
341:     metadata.errors.push(syncError.message);
342:     await logError(syncError.toGenericError(), "syncPrices:main");
343:   }
344: 
345:   metadata.lastSync = new Date();
346:   metadata.duration = Date.now() - startTime;
347: 
348:   if (!options.dryRun) {
349:     await db.collection(COLLECTION.SYNC_METADATA)
350:       .add(metadata);
351:   }
352: 
353:   await logger.finish();
354:   return metadata;
355: }
</file>

<file path="src/test/testEndpoints.ts">
 1: import axios, {isAxiosError} from "axios";
 2: 
 3: const FIREBASE_REGION = "us-central1";
 4: const PROJECT_ID = "fftcg-sync-service";
 5: const BASE_URL = `https://${FIREBASE_REGION}-${PROJECT_ID}.cloudfunctions.net`;
 6: 
 7: interface SyncResponse {
 8:   lastSync: Date;
 9:   status: string;
10:   cardCount: number;
11:   type: string;
12:   groupsProcessed: number;
13:   groupsUpdated: number;
14:   errors: string[];
15:   duration?: number;
16: }
17: 
18: async function testEndpoints() {
19:   try {
20:     // Test card sync
21:     console.log("\nTesting card sync...");
22:     const cardResponse = await axios.get<SyncResponse>(`${BASE_URL}/testCardSync`, {
23:       params: {
24:         limit: 5,
25:         dryRun: true,
26:         groupId: "23783", // Example group ID
27:       },
28:     });
29:     console.log("Card sync results:", JSON.stringify(cardResponse.data, null, 2));
30: 
31:     // Test price sync
32:     console.log("\nTesting price sync...");
33:     const priceResponse = await axios.get<SyncResponse>(`${BASE_URL}/testPriceSync`, {
34:       params: {
35:         groupId: "23783", // Example group ID
36:         dryRun: true,
37:         limit: 5,
38:       },
39:     });
40:     console.log("Price sync results:", JSON.stringify(priceResponse.data, null, 2));
41: 
42:     // Test health check
43:     console.log("\nTesting health check...");
44:     const healthResponse = await axios.get(`${BASE_URL}/healthCheck`);
45:     console.log("Health check response:", JSON.stringify(healthResponse.data, null, 2));
46:   } catch (error) {
47:     if (isAxiosError(error)) {
48:       console.error("Test failed:", error.response?.data || error.message);
49:       console.error("Status:", error.response?.status);
50:       console.error("Headers:", error.response?.headers);
51:     } else {
52:       console.error("Test failed:", error);
53:     }
54:     process.exit(1);
55:   }
56: }
57: 
58: // Execute tests
59: console.log("Starting endpoint tests...");
60: testEndpoints().then(() => {
61:   console.log("All tests completed!");
62: }).catch(console.error);
</file>

<file path="src/test/testImageHandler.ts">
 1: // src/test/testImageHandler.ts
 2: import {ImageHandler} from "../utils/imageHandler";
 3: 
 4: const TEST_CASES = [
 5:   {
 6:     imageUrl: "https://tcgplayer-cdn.tcgplayer.com/product/477236_200w.jpg",
 7:     groupId: "23783",
 8:     productId: 477236,
 9:     description: "FFVII Boss Deck",
10:   },
11: ];
12: 
13: async function testImageProcessing() {
14:   try {
15:     console.log("\nTesting Image Handler...");
16:     const imageHandler = new ImageHandler();
17: 
18:     for (const testCase of TEST_CASES) {
19:       console.log(`\nTesting image download and processing for ${testCase.description}...`);
20:       console.log(`Original URL: ${testCase.imageUrl}`);
21:       console.log(`High-res URL: ${testCase.imageUrl.replace("_200w.jpg", "_400w.jpg")}`);
22: 
23:       const result = await imageHandler.processImage(
24:         testCase.imageUrl,
25:         testCase.groupId,
26:         testCase.productId
27:       );
28: 
29:       console.log("Image Processing Results:", {
30:         originalUrl: result.originalUrl,
31:         highResUrl: result.highResUrl,
32:         updated: result.updated,
33:         metadata: {
34:           size: result.metadata.size,
35:           originalSize: result.metadata.originalSize,
36:           highResSize: result.metadata.highResSize,
37:           contentType: result.metadata.contentType,
38:           updated: result.metadata.updated,
39:         },
40:       });
41: 
42:       // Test cache behavior
43:       console.log("\nTesting cache behavior...");
44:       const cachedResult = await imageHandler.processImage(
45:         testCase.imageUrl,
46:         testCase.groupId,
47:         testCase.productId
48:       );
49: 
50:       console.log("Cache Test Results:", {
51:         cached: !cachedResult.updated,
52:         originalUrl: cachedResult.originalUrl,
53:         highResUrl: cachedResult.highResUrl,
54:       });
55:     }
56: 
57:     // Test cleanup
58:     console.log("\nTesting image cleanup (dry run)...");
59:     await imageHandler.cleanup(true);
60: 
61:     // Test error handling
62:     console.log("\nTesting error handling...");
63:     const invalidResult = await imageHandler.processImage(
64:       "https://invalid-url.com/image.jpg",
65:       TEST_CASES[0].groupId,
66:       TEST_CASES[0].productId
67:     );
68: 
69:     console.log("Error Handling Results:", {
70:       fallbackToOriginal: invalidResult.originalUrl === "https://invalid-url.com/image.jpg",
71:       updated: invalidResult.updated,
72:     });
73:   } catch (error) {
74:     console.error("Test failed:", error);
75:     process.exit(1);
76:   }
77: }
78: 
79: async function runTests() {
80:   console.log("Starting Image Handler tests...");
81: 
82:   try {
83:     await testImageProcessing();
84:     console.log("\nAll Image Handler tests completed successfully!");
85:   } catch (error) {
86:     console.error("\nTests failed:", error);
87:     process.exit(1);
88:   }
89: }
90: 
91: // Execute the tests
92: runTests().catch(console.error);
</file>

<file path="src/test/testSync.ts">
 1: import axios, {isAxiosError} from "axios";
 2: import {SyncOptions, SyncMetadata} from "../types";
 3: 
 4: const PROJECT_ID = "fftcg-sync-service";
 5: const REGION = "us-central1";
 6: const BASE_URL = `https://${REGION}-${PROJECT_ID}.cloudfunctions.net`;
 7: 
 8: async function runSyncTest(
 9:   endpoint: string,
10:   options: SyncOptions,
11:   description: string
12: ): Promise<SyncMetadata> {
13:   console.log(`\nTesting ${description}...`);
14: 
15:   try {
16:     const response = await axios.get<SyncMetadata>(`${BASE_URL}/${endpoint}`, {
17:       params: options,
18:     });
19:     return response.data;
20:   } catch (error) {
21:     if (isAxiosError(error)) {
22:       console.error(`${description} failed:`, error.response?.data || error.message);
23:       throw error;
24:     }
25:     throw error;
26:   }
27: }
28: 
29: async function testSync() {
30:   try {
31:     // Test manual card sync
32:     const cardSyncResult = await runSyncTest("testCardSync", {
33:       limit: 5,
34:       dryRun: true,
35:       groupId: "23783",
36:     }, "Card Sync");
37: 
38:     console.log("Card Sync Results:", JSON.stringify(cardSyncResult, null, 2));
39: 
40:     // Test manual price sync
41:     const priceSyncResult = await runSyncTest("testPriceSync", {
42:       groupId: "23783",
43:       dryRun: true,
44:       limit: 5,
45:     }, "Price Sync");
46: 
47:     console.log("Price Sync Results:", JSON.stringify(priceSyncResult, null, 2));
48: 
49:     // Test full sync (if needed)
50:     if (process.env.TEST_FULL_SYNC === "true") {
51:       console.log("\nTesting full sync...");
52: 
53:       const fullSyncResult = await runSyncTest("manualCardSync", {
54:         dryRun: true,
55:       }, "Full Sync");
56: 
57:       console.log("Full Sync Results:", JSON.stringify(fullSyncResult, null, 2));
58:     }
59:   } catch (error) {
60:     console.error("Test failed:", error);
61:     process.exit(1);
62:   }
63: }
64: 
65: // Execute the test
66: console.log("Starting sync tests...");
67: testSync().then(() => {
68:   console.log("\nAll sync tests completed successfully!");
69: }).catch(console.error);
</file>

<file path="src/test/validateSync.ts">
  1: import * as admin from "firebase-admin";
  2: import {Timestamp} from "firebase-admin/firestore";
  3: import {ServiceAccount} from "firebase-admin";
  4: import * as path from "path";
  5: import * as fs from "fs/promises";
  6: import {COLLECTION} from "../config/firebase";
  7: 
  8: interface ValidationResult {
  9:   collection: string;
 10:   documentsChecked: number;
 11:   documentsValid: number;
 12:   errors: string[];
 13:   details?: Record<string, any>;
 14: }
 15: 
 16: interface ValidationOptions {
 17:   limit?: number;
 18:   verbose?: boolean;
 19:   groupId?: string;
 20: }
 21: 
 22: async function initializeFirebase(): Promise<FirebaseFirestore.Firestore> {
 23:   try {
 24:     const serviceAccountPath = path.resolve(__dirname, "../../../service_account_key.json");
 25:     const serviceAccountData = await fs.readFile(serviceAccountPath, "utf8");
 26:     const serviceAccount = JSON.parse(serviceAccountData) as ServiceAccount;
 27: 
 28:     if (!admin.apps.length) {
 29:       admin.initializeApp({
 30:         credential: admin.credential.cert(serviceAccount),
 31:       });
 32:     }
 33: 
 34:     return admin.firestore();
 35:   } catch (error) {
 36:     console.error("Failed to initialize Firebase:", error);
 37:     throw error;
 38:   }
 39: }
 40: 
 41: async function validateCollection(
 42:   db: FirebaseFirestore.Firestore,
 43:   collectionName: string,
 44:   validator: (doc: FirebaseFirestore.DocumentData) => boolean,
 45:   options: ValidationOptions = {}
 46: ): Promise<ValidationResult> {
 47:   const result: ValidationResult = {
 48:     collection: collectionName,
 49:     documentsChecked: 0,
 50:     documentsValid: 0,
 51:     errors: [],
 52:     details: {},
 53:   };
 54: 
 55:   try {
 56:     let query = db.collection(collectionName)
 57:       .orderBy("lastUpdated", "desc");
 58: 
 59:     if (options.limit) {
 60:       query = query.limit(options.limit);
 61:     }
 62: 
 63:     if (options.groupId && (collectionName === COLLECTION.CARDS || collectionName === COLLECTION.PRICES)) {
 64:       query = query.where("groupId", "==", options.groupId);
 65:     }
 66: 
 67:     const snapshot = await query.get();
 68:     result.documentsChecked = snapshot.size;
 69: 
 70:     snapshot.forEach((doc) => {
 71:       const data = doc.data();
 72:       try {
 73:         if (validator(data)) {
 74:           result.documentsValid++;
 75:           if (options.verbose) {
 76:             result.details![doc.id] = data;
 77:           }
 78:         } else {
 79:           result.errors.push(`Document ${doc.id} failed validation`);
 80:         }
 81:       } catch (error) {
 82:         result.errors.push(`Error validating ${doc.id}: ${error}`);
 83:       }
 84:     });
 85:   } catch (error) {
 86:     result.errors.push(`Error accessing collection: ${error}`);
 87:   }
 88: 
 89:   return result;
 90: }
 91: 
 92: async function validateSync(options: ValidationOptions = {}) {
 93:   console.log("Starting sync validation...");
 94:   console.log("Options:", JSON.stringify(options, null, 2));
 95: 
 96:   try {
 97:     const db = await initializeFirebase();
 98: 
 99:     // Validate cards
100:     const cardResult = await validateCollection(db, COLLECTION.CARDS, (data) => {
101:       return (
102:         typeof data.productId === "number" &&
103:         typeof data.name === "string" &&
104:         typeof data.lastUpdated === "object" &&
105:         data.lastUpdated instanceof Timestamp
106:       );
107:     }, options);
108: 
109:     // Validate prices
110:     const priceResult = await validateCollection(db, COLLECTION.PRICES, (data) => {
111:       return (
112:         data.lastUpdated instanceof Timestamp &&
113:         (!data.normal || typeof data.normal.midPrice === "number") &&
114:         (!data.foil || typeof data.foil.midPrice === "number")
115:       );
116:     }, options);
117: 
118:     // Validate sync metadata
119:     const metadataResult = await validateCollection(db, COLLECTION.SYNC_METADATA, (data) => {
120:       return (
121:         data.lastSync instanceof Timestamp &&
122:         typeof data.status === "string" &&
123:         typeof data.cardCount === "number" &&
124:         Array.isArray(data.errors)
125:       );
126:     }, options);
127: 
128:     // Print results
129:     console.log("\nValidation Results:");
130:     [cardResult, priceResult, metadataResult].forEach((result) => {
131:       console.log(`\n${result.collection}:`);
132:       console.log(`Documents Checked: ${result.documentsChecked}`);
133:       console.log(`Valid Documents: ${result.documentsValid}`);
134:       if (result.errors.length > 0) {
135:         console.log("Errors:");
136:         result.errors.forEach((error) => console.log(`- ${error}`));
137:       }
138:       if (options.verbose && result.details) {
139:         console.log("\nDetails:");
140:         console.log(JSON.stringify(result.details, null, 2));
141:       }
142:     });
143:   } catch (error) {
144:     console.error("Validation failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Execute validation with command line arguments
150: const args = process.argv.slice(2);
151: const options: ValidationOptions = {
152:   limit: args.includes("--limit") ? parseInt(args[args.indexOf("--limit") + 1]) : undefined,
153:   verbose: args.includes("--verbose"),
154:   groupId: args.includes("--groupId") ? args[args.indexOf("--groupId") + 1] : undefined,
155: };
156: 
157: validateSync(options).then(() => {
158:   console.log("\nValidation completed!");
159: }).catch(console.error);
</file>

<file path="src/types/express.d.ts">
1: // / <reference types="express" />
2: import * as express from "express";
3: export = express;
</file>

<file path="src/types/index.ts">
  1: // functions/src/types/index.ts
  2: 
  3: export interface GenericError extends Error {
  4:   code?: string;
  5:   message: string;
  6:   stack?: string;
  7: }
  8: 
  9: export interface CardProduct {
 10:   productId: number;
 11:   name: string;
 12:   cleanName: string;
 13:   imageUrl: string;
 14:   storageImageUrl?: string; // Added for Firebase Storage URL
 15:   categoryId: number;
 16:   groupId: number;
 17:   url: string;
 18:   modifiedOn: string;
 19:   imageCount: number;
 20:   imageMetadata?: ImageMetadata; // Added for image metadata
 21:   extendedData: Array<{
 22:     name: string;
 23:     displayName: string;
 24:     value: string;
 25:   }>;
 26: }
 27: 
 28: export interface CardPrice {
 29:   productId: number;
 30:   lowPrice: number;
 31:   midPrice: number;
 32:   highPrice: number;
 33:   marketPrice: number | null;
 34:   directLowPrice: number | null;
 35:   subTypeName: "Normal" | "Foil";
 36: }
 37: 
 38: export interface SyncOptions {
 39:   dryRun?: boolean;
 40:   limit?: number;
 41:   groupId?: string;
 42:   productId?: number;
 43:   showAll?: boolean;
 44:   skipImages?: boolean; // Added to optionally skip image processing
 45: }
 46: 
 47: export interface SyncMetadata {
 48:   lastSync: Date;
 49:   status: "in_progress" | "success" | "failed" | "completed_with_errors";
 50:   cardCount: number;
 51:   type: "manual" | "scheduled";
 52:   groupsProcessed: number;
 53:   groupsUpdated: number;
 54:   errors: string[];
 55:   duration?: number;
 56:   imagesProcessed?: number; // Added for image tracking
 57:   imagesUpdated?: number; // Added for image tracking
 58: }
 59: 
 60: export type CacheType = "card" | "price" | "image";
 61: 
 62: export interface PriceData {
 63:   normal?: CardPrice;
 64:   foil?: CardPrice;
 65:   lastUpdated: Date;
 66: }
 67: 
 68: // New interfaces for image handling
 69: export interface ImageMetadata {
 70:   contentType: string;
 71:   size: number;
 72:   updated: Date;
 73:   hash: string;
 74:   originalUrl: string;
 75:   highResUrl: string;
 76:   groupId?: string;
 77:   productId?: number;
 78:   lastUpdated?: Date;
 79: }
 80: 
 81: export interface ImageProcessingResult {
 82:   url: string;
 83:   metadata: ImageMetadata;
 84:   updated: boolean;
 85: }
 86: 
 87: export interface ImageSyncStats {
 88:   processed: number;
 89:   updated: number;
 90:   failed: number;
 91:   skipped: number;
 92: }
 93: 
 94: // Update existing interfaces
 95: export interface LogData {
 96:   imageMetadata?: ImageMetadata;
 97:   imageSyncStats?: ImageSyncStats;
 98:   [key: string]: any;
 99: }
100: 
101: // Cache interfaces
102: export interface CacheOptions {
103:   max: number;
104:   ttl: number;
105: }
106: 
107: export interface CacheEntry<T> {
108:   data: T;
109:   timestamp: number;
110:   expires: number;
111: }
112: 
113: // Error types
114: export interface ImageProcessingError extends GenericError {
115:   productId: number;
116:   groupId: string;
117:   originalUrl: string;
118:   type: "download" | "upload" | "metadata" | "unknown";
119: }
120: 
121: export type GenericObject = Record<string, any>;
122: 
123: // Batch processing types
124: export interface BatchProcessingStats {
125:   total: number;
126:   processed: number;
127:   successful: number;
128:   failed: number;
129:   skipped: number;
130: }
131: 
132: export interface BatchOptions {
133:   batchSize?: number;
134:   delayBetweenBatches?: number;
135:   onBatchComplete?: (stats: BatchProcessingStats) => Promise<void>;
136:   skipImages?: boolean;
137:   retryFailedImages?: boolean;
138: }
139: 
140: // Enhanced logging types for image processing
141: export interface ImageLogEntry {
142:   timestamp: Date;
143:   level: "INFO" | "WARNING" | "ERROR";
144:   message: string;
145:   context?: string;
146:   metadata?: ImageMetadata;
147:   error?: ImageProcessingError;
148:   stats?: ImageSyncStats;
149: }
150: 
151: // Storage types
152: export interface StoragePaths {
153:   original: string;
154:   processed: string;
155: }
156: 
157: export interface StorageOptions {
158:   contentType: string;
159:   metadata?: Record<string, string>;
160:   cacheControl?: string;
161: }
162: 
163: // Progress tracking for image processing
164: export interface ImageProcessingProgress {
165:   total: number;
166:   current: number;
167:   updated: number;
168:   failed: number;
169:   startTime: number;
170:   estimatedTimeRemaining?: number;
171: }
</file>

<file path="src/types/node.d.ts">
1: // / <reference types="node" />
</file>

<file path="src/utils/batch.ts">
 1: import {logInfo} from "./logger";
 2: 
 3: export interface BatchProcessorOptions {
 4:   batchSize?: number;
 5:   delayBetweenBatches?: number;
 6:   onBatchComplete?: (processedCount: number, totalCount: number) => Promise<void>;
 7: }
 8: 
 9: export async function processBatch<TItem>(
10:   items: TItem[],
11:   processor: (batch: TItem[]) => Promise<void>,
12:   options: BatchProcessorOptions = {}
13: ): Promise<void> {
14:   const {
15:     batchSize = 500,
16:     delayBetweenBatches = 100,
17:     onBatchComplete,
18:   } = options;
19: 
20:   const totalBatches = Math.ceil(items.length / batchSize);
21:   let processedCount = 0;
22: 
23:   for (let i = 0; i < items.length; i += batchSize) {
24:     const batch = items.slice(i, i + batchSize);
25:     const batchNumber = Math.floor(i / batchSize) + 1;
26: 
27:     await processor(batch);
28:     processedCount += batch.length;
29: 
30:     if (onBatchComplete) {
31:       await onBatchComplete(processedCount, items.length);
32:     }
33: 
34:     logInfo(`Processed batch ${batchNumber}/${totalBatches} (${processedCount}/${items.length} items)`);
35: 
36:     if (i + batchSize < items.length) {
37:       await new Promise((resolve) => setTimeout(resolve, delayBetweenBatches));
38:     }
39:   }
40: }
</file>

<file path="src/utils/cache.ts">
 1: import LRUCache from "lru-cache";
 2: import {CacheType, CardProduct} from "../types";
 3: 
 4: const options = {
 5:   max: 500,
 6:   ttl: 1000 * 60 * 60, // 1 hour
 7: };
 8: 
 9: export const cardCache = new LRUCache<string, CardProduct>(options);
10: 
11: export const getCacheKey = (type: CacheType, id: number): string => {
12:   return `${type}:${id}`;
13: };
</file>

<file path="src/utils/error.ts">
 1: import {db, COLLECTION} from "../config/firebase";
 2: import {logError} from "./logger";
 3: 
 4: export interface ErrorReport {
 5:   timestamp: Date;
 6:   context: string;
 7:   error: string;
 8:   stackTrace?: string;
 9:   metadata?: Record<string, unknown>;
10:   severity: "ERROR" | "WARNING" | "CRITICAL";
11: }
12: 
13: export class DetailedError extends Error {
14:   constructor(
15:     message: string,
16:     public context: string,
17:     public metadata?: Record<string, unknown>,
18:     public severity: "ERROR" | "WARNING" | "CRITICAL" = "ERROR"
19:   ) {
20:     super(message);
21:     this.name = "DetailedError";
22:   }
23: }
24: 
25: export async function logDetailedError(
26:   error: Error,
27:   context: string,
28:   metadata?: Record<string, unknown>,
29:   severity: "ERROR" | "WARNING" | "CRITICAL" = "ERROR"
30: ): Promise<void> {
31:   const report: ErrorReport = {
32:     timestamp: new Date(),
33:     context,
34:     error: error.message,
35:     stackTrace: error.stack,
36:     metadata,
37:     severity,
38:   };
39: 
40:   // Log to Firestore
41:   await db.collection(COLLECTION.LOGS)
42:     .add(report);
43: 
44:   // Log using existing logger
45:   await logError(error, context);
46: }
</file>

<file path="src/utils/imageHandler.ts">
  1: // src/utils/imageHandler.ts
  2: import axios, {AxiosError} from "axios";
  3: import {storage, STORAGE, COLLECTION, db} from "../config/firebase";
  4: import {logError, logInfo, logWarning} from "./logger";
  5: import LRUCache from "lru-cache";
  6: import * as crypto from "crypto";
  7: import {GenericError} from "../types";
  8: 
  9: interface ImageMetadata {
 10:   contentType: string;
 11:   size: number;
 12:   updated: Date;
 13:   hash: string;
 14:   originalUrl: string;
 15:   highResUrl: string;
 16:   originalSize?: number;
 17:   highResSize?: number;
 18: }
 19: 
 20: interface ImageProcessingResult {
 21:   originalUrl: string;
 22:   highResUrl: string;
 23:   metadata: ImageMetadata;
 24:   updated: boolean;
 25: }
 26: 
 27: const cacheOptions = {
 28:   max: 1000,
 29:   ttl: 1000 * 60 * 60, // 1 hour
 30: };
 31: 
 32: const imageMetadataCache = new LRUCache<string, ImageMetadata>(cacheOptions);
 33: const imageExistsCache = new LRUCache<string, boolean>(cacheOptions);
 34: 
 35: export class ImageHandler {
 36:   private bucket = storage.bucket(STORAGE.BUCKETS.CARD_IMAGES);
 37: 
 38:   private getHighResUrl(imageUrl: string): string {
 39:     return imageUrl.replace(/_200w\.jpg$/, "_400w.jpg");
 40:   }
 41: 
 42:   private getStoragePath(groupId: string, productId: number, isHighRes: boolean = false): string {
 43:     const suffix = isHighRes ? "_400w" : "_200w";
 44:     return `${STORAGE.PATHS.IMAGES}/${groupId}/${productId}${suffix}.jpg`;
 45:   }
 46: 
 47:   private async getImageHash(imageBuffer: Buffer): Promise<string> {
 48:     return crypto.createHash("md5").update(imageBuffer).digest("hex");
 49:   }
 50: 
 51:   private async downloadImage(url: string): Promise<Buffer> {
 52:     try {
 53:       await logInfo(`Attempting to download image from: ${url}`);
 54:       const response = await axios.get(url, {
 55:         responseType: "arraybuffer",
 56:         timeout: 30000,
 57:         headers: {
 58:           "Accept": "image/jpeg",
 59:           "User-Agent": "FFTCG-Sync-Service/1.0",
 60:         },
 61:       });
 62:       await logInfo(`Successfully downloaded image from: ${url}`);
 63:       return Buffer.from(response.data);
 64:     } catch (error) {
 65:       await logWarning(
 66:         `Failed to download image: ${error instanceof Error ? error.message : "Unknown error"}`,
 67:         {url, errorDetails: error instanceof Error ? error.message : "Unknown error"}
 68:       );
 69:       throw error;
 70:     }
 71:   }
 72: 
 73:   private async shouldUpdateImage(
 74:     groupId: string,
 75:     productId: number,
 76:     imageBuffer: Buffer,
 77:     isHighRes: boolean
 78:   ): Promise<boolean> {
 79:     const storagePath = this.getStoragePath(groupId, productId, isHighRes);
 80:     const cacheKey = `${groupId}:${productId}:${isHighRes ? "high" : "original"}`;
 81: 
 82:     try {
 83:       const cachedMetadata = imageMetadataCache.get(cacheKey);
 84:       if (cachedMetadata) {
 85:         const newHash = await this.getImageHash(imageBuffer);
 86:         return cachedMetadata.hash !== newHash;
 87:       }
 88: 
 89:       const exists = imageExistsCache.get(cacheKey);
 90:       if (exists === false) return true;
 91: 
 92:       const [fileExists] = await this.bucket.file(storagePath).exists();
 93:       imageExistsCache.set(cacheKey, fileExists);
 94: 
 95:       if (!fileExists) return true;
 96: 
 97:       const [metadata] = await this.bucket.file(storagePath).getMetadata();
 98:       const currentHash = metadata.metadata?.hash;
 99:       const newHash = await this.getImageHash(imageBuffer);
100: 
101:       return currentHash !== newHash;
102:     } catch (error) {
103:       const genericError: GenericError = {
104:         message: error instanceof Error ? error.message : "Unknown error",
105:         name: error instanceof Error ? error.name : "UnknownError",
106:         code: error instanceof AxiosError ? error.code : undefined,
107:         stack: error instanceof Error ? error.stack : undefined,
108:       };
109:       await logError(genericError, "shouldUpdateImage");
110:       return true;
111:     }
112:   }
113: 
114:   private async saveMetadata(
115:     groupId: string,
116:     productId: number,
117:     metadata: ImageMetadata
118:   ): Promise<void> {
119:     const docRef = db.collection(COLLECTION.IMAGE_METADATA)
120:       .doc(`${groupId}_${productId}`);
121: 
122:     await docRef.set({
123:       ...metadata,
124:       groupId,
125:       productId,
126:       lastUpdated: new Date(),
127:     }, {merge: true});
128: 
129:     const cacheKey = `${groupId}:${productId}`;
130:     imageMetadataCache.set(cacheKey, metadata);
131:   }
132: 
133:   async processImage(
134:     imageUrl: string,
135:     groupId: string,
136:     productId: number
137:   ): Promise<ImageProcessingResult> {
138:     try {
139:       await logInfo(`Processing image for product ${productId} in group ${groupId}`, {
140:         originalUrl: imageUrl,
141:         highResUrl: this.getHighResUrl(imageUrl),
142:       });
143: 
144:       const highResUrl = this.getHighResUrl(imageUrl);
145:       let originalBuffer: Buffer | null = null;
146:       let highResBuffer: Buffer | null = null;
147:       let updated = false;
148: 
149:       try {
150:         originalBuffer = await this.downloadImage(imageUrl);
151:       } catch (error) {
152:         await logWarning(`Original image download failed for ${productId}`, {
153:           url: imageUrl,
154:           error: error instanceof Error ? error.message : "Unknown error",
155:         });
156:       }
157: 
158:       try {
159:         highResBuffer = await this.downloadImage(highResUrl);
160:       } catch (error) {
161:         await logWarning(`High-res image download failed for ${productId}`, {
162:           url: highResUrl,
163:           error: error instanceof Error ? error.message : "Unknown error",
164:         });
165:       }
166: 
167:       if (!originalBuffer && !highResBuffer) {
168:         throw new Error(`Failed to download both image versions for product ${productId}`);
169:       }
170: 
171:       const metadata: ImageMetadata = {
172:         contentType: "image/jpeg",
173:         size: 0,
174:         updated: new Date(),
175:         hash: "",
176:         originalUrl: imageUrl,
177:         highResUrl: highResUrl,
178:         originalSize: originalBuffer?.length,
179:         highResSize: highResBuffer?.length,
180:       };
181: 
182:       if (originalBuffer) {
183:         const originalNeedsUpdate = await this.shouldUpdateImage(groupId, productId, originalBuffer, false);
184:         if (originalNeedsUpdate) {
185:           const originalPath = this.getStoragePath(groupId, productId, false);
186:           const originalHash = await this.getImageHash(originalBuffer);
187:           await this.bucket.file(originalPath).save(originalBuffer, {
188:             metadata: {
189:               contentType: "image/jpeg",
190:               metadata: {
191:                 hash: originalHash,
192:                 type: "original",
193:                 updatedAt: new Date().toISOString(),
194:               },
195:             },
196:           });
197:           updated = true;
198:           metadata.hash = originalHash;
199:           metadata.size = originalBuffer.length;
200:         }
201:       }
202: 
203:       if (highResBuffer) {
204:         const highResNeedsUpdate = await this.shouldUpdateImage(groupId, productId, highResBuffer, true);
205:         if (highResNeedsUpdate) {
206:           const highResPath = this.getStoragePath(groupId, productId, true);
207:           const highResHash = await this.getImageHash(highResBuffer);
208:           await this.bucket.file(highResPath).save(highResBuffer, {
209:             metadata: {
210:               contentType: "image/jpeg",
211:               metadata: {
212:                 hash: highResHash,
213:                 type: "highres",
214:                 updatedAt: new Date().toISOString(),
215:               },
216:             },
217:           });
218:           updated = true;
219:         }
220:       }
221: 
222:       await this.saveMetadata(groupId, productId, metadata);
223: 
224:       const [originalStorageUrl] = await this.bucket.file(
225:         this.getStoragePath(groupId, productId, false)
226:       ).getSignedUrl({
227:         action: "read",
228:         expires: "03-01-2500",
229:       });
230: 
231:       const [highResStorageUrl] = await this.bucket.file(
232:         this.getStoragePath(groupId, productId, true)
233:       ).getSignedUrl({
234:         action: "read",
235:         expires: "03-01-2500",
236:       });
237: 
238:       return {
239:         originalUrl: originalStorageUrl,
240:         highResUrl: highResStorageUrl,
241:         metadata,
242:         updated,
243:       };
244:     } catch (error) {
245:       const genericError: GenericError = {
246:         message: error instanceof Error ? error.message : "Unknown error",
247:         name: error instanceof Error ? error.name : "UnknownError",
248:         code: error instanceof AxiosError ? error.code : undefined,
249:         stack: error instanceof Error ? error.stack : undefined,
250:       };
251:       await logError({
252:         ...genericError,
253:         metadata: {
254:           productId,
255:           groupId,
256:           originalUrl: imageUrl,
257:           highResUrl: this.getHighResUrl(imageUrl),
258:         },
259:       }, "processImage");
260:       return {
261:         originalUrl: imageUrl,
262:         highResUrl: this.getHighResUrl(imageUrl),
263:         metadata: {
264:           contentType: "image/jpeg",
265:           size: 0,
266:           updated: new Date(),
267:           hash: "",
268:           originalUrl: imageUrl,
269:           highResUrl: this.getHighResUrl(imageUrl),
270:         },
271:         updated: false,
272:       };
273:     }
274:   }
275: 
276:   async cleanup(dryRun = true): Promise<void> {
277:     try {
278:       const [files] = await this.bucket.getFiles({
279:         prefix: STORAGE.PATHS.IMAGES,
280:       });
281: 
282:       const activeImages = await db.collection(COLLECTION.IMAGE_METADATA).get();
283:       const activeImagePaths = new Set([
284:         ...activeImages.docs.map((doc) => this.getStoragePath(
285:           doc.data().groupId,
286:           doc.data().productId,
287:           false
288:         )),
289:         ...activeImages.docs.map((doc) => this.getStoragePath(
290:           doc.data().groupId,
291:           doc.data().productId,
292:           true
293:         )),
294:       ]);
295: 
296:       let deletedCount = 0;
297:       for (const file of files) {
298:         if (!activeImagePaths.has(file.name)) {
299:           if (!dryRun) {
300:             await file.delete();
301:           }
302:           deletedCount++;
303:         }
304:       }
305: 
306:       await logInfo(`Cleanup complete. ${deletedCount} files ${dryRun ? "would be" : "were"} deleted.`);
307:     } catch (error) {
308:       const genericError: GenericError = {
309:         message: error instanceof Error ? error.message : "Unknown error",
310:         name: error instanceof Error ? error.name : "UnknownError",
311:         code: error instanceof AxiosError ? error.code : undefined,
312:         stack: error instanceof Error ? error.stack : undefined,
313:       };
314:       await logError(genericError, "cleanup");
315:     }
316:   }
317: }
</file>

<file path="src/utils/logger.ts">
 1: import * as functions from "firebase-functions";
 2: import {db, COLLECTION} from "../config/firebase";
 3: import {GenericError, LogData, GenericObject} from "../types";
 4: 
 5: export const logger = functions.logger;
 6: 
 7: interface LogEntry {
 8:   timestamp: Date;
 9:   level: "INFO" | "WARNING" | "ERROR";
10:   message: string;
11:   context?: string;
12:   data?: Record<string, unknown>;
13: }
14: 
15: async function saveLogEntry(entry: LogEntry): Promise<void> {
16:   // Remove undefined values and convert data to a plain object
17:   const cleanEntry = {
18:     timestamp: entry.timestamp,
19:     level: entry.level,
20:     message: entry.message,
21:     ...(entry.context && {context: entry.context}),
22:     ...(entry.data && {data: JSON.parse(JSON.stringify(entry.data))}),
23:   };
24: 
25:   await db.collection(COLLECTION.LOGS).add(cleanEntry);
26: }
27: 
28: export const logError = async (error: GenericError | GenericObject, context: string) => {
29:   const entry: LogEntry = {
30:     timestamp: new Date(),
31:     level: "ERROR",
32:     message: error.message || "Unknown error",
33:     context,
34:     data: {
35:       stack: error.stack || null,
36:       code: error.code || null,
37:     },
38:   };
39: 
40:   logger.error(entry.message, entry.data);
41:   await saveLogEntry(entry);
42: };
43: 
44: export const logInfo = async (message: string, data?: LogData) => {
45:   const entry: LogEntry = {
46:     timestamp: new Date(),
47:     level: "INFO",
48:     message,
49:     ...(data && {data: JSON.parse(JSON.stringify(data))}),
50:   };
51: 
52:   logger.info(message, data);
53:   await saveLogEntry(entry);
54: };
55: 
56: export const logWarning = async (message: string, data?: LogData) => {
57:   const entry: LogEntry = {
58:     timestamp: new Date(),
59:     level: "WARNING",
60:     message,
61:     ...(data && {data: JSON.parse(JSON.stringify(data))}),
62:   };
63: 
64:   logger.warn(message, data);
65:   await saveLogEntry(entry);
66: };
</file>

<file path="src/utils/progress.ts">
 1: // src/utils/progress.ts
 2: 
 3: import {logInfo} from "./logger";
 4: 
 5: export interface ProgressStats {
 6:   current: number;
 7:   total: number;
 8:   percent: number;
 9:   elapsed: number;
10:   rate: number;
11:   remaining: number;
12:   eta: number;
13: }
14: 
15: export class EnhancedProgressTracker {
16:   private startTime: number;
17:   private current: number;
18:   private estimates: number[] = [];
19:   private lastUpdate: number;
20:   private updateInterval: number;
21: 
22:   constructor(
23:     private total: number,
24:     private description: string,
25:     options: { updateInterval?: number } = {}
26:   ) {
27:     this.startTime = Date.now();
28:     this.current = 0;
29:     this.lastUpdate = Date.now();
30:     this.updateInterval = options.updateInterval || 1000; // Default 1 second
31:   }
32: 
33:   private calculateStats(): ProgressStats {
34:     const now = Date.now();
35:     const elapsed = (now - this.startTime) / 1000;
36:     const percent = (this.current / this.total) * 100;
37:     const rate = this.current / elapsed;
38:     const remaining = this.total - this.current;
39:     const eta = remaining / rate;
40: 
41:     return {
42:       current: this.current,
43:       total: this.total,
44:       percent,
45:       elapsed,
46:       rate,
47:       remaining,
48:       eta,
49:     };
50:   }
51: 
52:   update(amount = 1): void {
53:     const now = Date.now();
54:     this.current += amount;
55: 
56:     // Only update log if enough time has passed
57:     if (now - this.lastUpdate >= this.updateInterval) {
58:       const stats = this.calculateStats();
59:       this.estimates.push(stats.eta);
60: 
61:       // Keep only last 10 estimates for averaging
62:       if (this.estimates.length > 10) {
63:         this.estimates.shift();
64:       }
65: 
66:       const avgEta = this.estimates.reduce((a, b) => a + b, 0) / this.estimates.length;
67: 
68:       logInfo(
69:         `${this.description}: ${stats.current}/${stats.total} ` +
70:         `(${stats.percent.toFixed(1)}%) - ${stats.remaining} remaining - ` +
71:         `ETA: ${avgEta.toFixed(1)}s - Rate: ${stats.rate.toFixed(1)}/s`
72:       );
73: 
74:       this.lastUpdate = now;
75:     }
76:   }
77: 
78:   getProgress(): ProgressStats {
79:     return this.calculateStats();
80:   }
81: }
</file>

<file path="src/utils/request.ts">
 1: import axios, {AxiosError} from "axios";
 2: import {logWarning} from "./logger";
 3: 
 4: export const MAX_RETRIES = 3;
 5: export const BASE_DELAY = 1000; // 1 second
 6: 
 7: export interface RequestOptions {
 8:   retryCount?: number;
 9:   customDelay?: number;
10:   metadata?: Record<string, unknown>;
11: }
12: 
13: export class RequestError extends Error {
14:   constructor(
15:     message: string,
16:     public originalError: Error,
17:     public context: string,
18:     public metadata?: Record<string, unknown>
19:   ) {
20:     super(message);
21:     this.name = "RequestError";
22:   }
23: }
24: 
25: export async function makeRequest<T>(
26:   endpoint: string,
27:   baseUrl: string,
28:   options: RequestOptions = {}
29: ): Promise<T> {
30:   const {retryCount = 0, customDelay = BASE_DELAY} = options;
31: 
32:   try {
33:     await new Promise((resolve) => setTimeout(resolve, customDelay));
34:     const url = `${baseUrl}/${endpoint}`;
35:     const response = await axios.get<T>(url, {
36:       timeout: 30000, // 30 seconds timeout
37:       headers: {
38:         "Accept": "application/json",
39:         "User-Agent": "FFTCG-Sync-Service/1.0",
40:       },
41:     });
42: 
43:     return response.data;
44:   } catch (error) {
45:     if (retryCount < MAX_RETRIES - 1 && error instanceof AxiosError) {
46:       const delay = Math.pow(2, retryCount) * BASE_DELAY;
47:       await logWarning(`Request failed, retrying in ${delay}ms...`, {
48:         url: `${baseUrl}/${endpoint}`,
49:         attempt: retryCount + 1,
50:         maxRetries: MAX_RETRIES,
51:         error: error.message,
52:         ...options.metadata,
53:       });
54: 
55:       return makeRequest<T>(endpoint, baseUrl, {
56:         ...options,
57:         retryCount: retryCount + 1,
58:         customDelay: delay,
59:       });
60:     }
61: 
62:     throw new RequestError(
63:       `Request failed after ${retryCount + 1} attempts`,
64:       error as Error,
65:       endpoint,
66:       options.metadata
67:     );
68:   }
69: }
</file>

<file path="src/utils/syncLogger.ts">
  1: interface CardDetails {
  2:   id: number;
  3:   name: string;
  4:   groupId: string;
  5:   normalPrice?: number;
  6:   foilPrice?: number;
  7:   rawPrices: Array<{
  8:     type: "Normal" | "Foil";
  9:     price: number;
 10:     groupId: string;
 11:   }>;
 12:   imageUrl?: string;
 13:   storageImageUrl?: string;
 14: }
 15: 
 16: interface SyncLoggerOptions {
 17:   type: "manual" | "scheduled" | "both";
 18:   limit?: number;
 19:   dryRun?: boolean;
 20:   groupId?: string;
 21:   batchSize?: number;
 22: }
 23: 
 24: interface SyncResults {
 25:   success: number;
 26:   failures: number;
 27:   groupId?: string;
 28:   type: "Manual" | "Scheduled";
 29:   imagesProcessed?: number;
 30:   imagesUpdated?: number;
 31: }
 32: 
 33: export class SyncLogger {
 34:   private startTime: number;
 35:   private cards: CardDetails[] = [];
 36:   private groups: Map<string, { products: number; prices: number }> = new Map();
 37: 
 38:   constructor(private options: SyncLoggerOptions) {
 39:     this.startTime = Date.now();
 40:   }
 41: 
 42:   async start(): Promise<void> {
 43:     console.log("\nStarting sync test...");
 44:     console.log(`Type: ${this.options.type}`);
 45:     if (this.options.limit) console.log(`Limit: ${this.options.limit} cards`);
 46:     console.log(`Dry Run: ${this.options.dryRun ? "true" : "false"}`);
 47:     console.log("\n=== Fetching Raw Data ===");
 48:   }
 49: 
 50:   async logGroupFound(totalGroups: number): Promise<void> {
 51:     console.log(`Found ${totalGroups} groups`);
 52:   }
 53: 
 54:   async logGroupDetails(groupId: string, products: number, prices: number): Promise<void> {
 55:     this.groups.set(groupId, {products, prices});
 56:     console.log(`Group ${groupId} has ${products} products and ${prices} prices`);
 57:   }
 58: 
 59:   async logCardDetails(details: CardDetails): Promise<void> {
 60:     this.cards.push(details);
 61:     if (this.cards.length === 1) {
 62:       console.log("\n=== Card Details ===");
 63:     }
 64: 
 65:     console.log(`Card: ${details.name} (${details.groupId || "UNKNOWN"})`);
 66:     console.log(`- ID: ${details.id}`);
 67:     console.log(`- Group ID: ${details.groupId || "UNKNOWN"}`);
 68: 
 69:     if (details.rawPrices.length > 0) {
 70:       console.log("- Raw Prices:");
 71:       details.rawPrices.forEach((price) => {
 72:         console.log(`  > ${price.type}: $${price.price.toFixed(2)} (Group: ${price.groupId})`);
 73:       });
 74:     }
 75: 
 76:     if (details.imageUrl) {
 77:       console.log(`- Image URL: ${details.imageUrl}`);
 78:       if (details.storageImageUrl) {
 79:         console.log(`- Storage URL: ${details.storageImageUrl}`);
 80:       }
 81:     }
 82: 
 83:     console.log(`- Normal Price: $${details.normalPrice?.toFixed(2) || "0.00"}`);
 84:     console.log(`- Foil Price: $${details.foilPrice?.toFixed(2) || "0.00"}`);
 85:     console.log("---");
 86:   }
 87: 
 88:   async logManualSyncStart(): Promise<void> {
 89:     console.log("\n=== Testing Manual Sync ===");
 90:     if (this.options.groupId) console.log(`Filtering for groups: ${this.options.groupId}`);
 91:     if (this.options.dryRun) console.log("DRY RUN MODE - No data will be modified");
 92:     if (this.options.limit) console.log(`Processing limited to ${this.options.limit} cards`);
 93:     if (this.options.batchSize) console.log(`Batch size: ${this.options.batchSize}`);
 94:     console.log();
 95:   }
 96: 
 97:   async logScheduledSyncStart(): Promise<void> {
 98:     console.log("\n=== Testing Scheduled Sync ===");
 99:   }
100: 
101:   async logSyncProgress(message: string): Promise<void> {
102:     console.log(message);
103:   }
104: 
105:   async logSyncResults(results: SyncResults): Promise<void> {
106:     const duration = (Date.now() - this.startTime) / 1000;
107: 
108:     console.log(`\n${results.type} Sync Results:`);
109:     console.log(`- Success: ${results.success}`);
110:     console.log(`- Failures: ${results.failures}`);
111:     console.log(`- Duration: ${duration.toFixed(1)} seconds`);
112:     if (results.groupId) console.log(`- Group ID: ${results.groupId}`);
113:     if (results.imagesProcessed) console.log(`- Images Processed: ${results.imagesProcessed}`);
114:     if (results.imagesUpdated) console.log(`- Images Updated: ${results.imagesUpdated}`);
115:   }
116: 
117:   async finish(): Promise<void> {
118:     console.log("\nTest completed!");
119:   }
120: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "extends": "./tsconfig.json",
3:   "include": [
4:     ".eslintrc.js",
5:     ".eslintrc.fix.js",
6:     ".eslintrc.base.cjs"
7:   ]
8: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "noImplicitReturns": true,
 5:     "noUnusedLocals": true,
 6:     "outDir": "lib",
 7:     "sourceMap": true,
 8:     "strict": true,
 9:     "target": "es2017",
10:     "esModuleInterop": true,
11:     "skipLibCheck": true,
12:     "typeRoots": [
13:       "./node_modules/@types",
14:       "./src/types"
15:     ],
16:     "types": ["node", "express"],
17:     "baseUrl": "./src"
18:   },
19:   "compileOnSave": true,
20:   "include": [
21:     "src/**/*",
22:     ".eslintrc.js",
23:     ".eslintrc.fix.js",
24:     ".eslintrc.base.cjs"
25:   ],
26:   "exclude": [
27:     "node_modules",
28:     "lib"
29:   ]
30: }
</file>

</repository_files>
