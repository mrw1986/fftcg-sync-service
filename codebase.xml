This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-05T06:25:10.667Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
.firebaserc
.gitignore
.npmrc
.prettierrc
.repomixignore
firebase.json
firestore.indexes.json
firestore.rules
package.json
repomix.config.json
src/config/environment.ts
src/config/firebase.ts
src/config/r2.ts
src/index.ts
src/scripts/cleanup.ts
src/scripts/prodSync.ts
src/scripts/setenv.ts
src/scripts/syncAll.ts
src/scripts/syncCards.ts
src/scripts/syncPrices.ts
src/scripts/testSync.ts
src/services/cardSync.ts
src/services/priceSync.ts
src/services/storageService.ts
src/types/index.ts
src/utils/api.ts
src/utils/cache.ts
src/utils/logger.ts
src/utils/rateLimiter.ts
src/utils/retention.ts
src/utils/retry.ts
src/utils/timeout.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     sourceType: "module",
19:   },
20:   ignorePatterns: [
21:     "/lib/**/*",
22:     "/generated/**/*",
23:     "*.js", // Add this line to ignore JS files
24:   ],
25:   plugins: ["@typescript-eslint", "import"],
26:   rules: {
27:     quotes: ["error", "double"],
28:     "import/no-unresolved": 0,
29:     indent: ["error", 2],
30:     "linebreak-style": 0, // Disable linebreak-style checks
31:     "object-curly-spacing": ["error", "always"],
32:     "max-len": ["error", { code: 120 }],
33:     "@typescript-eslint/no-explicit-any": "warn",
34:     "require-jsdoc": 0,
35:     "valid-jsdoc": 0,
36:     "@typescript-eslint/no-var-requires": 0,
37:     camelcase: 0,
38:   },
39: };
</file>

<file path=".firebaserc">
1: {
2:   "projects": {
3:     "default": "fftcg-sync-service"
4:   }
5: }
</file>

<file path=".gitignore">
 1: # Dependencies
 2: node_modules/
 3: 
 4: # Build output
 5: lib/
 6: dist/
 7: 
 8: # Environment variables
 9: .env
10: .env.local
11: .env.*.local
12: 
13: # Service account keys
14: service_account_key.json
15: *-service-account.json
16: 
17: # Firebase
18: .firebase/
19: firebase-debug.log
20: firebase-debug.*.log
21: 
22: # IDE
23: .vscode/
24: .idea/
25: 
26: # Logs
27: *.log
</file>

<file path=".npmrc">
1: //us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/:_authToken=${NPM_TOKEN}
2: @google-cloud:registry=https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/
</file>

<file path=".prettierrc">
1: {
2:   "singleQuote": false,
3:   "trailingComma": "es5",
4:   "bracketSpacing": true,
5:   "semi": true,
6:   "printWidth": 120,
7:   "tabWidth": 2,
8:   "endOfLine": "auto"
9: }
</file>

<file path=".repomixignore">
1: lib/**
2: !*/
3: !.gitignore
4: service_account_key.json
5: !src/**
</file>

<file path="firebase.json">
 1: {
 2:   "functions": {
 3:     "source": ".",
 4:     "codebase": "default",
 5:     "runtime": "nodejs18",
 6:     "ignore": [
 7:       "node_modules",
 8:       ".git",
 9:       "firebase-debug.log",
10:       "firebase-debug.*.log",
11:       "*.local"
12:     ],
13:     "predeploy": [
14:       "npm run lint",
15:       "npm run build"
16:     ]
17:   },
18:   "firestore": {
19:     "rules": "firestore.rules",
20:     "indexes": "firestore.indexes.json"
21:   },
22:   "emulators": {
23:     "functions": {
24:       "port": 5001
25:     },
26:     "firestore": {
27:       "port": 8080
28:     },
29:     "ui": {
30:       "enabled": true
31:     },
32:     "singleProjectMode": true
33:   }
34: }
</file>

<file path="firestore.indexes.json">
 1: {
 2:   "indexes": [],
 3:   "fieldOverrides": [
 4:     {
 5:       "collectionGroup": "cards",
 6:       "fieldPath": "imageMetadata",
 7:       "indexes": []
 8:     },
 9:     {
10:       "collectionGroup": "cards",
11:       "fieldPath": "extendedData",
12:       "indexes": []
13:     },
14:     {
15:       "collectionGroup": "cards",
16:       "fieldPath": "lastUpdated",
17:       "indexes": []
18:     },
19:     {
20:       "collectionGroup": "prices",
21:       "fieldPath": "lastUpdated",
22:       "indexes": []
23:     },
24:     {
25:       "collectionGroup": "historicalPrices",
26:       "fieldPath": "lastUpdated",
27:       "indexes": []
28:     }
29:   ]
30: }
</file>

<file path="firestore.rules">
1: rules_version = '2';
2: service cloud.firestore {
3:   match /databases/{database}/documents {
4:     match /{document=**} {
5:       allow read, write: if false;
6:     }
7:   }
8: }
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "lint": "eslint --ext .js,.ts .",
 5:     "lint:fix": "eslint --ext .js,.ts . --fix",
 6:     "build": "rimraf lib && tsc",
 7:     "build:watch": "tsc --watch",
 8:     "serve": "npm run build && firebase emulators:start --only functions,firestore",
 9:     "shell": "npm run build && firebase functions:shell",
10:     "start": "npm run shell",
11:     "deploy": "firebase deploy --only functions",
12:     "logs": "firebase functions:log"
13:   },
14:   "engines": {
15:     "node": "18"
16:   },
17:   "main": "lib/index.js",
18:   "dependencies": {
19:     "@aws-sdk/client-s3": "^3.485.0",
20:     "@aws-sdk/s3-request-presigner": "^3.485.0",
21:     "axios": "^1.7.7",
22:     "cors": "^2.8.5",
23:     "dotenv": "^16.4.7",
24:     "express": "^4.18.2",
25:     "firebase-admin": "^12.0.0",
26:     "firebase-functions": "^6.2.0"
27:   },
28:   "devDependencies": {
29:     "@types/cors": "^2.8.17",
30:     "@types/express": "^4.17.21",
31:     "@typescript-eslint/eslint-plugin": "^5.12.0",
32:     "@typescript-eslint/parser": "^5.12.0",
33:     "eslint": "^8.9.0",
34:     "eslint-config-google": "^0.14.0",
35:     "eslint-plugin-import": "^2.25.4",
36:     "firebase-functions-test": "^3.1.0",
37:     "rimraf": "^5.0.0",
38:     "typescript": "^4.9.0"
39:   },
40:   "private": true,
41:   "publishConfig": {
42:     "registry": "https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/"
43:   }
44: }
</file>

<file path="repomix.config.json">
 1: {
 2:   "output": {
 3:     "filePath": "C:\\VSCode\\fftcg-sync-service\\codebase.xml",
 4:     "style": "xml",
 5:     "removeComments": false,
 6:     "removeEmptyLines": false,
 7:     "topFilesLength": 5,
 8:     "showLineNumbers": true,
 9:     "copyToClipboard": false
10:   },
11:   "include": [],
12:   "ignore": {
13:     "useGitignore": false,
14:     "useDefaultPatterns": true,
15:     "customPatterns": []
16:   },
17:   "security": {
18:     "enableSecurityCheck": true
19:   }
20: }
</file>

<file path="src/config/environment.ts">
 1: // src/config/environment.ts
 2: import * as functions from "firebase-functions";
 3: import * as dotenv from "dotenv";
 4: 
 5: // Load .env file in development
 6: if (process.env.NODE_ENV !== "production") {
 7:   dotenv.config();
 8: }
 9: 
10: // Helper function to get config value
11: function getConfigValue(key: string): string {
12:   if (process.env.NODE_ENV === "production") {
13:     const config = functions.config();
14:     return config.r2?.[key.toLowerCase().replace("r2_", "")] || "";
15:   }
16:   return process.env[key] || "";
17: }
18: 
19: export const environment = {
20:   nodeEnv: process.env.NODE_ENV || "development",
21:   isLocal: process.env.NODE_ENV !== "production",
22:   r2: {
23:     accountId: getConfigValue("R2_ACCOUNT_ID"),
24:     accessKeyId: getConfigValue("R2_ACCESS_KEY_ID"),
25:     secretAccessKey: getConfigValue("R2_SECRET_ACCESS_KEY"),
26:     bucketName: getConfigValue("R2_BUCKET_NAME"),
27:     storagePath: getConfigValue("R2_STORAGE_PATH"),
28:     customDomain: getConfigValue("R2_CUSTOM_DOMAIN"),
29:   } as { [key: string]: string },
30: };
31: 
32: // Validate required environment variables
33: if (!environment.isLocal) {
34:   const required = ["R2_ACCOUNT_ID", "R2_ACCESS_KEY_ID", "R2_SECRET_ACCESS_KEY", "R2_BUCKET_NAME"];
35:   const missing = required.filter((key) => !(environment.r2[key.toLowerCase()] as string));
36:   if (missing.length) {
37:     throw new Error(`Missing required environment variables: ${missing.join(", ")}`);
38:   }
39: }
</file>

<file path="src/config/firebase.ts">
 1: // src/config/firebase.ts
 2: import * as admin from "firebase-admin";
 3: 
 4: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 5: const db = admin.firestore(app);
 6: 
 7: // Enable ignoreUndefinedProperties and other settings
 8: db.settings({
 9:   ignoreUndefinedProperties: true,
10:   timestampsInSnapshots: true,
11: });
12: 
13: export { db };
14: 
15: export const COLLECTION = {
16:   CARDS: "cards",
17:   PRICES: "prices",
18:   SYNC_METADATA: "syncMetadata",
19:   LOGS: "logs",
20:   CARD_HASHES: "cardHashes",
21:   PRICE_HASHES: "priceHashes",
22:   IMAGE_METADATA: "imageMetadata",
23:   HISTORICAL_PRICES: "historicalPrices",
24:   CARD_DELTAS: "cardDeltas",
25:   PRICE_DELTAS: "priceDeltas",
26: } as const;
27: 
28: export const BASE_URL = "https://tcgcsv.com/tcgplayer";
29: export const FFTCG_CATEGORY_ID = "24";
30: 
31: export const runtimeOpts = {
32:   timeoutSeconds: 540,
33:   memory: "1GiB",
34: } as const;
</file>

<file path="src/config/r2.ts">
 1: // src/config/r2.ts
 2: 
 3: import * as dotenv from "dotenv";
 4: dotenv.config();
 5: 
 6: export const R2_CONFIG = {
 7:   ACCOUNT_ID: process.env.R2_ACCOUNT_ID || "",
 8:   ACCESS_KEY_ID: process.env.R2_ACCESS_KEY_ID || "",
 9:   SECRET_ACCESS_KEY: process.env.R2_SECRET_ACCESS_KEY || "",
10:   BUCKET_NAME: process.env.R2_BUCKET_NAME || "",
11:   STORAGE_PATH: process.env.R2_STORAGE_PATH || "",
12:   CUSTOM_DOMAIN: process.env.R2_CUSTOM_DOMAIN || "",
13: } as const;
14: 
15: if (!R2_CONFIG.ACCOUNT_ID) {
16:   console.warn("Missing R2_ACCOUNT_ID in .env file");
17: }
18: if (!R2_CONFIG.ACCESS_KEY_ID) {
19:   console.warn("Missing R2_ACCESS_KEY_ID in .env file");
20: }
21: if (!R2_CONFIG.SECRET_ACCESS_KEY) {
22:   console.warn("Missing R2_SECRET_ACCESS_KEY in .env file");
23: }
24: if (!R2_CONFIG.BUCKET_NAME) {
25:   console.warn("Missing R2_BUCKET_NAME in .env file");
26: }
27: if (!R2_CONFIG.STORAGE_PATH) {
28:   console.warn("Missing R2_STORAGE_PATH in .env file");
29: }
30: if (!R2_CONFIG.CUSTOM_DOMAIN) {
31:   console.warn("Missing R2_CUSTOM_DOMAIN in .env file");
32: }
33: 
34: console.log("R2 Config:", R2_CONFIG);
</file>

<file path="src/index.ts">
  1: // src/index.ts
  2: import { onCall, HttpsError } from "firebase-functions/v2/https";
  3: import { onSchedule } from "firebase-functions/v2/scheduler";
  4: import { logger } from "firebase-functions/v2";
  5: import { cardSync } from "./services/cardSync";
  6: import { priceSync } from "./services/priceSync";
  7: import { retention } from "./utils/retention";
  8: import { runtimeOpts } from "./config/firebase";
  9: import * as dotenv from "dotenv";
 10: 
 11: dotenv.config();
 12: 
 13: // Manual card sync endpoint as a callable function
 14: export const manualCardSync = onCall(
 15:   {
 16:     memory: runtimeOpts.memory,
 17:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 18:     region: "us-central1",
 19:   },
 20:   async (request) => {
 21:     try {
 22:       const forceUpdate = request.data.force === true;
 23:       const groupId = request.data.groupId as string | undefined;
 24: 
 25:       const result = await cardSync.syncCards({
 26:         forceUpdate,
 27:         groupId,
 28:         skipImages: false,
 29:         imagesOnly: false,
 30:         silent: false,
 31:         dryRun: false,
 32:       });
 33: 
 34:       return result;
 35:     } catch (error) {
 36:       logger.error("Manual card sync failed", { error });
 37:       throw new HttpsError(
 38:         "internal",
 39:         error instanceof Error ? error.message : "Unknown error"
 40:       );
 41:     }
 42:   }
 43: );
 44: 
 45: // Manual price sync endpoint as a callable function
 46: export const manualPriceSync = onCall(
 47:   {
 48:     memory: runtimeOpts.memory,
 49:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 50:     region: "us-central1",
 51:   },
 52:   async (request) => {
 53:     try {
 54:       const forceUpdate = request.data.force === true;
 55:       const groupId = request.data.groupId as string | undefined;
 56: 
 57:       const result = await priceSync.syncPrices({
 58:         forceUpdate,
 59:         groupId,
 60:         silent: false,
 61:         dryRun: false,
 62:       });
 63: 
 64:       return result;
 65:     } catch (error) {
 66:       logger.error("Manual price sync failed", { error });
 67:       throw new HttpsError(
 68:         "internal",
 69:         error instanceof Error ? error.message : "Unknown error"
 70:       );
 71:     }
 72:   }
 73: );
 74: 
 75: // Manual cleanup endpoint as a callable function
 76: export const manualCleanup = onCall(
 77:   {
 78:     memory: runtimeOpts.memory,
 79:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 80:     region: "us-central1",
 81:   },
 82:   async () => {
 83:     try {
 84:       await retention.cleanOldData();
 85:       return { success: true };
 86:     } catch (error) {
 87:       logger.error("Manual cleanup failed", { error });
 88:       throw new HttpsError(
 89:         "internal",
 90:         error instanceof Error ? error.message : "Unknown error"
 91:       );
 92:     }
 93:   }
 94: );
 95: 
 96: // Scheduled Functions
 97: export const scheduledCardSync = onSchedule(
 98:   {
 99:     schedule: "0 21 * * *", // Daily at 21:00 UTC
100:     timeZone: "UTC",
101:     memory: runtimeOpts.memory,
102:     timeoutSeconds: runtimeOpts.timeoutSeconds,
103:     retryCount: 3,
104:   },
105:   async () => {
106:     try {
107:       logger.info("Starting scheduled card sync");
108:       const result = await cardSync.syncCards({
109:         forceUpdate: false,
110:         skipImages: false,
111:         imagesOnly: false,
112:         silent: false,
113:         dryRun: false,
114:       });
115:       logger.info("Card sync completed", result);
116:     } catch (error) {
117:       logger.error("Scheduled card sync failed", { error });
118:       throw error;
119:     }
120:   }
121: );
122: 
123: export const scheduledPriceSync = onSchedule(
124:   {
125:     schedule: "30 21 * * *", // Daily at 21:30 UTC
126:     timeZone: "UTC",
127:     memory: runtimeOpts.memory,
128:     timeoutSeconds: runtimeOpts.timeoutSeconds,
129:     retryCount: 3,
130:   },
131:   async () => {
132:     try {
133:       logger.info("Starting scheduled price sync");
134:       const result = await priceSync.syncPrices({
135:         forceUpdate: false,
136:         silent: false,
137:         dryRun: false,
138:       });
139:       logger.info("Price sync completed", result);
140:     } catch (error) {
141:       logger.error("Scheduled price sync failed", { error });
142:       throw error;
143:     }
144:   }
145: );
146: 
147: export const scheduledCleanup = onSchedule(
148:   {
149:     schedule: "0 22 * * *", // Daily at 22:00 UTC
150:     timeZone: "UTC",
151:     memory: runtimeOpts.memory,
152:     timeoutSeconds: runtimeOpts.timeoutSeconds,
153:     retryCount: 3,
154:   },
155:   async () => {
156:     try {
157:       logger.info("Starting scheduled cleanup");
158:       await retention.cleanOldData();
159:       logger.info("Cleanup completed");
160:     } catch (error) {
161:       logger.error("Scheduled cleanup failed", { error });
162:       throw error;
163:     }
164:   }
165: );
</file>

<file path="src/scripts/cleanup.ts">
 1: import { retention } from "../utils/retention";
 2: 
 3: async function main() {
 4:   console.log("Starting manual cleanup...");
 5:   try {
 6:     await retention.cleanOldData();
 7:     console.log("Cleanup completed successfully");
 8:   } catch (error) {
 9:     console.error("Cleanup failed:", error);
10:     process.exit(1);
11:   }
12: }
13: 
14: main();
</file>

<file path="src/scripts/prodSync.ts">
  1: // src/scripts/prodSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger, LogData } from "../utils/logger";
  5: 
  6: 
  7: interface SyncStats {
  8:   success: boolean;
  9:   itemsProcessed: number;
 10:   itemsUpdated: number;
 11:   errors: string[];
 12:   duration: number;
 13: }
 14: 
 15: interface SyncOptions {
 16:   forceUpdate?: boolean;
 17:   groupId?: string;
 18:   cardsOnly?: boolean;
 19:   pricesOnly?: boolean;
 20: }
 21: 
 22: // Move runProductionSync into a class for better organization
 23: class ProductionSync {
 24:   async run(options: SyncOptions = {}) {
 25:     const startTime = Date.now();
 26:     const results: {
 27:       cards?: SyncStats;
 28:       prices?: SyncStats;
 29:     } = {};
 30: 
 31:     try {
 32:       logger.info("Starting production sync", { options } as LogData);
 33: 
 34:       // Run card sync if not prices-only
 35:       if (!options.pricesOnly) {
 36:         logger.info("Starting card sync...");
 37:         const cardResult = await cardSync.syncCards({
 38:           forceUpdate: options.forceUpdate,
 39:           groupId: options.groupId,
 40:         });
 41: 
 42:         results.cards = {
 43:           success: cardResult.success,
 44:           itemsProcessed: cardResult.itemsProcessed,
 45:           itemsUpdated: cardResult.itemsUpdated,
 46:           errors: cardResult.errors,
 47:           duration: cardResult.timing.duration || 0,
 48:         };
 49: 
 50:         logger.info("Card sync completed", { stats: results.cards } as LogData);
 51:       }
 52: 
 53:       // Run price sync if not cards-only
 54:       if (!options.cardsOnly) {
 55:         logger.info("Starting price sync...");
 56:         const priceResult = await priceSync.syncPrices({
 57:           forceUpdate: options.forceUpdate,
 58:           groupId: options.groupId,
 59:         });
 60: 
 61:         results.prices = {
 62:           success: priceResult.success,
 63:           itemsProcessed: priceResult.itemsProcessed,
 64:           itemsUpdated: priceResult.itemsUpdated,
 65:           errors: priceResult.errors,
 66:           duration: priceResult.timing.duration || 0,
 67:         };
 68: 
 69:         logger.info("Price sync completed", { stats: results.prices } as LogData);
 70:       }
 71: 
 72:       const totalDuration = (Date.now() - startTime) / 1000;
 73:       logger.info(`Full sync completed in ${totalDuration}s`, { results } as LogData);
 74: 
 75:       return results;
 76:     } catch (error) {
 77:       logger.error("Production sync failed", { error } as LogData);
 78:       throw error;
 79:     }
 80:   }
 81: }
 82: 
 83: function parseArgs(args: string[]): SyncOptions {
 84:   const options: SyncOptions = {};
 85: 
 86:   for (let i = 0; i < args.length; i++) {
 87:     switch (args[i]) {
 88:     case "--force":
 89:       options.forceUpdate = true;
 90:       break;
 91:     case "--group":
 92:       options.groupId = args[++i];
 93:       break;
 94:     case "--cards-only":
 95:       options.cardsOnly = true;
 96:       break;
 97:     case "--prices-only":
 98:       options.pricesOnly = true;
 99:       break;
100:     case "--help":
101:       printHelp();
102:       process.exit(0);
103:     }
104:   }
105: 
106:   return options;
107: }
108: 
109: function printHelp() {
110:   console.log(`
111: Usage: npx ts-node src/scripts/prodSync.ts [options]
112: 
113: Options:
114:   --force         Force update all items regardless of changes
115:   --group <id>    Sync specific group ID only
116:   --cards-only    Only sync card data
117:   --prices-only   Only sync price data
118:   --help          Show this help message
119:   
120: Examples:
121:   npx ts-node src/scripts/prodSync.ts
122:   npx ts-node src/scripts/prodSync.ts --force
123:   npx ts-node src/scripts/prodSync.ts --group 23244
124:   npx ts-node src/scripts/prodSync.ts --cards-only
125:   `);
126: }
127: 
128: // Create singleton instance
129: export const productionSync = new ProductionSync();
130: 
131: // Command line execution
132: async function main() {
133:   const args = process.argv.slice(2);
134:   const options = parseArgs(args);
135: 
136:   console.log("Starting production sync with options:", options);
137: 
138:   try {
139:     const results = await productionSync.run(options);
140:     console.log("Sync completed successfully!");
141:     console.log(JSON.stringify(results, null, 2));
142:     process.exit(0);
143:   } catch (error) {
144:     console.error("Sync failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Run if called directly
150: if (require.main === module) {
151:   main();
152: }
</file>

<file path="src/scripts/setenv.ts">
 1: // scripts/setenv.ts
 2: import * as dotenv from "dotenv";
 3: import { exec } from "child_process";
 4: import { promisify } from "util";
 5: 
 6: const execAsync = promisify(exec);
 7: 
 8: async function setFirebaseConfig() {
 9:   try {
10:     dotenv.config();
11: 
12:     const config = {
13:       account_id: process.env.R2_ACCOUNT_ID,
14:       access_key_id: process.env.R2_ACCESS_KEY_ID,
15:       secret_access_key: process.env.R2_SECRET_ACCESS_KEY,
16:       bucket_name: process.env.R2_BUCKET_NAME,
17:       storage_path: process.env.R2_STORAGE_PATH,
18:       custom_domain: process.env.R2_CUSTOM_DOMAIN,
19:     };
20: 
21:     // Remove existing config
22:     await execAsync("firebase functions:config:unset r2");
23: 
24:     // Set new config
25:     const configString = Object.entries(config)
26:       .map(([key, value]) => `r2.${key}="${value}"`)
27:       .join(" ");
28: 
29:     await execAsync(`firebase functions:config:set ${configString}`);
30:     console.log("Firebase config updated successfully");
31:   } catch (error) {
32:     console.error("Error setting Firebase config:", error);
33:   }
34: }
35: 
36: setFirebaseConfig();
</file>

<file path="src/scripts/syncAll.ts">
 1: import { cardSync } from "../services/cardSync";
 2: import { priceSync } from "../services/priceSync";
 3: 
 4: async function main() {
 5:   console.log("Starting full sync...");
 6: 
 7:   try {
 8:     console.log("\n1. Running card sync...");
 9:     const cardResult = await cardSync.syncCards();
10:     console.log("Card sync completed:", {
11:       success: cardResult.success,
12:       processed: cardResult.itemsProcessed,
13:       updated: cardResult.itemsUpdated,
14:       errors: cardResult.errors.length,
15:     });
16: 
17:     console.log("\n2. Running price sync...");
18:     const priceResult = await priceSync.syncPrices();
19:     console.log("Price sync completed:", {
20:       success: priceResult.success,
21:       processed: priceResult.itemsProcessed,
22:       updated: priceResult.itemsUpdated,
23:       errors: priceResult.errors.length,
24:     });
25: 
26:     const allErrors = [...cardResult.errors, ...priceResult.errors];
27:     if (allErrors.length > 0) {
28:       console.log("\nErrors encountered:");
29:       allErrors.forEach((error) => console.log(`- ${error}`));
30:     }
31: 
32:     console.log("\nFull sync completed!");
33:   } catch (error) {
34:     console.error("Full sync failed:", error);
35:     process.exit(1);
36:   }
37: }
38: 
39: main();
</file>

<file path="src/scripts/syncCards.ts">
 1: import { cardSync } from "../services/cardSync";
 2: 
 3: async function main() {
 4:   try {
 5:     console.log("Starting manual card sync...");
 6:     const result = await cardSync.syncCards();
 7:     console.log("Card sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Card sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/syncPrices.ts">
 1: import { priceSync } from "../services/priceSync";
 2: 
 3: async function main() {
 4:   console.log("Starting manual price sync...");
 5:   try {
 6:     const result = await priceSync.syncPrices();
 7:     console.log("Price sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Price sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/testSync.ts">
  1: // src/scripts/testSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger } from "../utils/logger";
  5: import { withTimeout, TimeoutError } from "../utils/timeout";
  6: import { storageService } from "../services/storageService";
  7: 
  8: const MAX_SYNC_TIME = 30 * 60 * 1000; // 30 minutes
  9: const TEST_GROUP_ID = "23244"; // Dawn of Heroes
 10: const TEST_PRODUCT_ID = 508343; // Example product ID
 11: const IMAGE_BASE_URL = "https://fftcgcompanion.com/card-images";
 12: 
 13: async function testImageProcessing() {
 14:   try {
 15:     logger.info("Testing image processing...");
 16: 
 17:     // Test with a valid image URL using correct format
 18:     const validImageResult = await storageService.processAndStoreImage(
 19:       `${IMAGE_BASE_URL}/${TEST_GROUP_ID}/${TEST_PRODUCT_ID}_200w.jpg`,
 20:       TEST_PRODUCT_ID,
 21:       TEST_GROUP_ID,
 22:       "1-001" // Example card number
 23:     );
 24: 
 25:     logger.info("Valid image processing result:", {
 26:       highResUrl: validImageResult.highResUrl,
 27:       lowResUrl: validImageResult.lowResUrl,
 28:       isPlaceholder: validImageResult.metadata.isPlaceholder,
 29:       originalUrl: validImageResult.metadata.originalUrl,
 30:     });
 31: 
 32:     // Verify the image URLs follow the correct pattern
 33:     const urlPattern = new RegExp(`^${IMAGE_BASE_URL}/.*_[24]00w.jpg$`);
 34:     const isValidImageUrl = urlPattern.test(validImageResult.metadata.originalUrl || "");
 35: 
 36:     if (!isValidImageUrl) {
 37:       logger.error("Image URL pattern does not match expected format", {
 38:         url: validImageResult.metadata.originalUrl,
 39:         expectedPattern: `${IMAGE_BASE_URL}/{groupId}/{productId}_200w.jpg`,
 40:       });
 41:     }
 42: 
 43:     // Test with invalid/missing image (should return placeholder)
 44:     const placeholderResult = await storageService.processAndStoreImage(
 45:       undefined,
 46:       TEST_PRODUCT_ID,
 47:       TEST_GROUP_ID,
 48:       "1-001"
 49:     );
 50: 
 51:     logger.info("Placeholder image result:", {
 52:       highResUrl: placeholderResult.highResUrl,
 53:       lowResUrl: placeholderResult.lowResUrl,
 54:       isPlaceholder: placeholderResult.metadata.isPlaceholder,
 55:     });
 56: 
 57:     return {
 58:       validImage: {
 59:         success: validImageResult.metadata.isPlaceholder !== true,
 60:         correctUrlPattern: isValidImageUrl,
 61:         urls: {
 62:           original: validImageResult.metadata.originalUrl,
 63:           highRes: validImageResult.highResUrl,
 64:           lowRes: validImageResult.lowResUrl,
 65:         },
 66:       },
 67:       placeholderImage: {
 68:         success: placeholderResult.metadata.isPlaceholder === true,
 69:         urls: {
 70:           highRes: placeholderResult.highResUrl,
 71:           lowRes: placeholderResult.lowResUrl,
 72:         },
 73:       },
 74:     };
 75:   } catch (error) {
 76:     logger.error("Image processing test failed:", { error });
 77:     throw error;
 78:   }
 79: }
 80: 
 81: async function testSync() {
 82:   try {
 83:     logger.info("Starting test sync with group " + TEST_GROUP_ID);
 84: 
 85:     // Test image processing first
 86:     logger.info("Testing image processing capabilities...");
 87:     const imageResults = await testImageProcessing();
 88:     logger.info("Image processing test results:", imageResults);
 89: 
 90:     // Monitor card sync with timeout
 91:     const cardResult = await withTimeout(
 92:       cardSync.syncCards({
 93:         groupId: TEST_GROUP_ID,
 94:         forceUpdate: true,
 95:       }),
 96:       MAX_SYNC_TIME
 97:     );
 98: 
 99:     logger.info("Card sync results:", {
100:       processed: cardResult.itemsProcessed,
101:       updated: cardResult.itemsUpdated,
102:       errors: cardResult.errors,
103:       timing: cardResult.timing,
104:     });
105: 
106:     // Monitor price sync with timeout
107:     const priceResult = await withTimeout(
108:       priceSync.syncPrices({
109:         groupId: TEST_GROUP_ID,
110:         forceUpdate: true,
111:       }),
112:       MAX_SYNC_TIME
113:     );
114: 
115:     logger.info("Price sync results:", {
116:       processed: priceResult.itemsProcessed,
117:       updated: priceResult.itemsUpdated,
118:       errors: priceResult.errors,
119:       timing: priceResult.timing,
120:     });
121: 
122:     // Validate results
123:     const validationResults = {
124:       imageProcessing: imageResults,
125:       cardSync: {
126:         success: cardResult.success,
127:         hasUpdates: cardResult.itemsUpdated > 0,
128:         hasErrors: cardResult.errors.length > 0,
129:       },
130:       priceSync: {
131:         success: priceResult.success,
132:         hasUpdates: priceResult.itemsUpdated > 0,
133:         hasErrors: priceResult.errors.length > 0,
134:       },
135:     };
136: 
137:     logger.info("Test validation results:", validationResults);
138: 
139:     // Log any errors
140:     const allErrors = [...cardResult.errors, ...priceResult.errors];
141:     if (allErrors.length > 0) {
142:       logger.error("Errors during sync:", { errors: allErrors });
143:     }
144: 
145:     return validationResults;
146:   } catch (error) {
147:     if (error instanceof TimeoutError) {
148:       logger.error("Sync operation timed out", { error });
149:     } else {
150:       logger.error("Test sync failed:", { error });
151:     }
152:     throw error;
153:   }
154: }
155: 
156: // Execute if run directly
157: if (require.main === module) {
158:   testSync()
159:     .then((results) => {
160:       console.log("Test sync completed successfully!");
161:       console.log("Results:", JSON.stringify(results, null, 2));
162:       process.exit(0);
163:     })
164:     .catch((error) => {
165:       console.error("Test failed:", error);
166:       process.exit(1);
167:     });
168: }
169: 
170: export { testSync, testImageProcessing };
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { storageService } from "./storageService";
  5: import { CardProduct, SyncResult, CardHashData, SyncOptions, CardChanges } from "../types";
  6: import { logger } from "../utils/logger";
  7: import { RateLimiter } from "../utils/rateLimiter";
  8: import { Cache } from "../utils/cache";
  9: import { RetryWithBackoff } from "../utils/retry";
 10: import * as crypto from "crypto";
 11: import { FieldValue } from "firebase-admin/firestore";
 12: 
 13: export class CardSyncService {
 14:   private readonly BATCH_SIZE = 500; // Optimized batch size
 15:   private readonly MAX_PARALLEL_BATCHES = 3; // Reduced for better control
 16:   private readonly MAX_BATCH_OPERATIONS = 499; // Just under Firestore's limit
 17:   private readonly IMAGE_CONCURRENCY = 5; // Control parallel image processing
 18: 
 19:   private readonly rateLimiter = new RateLimiter();
 20:   private readonly cache = new Cache<string>(15);
 21:   private readonly retry = new RetryWithBackoff();
 22: 
 23:   private calculateHash(data: CardHashData): string {
 24:     return crypto
 25:       .createHash("md5")
 26:       .update(JSON.stringify(data))
 27:       .digest("hex");
 28:   }
 29: 
 30:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 31:     const hashMap = new Map<number, string>();
 32:     const uncachedIds: number[] = [];
 33: 
 34:     // Check cache first
 35:     productIds.forEach(id => {
 36:       const cacheKey = `hash_${id}`;
 37:       const cached = this.cache.get(cacheKey);
 38:       if (cached) {
 39:         hashMap.set(id, cached);
 40:       } else {
 41:         uncachedIds.push(id);
 42:       }
 43:     });
 44: 
 45:     if (uncachedIds.length === 0) {
 46:       return hashMap;
 47:     }
 48: 
 49:     // Batch get uncached hashes
 50:     const chunks = [];
 51:     for (let i = 0; i < uncachedIds.length; i += 10) {
 52:       chunks.push(uncachedIds.slice(i, i + 10));
 53:     }
 54: 
 55:     await Promise.all(chunks.map(async chunk => {
 56:       const refs = chunk.map(id => 
 57:         db.collection(COLLECTION.CARD_HASHES).doc(id.toString())
 58:       );
 59:       
 60:       const snapshots = await this.retry.execute(() => 
 61:         db.getAll(...refs)
 62:       );
 63: 
 64:       snapshots.forEach((snap, index) => {
 65:         const id = chunk[index];
 66:         const hash = snap.exists ? snap.data()?.hash : null;
 67:         if (hash) {
 68:           hashMap.set(id, hash);
 69:           this.cache.set(`hash_${id}`, hash);
 70:         }
 71:       });
 72:     }));
 73: 
 74:     return hashMap;
 75:   }
 76: 
 77:   private async updateStoredHash(productId: number, hash: string): Promise<void> {
 78:     this.cache.set(`hash_${productId}`, hash);
 79:     // Actual DB update will be handled in batch operations
 80:   }
 81: 
 82:   private getCardNumbers(card: CardProduct): string[] {
 83:     const numbers: string[] = [];
 84:     card.extendedData
 85:       .filter((data) => data.name === "Number")
 86:       .forEach((numberField) => {
 87:         const vals = numberField.value.split(/[,;/]/).map((n) => n.trim());
 88:         numbers.push(...vals);
 89:       });
 90: 
 91:     if (numbers.length === 0) {
 92:       numbers.push(`P${card.productId}`);
 93:     }
 94: 
 95:     return [...new Set(numbers)];
 96:   }
 97: 
 98:   private isNonCardProduct(card: CardProduct): boolean {
 99:     const cardType = card.extendedData.find((data) => data.name === "CardType")?.value;
100:     return !cardType || cardType.toLowerCase() === "sealed product";
101:   }
102: 
103:   private async saveDeltaUpdate(
104:     batch: FirebaseFirestore.WriteBatch,
105:     card: CardProduct, 
106:     changes: CardChanges
107:   ): Promise<void> {
108:     const deltaRef = db.collection(COLLECTION.CARD_DELTAS).doc();
109:     batch.set(deltaRef, {
110:       productId: card.productId,
111:       changes,
112:       timestamp: FieldValue.serverTimestamp(),
113:     });
114:   }
115: 
116:   private async processCardBatch(
117:     cards: CardProduct[],
118:     groupId: string,
119:     options: { forceUpdate?: boolean } = {}
120:   ): Promise<{
121:     processed: number;
122:     updated: number;
123:     errors: string[];
124:   }> {
125:     const result = {
126:       processed: 0,
127:       updated: 0,
128:       errors: [] as string[],
129:     };
130: 
131:     try {
132:       // Pre-fetch all hashes in one go
133:       const productIds = cards.map(card => card.productId);
134:       const hashMap = await this.getStoredHashes(productIds);
135: 
136:       // Prepare batches
137:       let mainBatch = db.batch();
138:       let batchCount = 0;
139:       const batchPromises: Promise<void>[] = [];
140: 
141:       // Process images in controlled parallel chunks
142:       const imageProcessingChunks: Array<Promise<{
143:         card: CardProduct;
144:         imageResult: Awaited<ReturnType<typeof storageService.processAndStoreImage>>;
145:       }>> = [];
146: 
147:       // Process images with controlled concurrency
148:       for (let i = 0; i < cards.length; i += this.IMAGE_CONCURRENCY) {
149:         const chunk = cards.slice(i, i + this.IMAGE_CONCURRENCY);
150:         const chunkPromises = chunk.map(async card => {
151:           try {
152:             const cardNumbers = this.getCardNumbers(card);
153:             const primaryCardNumber = cardNumbers[0];
154:             
155:             const imageResult = await this.retry.execute(() =>
156:               storageService.processAndStoreImage(
157:                 card.imageUrl,
158:                 card.productId,
159:                 groupId,
160:                 primaryCardNumber
161:               )
162:             );
163: 
164:             return { card, imageResult };
165:           } catch (error) {
166:             const errorMessage = error instanceof Error ? error.message : "Unknown error";
167:             result.errors.push(`Image processing failed for card ${card.productId}: ${errorMessage}`);
168:             throw error;
169:           }
170:         });
171: 
172:         imageProcessingChunks.push(...chunkPromises);
173: 
174:         // Add delay between image processing chunks
175:         if (i + this.IMAGE_CONCURRENCY < cards.length) {
176:           await new Promise(resolve => setTimeout(resolve, 500));
177:         }
178:       }
179: 
180:       // Wait for current chunk of image processing to complete
181:       const processedImages = await Promise.allSettled(imageProcessingChunks);
182: 
183:       // Process successful image results and create Firestore operations
184:       for (const imagePromiseResult of processedImages) {
185:         if (imagePromiseResult.status === "rejected") {
186:           continue;
187:         }
188: 
189:         const { card, imageResult } = imagePromiseResult.value;
190:         result.processed++;
191: 
192:         try {
193:           const relevantData: CardHashData = {
194:             name: card.name,
195:             cleanName: card.cleanName,
196:             modifiedOn: card.modifiedOn,
197:             extendedData: card.extendedData,
198:           };
199: 
200:           const currentHash = this.calculateHash(relevantData);
201:           const storedHash = hashMap.get(card.productId);
202: 
203:           if (currentHash === storedHash && !options.forceUpdate) {
204:             logger.info(`Skipping card ${card.productId} - no changes`);
205:             continue;
206:           }
207: 
208:           const cardNumbers = this.getCardNumbers(card);
209:           const primaryCardNumber = cardNumbers[0];
210: 
211:           const cardDoc = {
212:             productId: card.productId,
213:             name: card.name,
214:             cleanName: card.cleanName,
215:             highResUrl: imageResult.highResUrl,
216:             lowResUrl: imageResult.lowResUrl,
217:             lastUpdated: FieldValue.serverTimestamp(),
218:             groupId: parseInt(groupId),
219:             isNonCard: this.isNonCardProduct(card),
220:             cardNumbers,
221:             primaryCardNumber,
222:           };
223: 
224:           // Main card document
225:           const cardRef = db.collection(COLLECTION.CARDS)
226:             .doc(card.productId.toString());
227:           mainBatch.set(cardRef, cardDoc, { merge: true });
228:           batchCount++;
229: 
230:           // Extended data subcollection
231:           const extendedDataRef = cardRef.collection("extendedData");
232:           card.extendedData.forEach((data) => {
233:             mainBatch.set(extendedDataRef.doc(data.name), data);
234:             batchCount++;
235:           });
236: 
237:           // Image metadata
238:           mainBatch.set(
239:             cardRef.collection("metadata").doc("image"),
240:             imageResult.metadata
241:           );
242:           batchCount++;
243: 
244:           // Update hash
245:           const hashRef = db.collection(COLLECTION.CARD_HASHES)
246:             .doc(card.productId.toString());
247:           mainBatch.set(hashRef, {
248:             hash: currentHash,
249:             lastUpdated: FieldValue.serverTimestamp(),
250:           }, { merge: true });
251:           batchCount++;
252: 
253:           // Save delta update in same batch
254:           await this.saveDeltaUpdate(mainBatch, card, cardDoc);
255:           batchCount++;
256: 
257:           // Update cache
258:           await this.updateStoredHash(card.productId, currentHash);
259: 
260:           // Commit batch if reaching limit
261:           if (batchCount >= this.MAX_BATCH_OPERATIONS) {
262:             batchPromises.push(
263:               this.rateLimiter.add(() => 
264:                 this.retry.execute(() => mainBatch.commit())
265:               ).then(() => void 0)
266:             );
267:             mainBatch = db.batch();
268:             batchCount = 0;
269:           }
270: 
271:           result.updated++;
272:           logger.info(
273:             `Updated card ${card.productId}: ${card.name} with numbers: ${cardNumbers.join(", ")}`
274:           );
275:         } catch (error) {
276:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
277:           result.errors.push(`Error processing card ${card.productId}: ${errorMessage}`);
278:           logger.error(`Error processing card ${card.productId}`, { error: errorMessage });
279:         }
280:       }
281: 
282:       // Commit any remaining batch operations
283:       if (batchCount > 0) {
284:         batchPromises.push(
285:           this.rateLimiter.add(() => 
286:             this.retry.execute(() => mainBatch.commit())
287:           ).then(() => void 0)
288:         );
289:       }
290: 
291:       // Wait for all batch commits to complete
292:       await Promise.all(batchPromises);
293: 
294:     } catch (error) {
295:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
296:       result.errors.push(`Batch processing error: ${errorMessage}`);
297:       logger.error("Batch processing error", { error: errorMessage });
298:     }
299: 
300:     return result;
301:   }
302: 
303:   private async processCardBatches(
304:     cards: CardProduct[],
305:     groupId: string,
306:     options: { forceUpdate?: boolean } = {}
307:   ): Promise<{
308:     processed: number;
309:     updated: number;
310:     errors: string[];
311:   }> {
312:     // Split into optimally sized batches
313:     const batches: CardProduct[][] = [];
314:     for (let i = 0; i < cards.length; i += this.BATCH_SIZE) {
315:       batches.push(cards.slice(i, i + this.BATCH_SIZE));
316:     }
317: 
318:     const results = [];
319:     // Process batches with controlled parallelism
320:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
321:       const currentBatches = batches.slice(i, i + this.MAX_PARALLEL_BATCHES);
322:       const batchPromises = currentBatches.map(batch =>
323:         this.processCardBatch(batch, groupId, options)
324:       );
325: 
326:       const batchResults = await Promise.all(batchPromises);
327:       results.push(...batchResults);
328: 
329:       // Add delay between batch groups to prevent rate limiting
330:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
331:         await new Promise(resolve => setTimeout(resolve, 2000));
332:       }
333:     }
334: 
335:     // Combine results
336:     return results.reduce(
337:       (acc, curr) => ({
338:         processed: acc.processed + curr.processed,
339:         updated: acc.updated + curr.updated,
340:         errors: [...acc.errors, ...curr.errors],
341:       }),
342:       { processed: 0, updated: 0, errors: [] }
343:     );
344:   }
345: 
346:   async syncCards(options: SyncOptions = {}): Promise<SyncResult> {
347:     const result: SyncResult = {
348:       success: true,
349:       itemsProcessed: 0,
350:       itemsUpdated: 0,
351:       errors: [],
352:       timing: {
353:         startTime: new Date(),
354:       },
355:     };
356: 
357:     try {
358:       logger.info("Starting card sync", { options });
359: 
360:       // Get groups to process
361:       const groups = options.groupId
362:         ? [{ groupId: options.groupId }]
363:         : await tcgcsvApi.getGroups();
364: 
365:       logger.info(`Found ${groups.length} groups to process`);
366: 
367:       // Process each group sequentially to prevent overload
368:       for (const group of groups) {
369:         result.timing.groupStartTime = new Date();
370:         try {
371:           // Get cards for current group with retry
372:           const cards = await this.retry.execute(() =>
373:             tcgcsvApi.getGroupProducts(group.groupId)
374:           );
375: 
376:           logger.info(`Processing ${cards.length} cards for group ${group.groupId}`);
377: 
378:           // Process cards in optimized batches
379:           const batchResults = await this.processCardBatches(
380:             cards,
381:             group.groupId,
382:             options
383:           );
384: 
385:           // Update results
386:           result.itemsProcessed += batchResults.processed;
387:           result.itemsUpdated += batchResults.updated;
388:           result.errors.push(...batchResults.errors);
389: 
390:           // Calculate and log group timing
391:           const groupEndTime = new Date();
392:           const groupDuration = 
393:             (groupEndTime.getTime() - result.timing.groupStartTime!.getTime()) / 1000;
394: 
395:           logger.info(`Completed group ${group.groupId} in ${groupDuration}s`, {
396:             processed: batchResults.processed,
397:             updated: batchResults.updated,
398:             errors: batchResults.errors.length,
399:           });
400: 
401:           // Add delay between groups
402:           if (groups.length > 1) {
403:             await new Promise(resolve => setTimeout(resolve, 3000));
404:           }
405: 
406:         } catch (error) {
407:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
408:           result.errors.push(
409:             `Error processing cards for group ${group.groupId}: ${errorMessage}`
410:           );
411:           logger.error(`Error processing group ${group.groupId}`, {
412:             error: errorMessage,
413:           });
414:         }
415:       }
416: 
417:     } catch (error) {
418:       result.success = false;
419:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
420:       result.errors.push(`Card sync failed: ${errorMessage}`);
421:       logger.error("Card sync failed", { error: errorMessage });
422:     }
423: 
424:     // Calculate final timing
425:     result.timing.endTime = new Date();
426:     result.timing.duration =
427:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
428: 
429:     // Log final results
430:     logger.info(`Card sync completed in ${result.timing.duration}s`, {
431:       processed: result.itemsProcessed,
432:       updated: result.itemsUpdated,
433:       errors: result.errors.length,
434:       timing: result.timing,
435:     });
436: 
437:     return result;
438:   }
439: }
440: 
441: export const cardSync = new CardSyncService();
</file>

<file path="src/services/priceSync.ts">
  1: // src/services/priceSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { CardPrice, SyncResult, SyncOptions } from "../types";
  5: import { logger } from "../utils/logger";
  6: import { RateLimiter } from "../utils/rateLimiter";
  7: import { Cache } from "../utils/cache";
  8: import { RetryWithBackoff } from "../utils/retry";
  9: import * as crypto from "crypto";
 10: import { FieldValue, WriteResult } from "firebase-admin/firestore";
 11: 
 12: export class PriceSyncService {
 13:   private readonly BATCH_SIZE = 500; // Optimized batch size
 14:   private readonly MAX_PARALLEL_BATCHES = 3; // Reduced parallel operations
 15:   private readonly MAX_BATCH_OPERATIONS = 499; // Just under Firestore's limit
 16: 
 17:   private readonly rateLimiter = new RateLimiter();
 18:   private readonly cache = new Cache<string>(15);
 19:   private readonly retry = new RetryWithBackoff();
 20: 
 21:   private calculateHash(price: CardPrice): string {
 22:     const relevantData = {
 23:       normal: price.normal,
 24:       foil: price.foil,
 25:       lastUpdated: price.lastUpdated,
 26:     };
 27:     return crypto.createHash("md5").update(JSON.stringify(relevantData)).digest("hex");
 28:   }
 29: 
 30:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 31:     const hashMap = new Map<number, string>();
 32:     const uncachedIds: number[] = [];
 33: 
 34:     // Check cache first
 35:     productIds.forEach(id => {
 36:       const cacheKey = `price_hash_${id}`;
 37:       const cached = this.cache.get(cacheKey);
 38:       if (cached) {
 39:         hashMap.set(id, cached);
 40:       } else {
 41:         uncachedIds.push(id);
 42:       }
 43:     });
 44: 
 45:     if (uncachedIds.length === 0) {
 46:       return hashMap;
 47:     }
 48: 
 49:     // Batch get uncached hashes
 50:     const chunks = [];
 51:     for (let i = 0; i < uncachedIds.length; i += 10) {
 52:       chunks.push(uncachedIds.slice(i, i + 10));
 53:     }
 54: 
 55:     await Promise.all(chunks.map(async chunk => {
 56:       const refs = chunk.map(id => 
 57:         db.collection(COLLECTION.PRICE_HASHES).doc(id.toString())
 58:       );
 59:       
 60:       const snapshots = await this.retry.execute(() => 
 61:         db.getAll(...refs)
 62:       );
 63: 
 64:       snapshots.forEach((snap, index) => {
 65:         const id = chunk[index];
 66:         const hash = snap.exists ? snap.data()?.hash : null;
 67:         if (hash) {
 68:           hashMap.set(id, hash);
 69:           this.cache.set(`price_hash_${id}`, hash);
 70:         }
 71:       });
 72:     }));
 73: 
 74:     return hashMap;
 75:   }
 76: 
 77:   private validatePrice(price: CardPrice): boolean {
 78:     const validatePriceData = (data: typeof price.normal | typeof price.foil) => {
 79:       if (!data) return false;
 80:       return (
 81:         typeof data.marketPrice === "number" &&
 82:         data.marketPrice >= 0 &&
 83:         typeof data.lowPrice === "number" &&
 84:         data.lowPrice >= 0 &&
 85:         typeof data.highPrice === "number" &&
 86:         data.highPrice >= 0
 87:       );
 88:     };
 89: 
 90:     return validatePriceData(price.normal) || validatePriceData(price.foil);
 91:   }
 92: 
 93:   private async processPriceBatch(
 94:     prices: CardPrice[],
 95:     groupId: string,
 96:     options: { forceUpdate?: boolean } = {}
 97:   ): Promise<{
 98:     processed: number;
 99:     updated: number;
100:     errors: string[];
101:   }> {
102:     const result = {
103:       processed: 0,
104:       updated: 0,
105:       errors: [] as string[],
106:     };
107: 
108:     try {
109:       // Pre-fetch all hashes in one go
110:       const productIds = prices.map(price => price.productId);
111:       const hashMap = await this.getStoredHashes(productIds);
112: 
113:       // Prepare batches
114:       let mainBatch = db.batch();
115:       let historicalBatch = db.batch();
116:       let mainOps = 0;
117:       let historicalOps = 0;
118:       const batchPromises: Promise<WriteResult[]>[] = [];
119: 
120:       // Prepare date once
121:       const today = new Date();
122:       today.setHours(0, 0, 0, 0);
123: 
124:       for (const price of prices) {
125:         try {
126:           result.processed++;
127: 
128:           if (!this.validatePrice(price)) continue;
129: 
130:           const currentHash = this.calculateHash(price);
131:           const storedHash = hashMap.get(price.productId);
132: 
133:           if (currentHash === storedHash && !options.forceUpdate) {
134:             continue;
135:           }
136: 
137:           // Prepare documents
138:           const priceDoc = {
139:             productId: price.productId,
140:             lastUpdated: FieldValue.serverTimestamp(),
141:             groupId: parseInt(groupId),
142:             ...(price.normal && { normal: price.normal }),
143:             ...(price.foil && { foil: price.foil }),
144:           };
145: 
146:           const historicalDoc = {
147:             productId: price.productId,
148:             groupId,
149:             date: today,
150:             timestamp: FieldValue.serverTimestamp(),
151:             ...(price.normal && {
152:               normal: {
153:                 directLow: price.normal.directLowPrice,
154:                 high: price.normal.highPrice,
155:                 low: price.normal.lowPrice,
156:                 market: price.normal.marketPrice,
157:                 mid: price.normal.midPrice,
158:               },
159:             }),
160:             ...(price.foil && {
161:               foil: {
162:                 directLow: price.foil.directLowPrice,
163:                 high: price.foil.highPrice,
164:                 low: price.foil.lowPrice,
165:                 market: price.foil.marketPrice,
166:                 mid: price.foil.midPrice,
167:               },
168:             }),
169:           };
170: 
171:           // Add to main batch
172:           const priceRef = db.collection(COLLECTION.PRICES).doc(price.productId.toString());
173:           mainBatch.set(priceRef, priceDoc, { merge: true });
174:           mainOps++;
175: 
176:           // Add hash update to same batch
177:           const hashRef = db.collection(COLLECTION.PRICE_HASHES).doc(price.productId.toString());
178:           mainBatch.set(hashRef, {
179:             hash: currentHash,
180:             lastUpdated: FieldValue.serverTimestamp(),
181:           }, { merge: true });
182:           mainOps++;
183: 
184:           // Add to historical batch
185:           const docId = `${price.productId}_${today.toISOString().split("T")[0]}`;
186:           const historicalRef = db.collection(COLLECTION.HISTORICAL_PRICES).doc(docId);
187:           historicalBatch.set(historicalRef, historicalDoc, { merge: true });
188:           historicalOps++;
189: 
190:           // Commit batches if reaching limits
191:           if (mainOps >= this.MAX_BATCH_OPERATIONS) {
192:             batchPromises.push(
193:               this.rateLimiter.add(() => this.retry.execute(() => mainBatch.commit()))
194:             );
195:             mainBatch = db.batch();
196:             mainOps = 0;
197:           }
198: 
199:           if (historicalOps >= this.MAX_BATCH_OPERATIONS) {
200:             batchPromises.push(
201:               this.rateLimiter.add(() => this.retry.execute(() => historicalBatch.commit()))
202:             );
203:             historicalBatch = db.batch();
204:             historicalOps = 0;
205:           }
206: 
207:           result.updated++;
208:           
209:           // Update cache
210:           this.cache.set(`price_hash_${price.productId}`, currentHash);
211: 
212:         } catch (error) {
213:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
214:           result.errors.push(`Error processing price for product ${price.productId}: ${errorMessage}`);
215:         }
216:       }
217: 
218:       // Commit remaining batches
219:       if (mainOps > 0) {
220:         batchPromises.push(
221:           this.rateLimiter.add(() => this.retry.execute(() => mainBatch.commit()))
222:         );
223:       }
224: 
225:       if (historicalOps > 0) {
226:         batchPromises.push(
227:           this.rateLimiter.add(() => this.retry.execute(() => historicalBatch.commit()))
228:         );
229:       }
230: 
231:       // Wait for all batches to complete
232:       await Promise.all(batchPromises);
233: 
234:     } catch (error) {
235:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
236:       result.errors.push(`Batch processing error: ${errorMessage}`);
237:     }
238: 
239:     return result;
240:   }
241: 
242:   private async processPriceBatches(
243:     prices: CardPrice[],
244:     groupId: string,
245:     options: { forceUpdate?: boolean } = {}
246:   ): Promise<{
247:     processed: number;
248:     updated: number;
249:     errors: string[];
250:   }> {
251:     // Split into optimally sized batches
252:     const batches: CardPrice[][] = [];
253:     for (let i = 0; i < prices.length; i += this.BATCH_SIZE) {
254:       batches.push(prices.slice(i, i + this.BATCH_SIZE));
255:     }
256: 
257:     const results = [];
258:     // Process batches with controlled parallelism
259:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
260:       const currentBatches = batches.slice(i, i + this.MAX_PARALLEL_BATCHES);
261:       const batchPromises = currentBatches.map(batch => 
262:         this.processPriceBatch(batch, groupId, options)
263:       );
264: 
265:       const batchResults = await Promise.all(batchPromises);
266:       results.push(...batchResults);
267: 
268:       // Add delay between batch groups to prevent rate limiting
269:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
270:         await new Promise(resolve => setTimeout(resolve, 1000));
271:       }
272:     }
273: 
274:     // Combine results
275:     return results.reduce(
276:       (acc, curr) => ({
277:         processed: acc.processed + curr.processed,
278:         updated: acc.updated + curr.updated,
279:         errors: [...acc.errors, ...curr.errors],
280:       }),
281:       { processed: 0, updated: 0, errors: [] }
282:     );
283:   }
284: 
285:   async syncPrices(options: SyncOptions = {}): Promise<SyncResult> {
286:     const result: SyncResult = {
287:       success: true,
288:       itemsProcessed: 0,
289:       itemsUpdated: 0,
290:       errors: [],
291:       timing: {
292:         startTime: new Date(),
293:       },
294:     };
295: 
296:     try {
297:       logger.info("Starting price sync", { options });
298: 
299:       // Get groups to process
300:       const groups = options.groupId
301:         ? [{ groupId: options.groupId }]
302:         : await tcgcsvApi.getGroups();
303: 
304:       logger.info(`Found ${groups.length} groups to process`);
305: 
306:       // Process each group sequentially to prevent overload
307:       for (const group of groups) {
308:         result.timing.groupStartTime = new Date();
309:         try {
310:           // Get prices for current group
311:           const prices = await tcgcsvApi.getGroupPrices(group.groupId);
312:           logger.info(`Processing ${prices.length} prices for group ${group.groupId}`);
313: 
314:           // Process prices in optimized batches
315:           const batchResults = await this.processPriceBatches(
316:             prices,
317:             group.groupId,
318:             options
319:           );
320: 
321:           // Update results
322:           result.itemsProcessed += batchResults.processed;
323:           result.itemsUpdated += batchResults.updated;
324:           result.errors.push(...batchResults.errors);
325: 
326:           // Add delay between groups
327:           if (groups.length > 1) {
328:             await new Promise(resolve => setTimeout(resolve, 2000));
329:           }
330: 
331:         } catch (error) {
332:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
333:           result.errors.push(
334:             `Error processing prices for group ${group.groupId}: ${errorMessage}`
335:           );
336:           logger.error(`Error processing prices for group ${group.groupId}`, {
337:             error: errorMessage,
338:           });
339:         }
340:       }
341:     } catch (error) {
342:       result.success = false;
343:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
344:       result.errors.push(`Price sync failed: ${errorMessage}`);
345:       logger.error("Price sync failed", { error: errorMessage });
346:     }
347: 
348:     // Calculate final timing
349:     result.timing.endTime = new Date();
350:     result.timing.duration =
351:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
352: 
353:     // Log final results
354:     logger.info(`Price sync completed in ${result.timing.duration}s`, {
355:       processed: result.itemsProcessed,
356:       updated: result.itemsUpdated,
357:       errors: result.errors.length,
358:       timing: result.timing,
359:     });
360: 
361:     return result;
362:   }
363: }
364: 
365: export const priceSync = new PriceSyncService();
</file>

<file path="src/services/storageService.ts">
  1: // src/services/storageService.ts
  2: import { S3Client, PutObjectCommand, HeadObjectCommand } from "@aws-sdk/client-s3";
  3: import axios from "axios";
  4: import { R2_CONFIG } from "../config/r2";
  5: import { logger } from "../utils/logger";
  6: 
  7: interface ImageResult {
  8:   highResUrl: string;
  9:   lowResUrl: string;
 10:   metadata: {
 11:     contentType: string;
 12:     productId: string;
 13:     groupId: string;
 14:     lastUpdated: string;
 15:     isPlaceholder?: boolean;
 16:     originalUrl?: string;
 17:     existingImage?: boolean;
 18:     errorMessage?: string;
 19:   };
 20: }
 21: 
 22: export class StorageService {
 23:   private client: S3Client;
 24:   private readonly bucket: string;
 25:   private readonly customDomain: string;
 26:   private readonly storagePath: string;
 27:   private readonly maxRetries = 3;
 28:   private readonly timeoutMs = 30000; // 30 seconds
 29:   private readonly PLACEHOLDER_URL = "https://fftcgcompanion.com/card-images/image-coming-soon.jpeg";
 30:   private readonly validImagePatterns = [
 31:     "_200w.", // Match _200w followed by any extension
 32:     "_400w.", // Match _400w followed by any extension
 33:     "_1000x1000.", // Match _1000x1000 followed by any extension
 34:   ];
 35: 
 36:   constructor() {
 37:     this.client = new S3Client({
 38:       region: "auto",
 39:       endpoint: `https://${R2_CONFIG.ACCOUNT_ID}.r2.cloudflarestorage.com`,
 40:       credentials: {
 41:         accessKeyId: R2_CONFIG.ACCESS_KEY_ID,
 42:         secretAccessKey: R2_CONFIG.SECRET_ACCESS_KEY,
 43:       },
 44:       forcePathStyle: true,
 45:     });
 46: 
 47:     this.bucket = R2_CONFIG.BUCKET_NAME;
 48:     this.customDomain = R2_CONFIG.CUSTOM_DOMAIN;
 49:     this.storagePath = R2_CONFIG.STORAGE_PATH;
 50:   }
 51: 
 52:   private isValidImageUrl(url: string | undefined): boolean {
 53:     if (!url) return false;
 54: 
 55:     // Check if it's TCGPlayer's missing image SVG
 56:     if (url.includes("image-missing.svg")) {
 57:       logger.info(`TCGPlayer missing image URL detected: ${url}, using our placeholder`);
 58:       return false;
 59:     }
 60: 
 61:     // If URL contains any of our valid patterns, it's a valid TCGPlayer image URL
 62:     const isValidPattern = this.validImagePatterns.some((pattern) => url.includes(pattern));
 63: 
 64:     // If URL doesn't match our patterns, consider it invalid
 65:     if (!isValidPattern) {
 66:       logger.info(`Invalid image URL pattern: ${url}, using placeholder`);
 67:       return false;
 68:     }
 69: 
 70:     return true;
 71:   }
 72: 
 73:   private async checkImageExists(path: string): Promise<boolean> {
 74:     try {
 75:       await this.client.send(
 76:         new HeadObjectCommand({
 77:           Bucket: this.bucket,
 78:           Key: path,
 79:         })
 80:       );
 81:       return true;
 82:     } catch (error) {
 83:       return false;
 84:     }
 85:   }
 86: 
 87:   private async validateImage(buffer: Buffer): Promise<boolean> {
 88:     if (buffer.length < 4) return false;
 89: 
 90:     const header = buffer.slice(0, 4);
 91:     // JPEG magic number: FF D8 FF
 92:     const isJPEG = header[0] === 0xff && header[1] === 0xd8 && header[2] === 0xff;
 93:     // PNG magic number: 89 50 4E 47
 94:     const isPNG = header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4e && header[3] === 0x47;
 95: 
 96:     return isJPEG || isPNG;
 97:   }
 98: 
 99:   private async downloadImage(url: string, retries = this.maxRetries): Promise<Buffer> {
100:     let lastError: Error | null = null;
101: 
102:     for (let attempt = 0; attempt <= retries; attempt++) {
103:       try {
104:         const response = await axios.get(url, {
105:           responseType: "arraybuffer",
106:           timeout: this.timeoutMs,
107:           headers: {
108:             "User-Agent": "FFTCG-Sync-Service/1.0",
109:             "Accept": "image/jpeg,image/png,image/*",
110:           },
111:           maxContentLength: 10 * 1024 * 1024, // 10MB max
112:           validateStatus: (status) => status === 200, // Only accept 200 status
113:         });
114: 
115:         const buffer = Buffer.from(response.data);
116: 
117:         if (await this.validateImage(buffer)) {
118:           return buffer;
119:         } else {
120:           throw new Error("Invalid image format");
121:         }
122:       } catch (error) {
123:         const axiosError = error as { response?: { status?: number } };
124: 
125:         // If we get a 403, this means the image doesn't exist or access is denied
126:         // Don't retry and don't log as error since this is an expected case
127:         if (axiosError?.response?.status === 403) {
128:           logger.info(`Image not available (403) for URL: ${url}`);
129:           throw new Error("IMAGE_NOT_AVAILABLE");
130:         }
131: 
132:         // For other errors, continue with retry logic
133:         lastError = error instanceof Error ? error : new Error(String(error));
134: 
135:         if (attempt === retries) {
136:           logger.error(`Failed to download image after ${retries + 1} attempts`, {
137:             url,
138:             error: lastError.message,
139:             status: axiosError?.response?.status,
140:           });
141:           break;
142:         }
143: 
144:         // Only log retries for non-403 errors
145:         logger.info(`Retrying image download (attempt ${attempt + 1}/${retries})`, {
146:           url,
147:           status: axiosError?.response?.status,
148:         });
149: 
150:         await new Promise((resolve) => setTimeout(resolve, 2000 * Math.pow(2, attempt)));
151:       }
152:     }
153: 
154:     throw lastError || new Error("Download failed after retries");
155:   }
156: 
157:   private async uploadToR2WithRetry(
158:     buffer: Buffer,
159:     path: string,
160:     metadata: Record<string, string>,
161:     retries = this.maxRetries
162:   ): Promise<string> {
163:     let lastError: Error | null = null;
164: 
165:     const stringMetadata = Object.entries(metadata).reduce(
166:       (acc, [key, value]) => ({
167:         ...acc,
168:         [key]: String(value),
169:       }),
170:       {}
171:     );
172: 
173:     for (let attempt = 0; attempt <= retries; attempt++) {
174:       try {
175:         await this.client.send(
176:           new PutObjectCommand({
177:             Bucket: this.bucket,
178:             Key: path,
179:             Body: buffer,
180:             ContentType: "image/jpeg",
181:             Metadata: stringMetadata,
182:             ContentLength: buffer.length,
183:             CacheControl: "public, max-age=31536000", // Cache for 1 year
184:             ACL: "public-read",
185:           })
186:         );
187:         return `${this.customDomain}/${path}`;
188:       } catch (error) {
189:         lastError = error instanceof Error ? error : new Error(String(error));
190:         logger.error(`Upload attempt ${attempt + 1} failed`, {
191:           path,
192:           error: lastError.message,
193:         });
194:         if (attempt === retries) break;
195:         await new Promise((resolve) => setTimeout(resolve, 1000 * (attempt + 1)));
196:       }
197:     }
198: 
199:     throw lastError || new Error("Upload failed after retries");
200:   }
201: 
202:   private getImagePath(groupId: string, cardNumber: string, resolution: "200w" | "400w"): string {
203:     return `${this.storagePath}/${groupId}/${cardNumber}_${resolution}.jpg`;
204:   }
205: 
206:   public async processAndStoreImage(
207:     imageUrl: string | undefined,
208:     productId: number,
209:     groupId: string,
210:     cardNumber: string
211:   ): Promise<ImageResult> {
212:     const baseMetadata = {
213:       productId: productId.toString(),
214:       groupId,
215:       lastUpdated: new Date().toISOString(),
216:       contentType: "image/jpeg",
217:     };
218: 
219:     // Check for valid TCGPlayer URL first
220:     if (!this.isValidImageUrl(imageUrl)) {
221:       logger.info(`Invalid or missing image URL for product ${productId}, using placeholder`);
222:       return {
223:         highResUrl: this.PLACEHOLDER_URL,
224:         lowResUrl: this.PLACEHOLDER_URL,
225:         metadata: {
226:           ...baseMetadata,
227:           isPlaceholder: true,
228:           originalUrl: imageUrl,
229:           errorMessage: "Invalid or missing image URL",
230:         },
231:       };
232:     }
233: 
234:     try {
235:       // Check if images already exist in R2
236:       const highResPath = this.getImagePath(groupId, cardNumber, "400w");
237:       const lowResPath = this.getImagePath(groupId, cardNumber, "200w");
238: 
239:       const [highResExists, lowResExists] = await Promise.all([
240:         this.checkImageExists(highResPath),
241:         this.checkImageExists(lowResPath),
242:       ]);
243: 
244:       // If both images exist, return their URLs
245:       if (highResExists && lowResExists) {
246:         const existingHighResUrl = `${this.customDomain}/${highResPath}`;
247:         const existingLowResUrl = `${this.customDomain}/${lowResPath}`;
248: 
249:         logger.info(`Using existing images for product ${productId}`);
250:         return {
251:           highResUrl: existingHighResUrl,
252:           lowResUrl: existingLowResUrl,
253:           metadata: {
254:             ...baseMetadata,
255:             originalUrl: imageUrl,
256:             existingImage: true,
257:           },
258:         };
259:       }
260: 
261:       try {
262:         const baseUrl = imageUrl || "";
263:         const highResTcgUrl = baseUrl.replace("/fit-in/", "/fit-in/437x437/");
264:         const lowResTcgUrl = baseUrl.replace("/fit-in/", "/fit-in/223x223/");
265: 
266:         const [highResBuffer, lowResBuffer] = await Promise.all([
267:           this.downloadImage(highResTcgUrl),
268:           this.downloadImage(lowResTcgUrl),
269:         ]);
270: 
271:         // Upload both versions to R2
272:         const [storedHighResUrl, storedLowResUrl] = await Promise.all([
273:           this.uploadToR2WithRetry(highResBuffer, highResPath, baseMetadata),
274:           this.uploadToR2WithRetry(lowResBuffer, lowResPath, baseMetadata),
275:         ]);
276: 
277:         return {
278:           highResUrl: storedHighResUrl,
279:           lowResUrl: storedLowResUrl,
280:           metadata: {
281:             ...baseMetadata,
282:             originalUrl: imageUrl,
283:           },
284:         };
285:       } catch (unknownError: unknown) {
286:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
287: 
288:         // Only log as error if it's not an expected case
289:         if (error.message !== "IMAGE_NOT_AVAILABLE") {
290:           logger.error(`Failed to process images for ${productId}`, { error });
291:         }
292: 
293:         return {
294:           highResUrl: this.PLACEHOLDER_URL,
295:           lowResUrl: this.PLACEHOLDER_URL,
296:           metadata: {
297:             ...baseMetadata,
298:             isPlaceholder: true,
299:             originalUrl: imageUrl,
300:             errorMessage:
301:               error.message === "IMAGE_NOT_AVAILABLE" ? "Image not available from source" : "Image processing failed",
302:           },
303:         };
304:       }
305:     } catch (unknownError: unknown) {
306:       const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
307: 
308:       // Only log as error if it's not an expected case
309:       if (error.message !== "IMAGE_NOT_AVAILABLE") {
310:         logger.error(`Failed to process images for ${productId}`, { error });
311:       }
312: 
313:       return {
314:         highResUrl: this.PLACEHOLDER_URL,
315:         lowResUrl: this.PLACEHOLDER_URL,
316:         metadata: {
317:           ...baseMetadata,
318:           isPlaceholder: true,
319:           originalUrl: imageUrl,
320:           errorMessage:
321:             error.message === "IMAGE_NOT_AVAILABLE" ? "Image not available from source" : "Image processing failed",
322:         },
323:       };
324:     }
325:   }
326: }
327: 
328: export const storageService = new StorageService();
</file>

<file path="src/types/index.ts">
  1: import { FieldValue } from "firebase-admin/firestore";
  2: 
  3: export interface CardProduct {
  4:   productId: number;
  5:   name: string;
  6:   cleanName: string;
  7:   imageUrl?: string;
  8:   categoryId: number;
  9:   groupId: number;
 10:   url: string;
 11:   modifiedOn: string;
 12:   imageCount: number;
 13:   extendedData: Array<{
 14:     name: string;
 15:     displayName: string;
 16:     value: string;
 17:   }>;
 18: }
 19: 
 20: export interface CardPrice {
 21:   productId: number;
 22:   normal?: {
 23:     directLowPrice: number | null;
 24:     highPrice: number;
 25:     lowPrice: number;
 26:     marketPrice: number;
 27:     midPrice: number;
 28:     subTypeName: "Normal";
 29:   };
 30:   foil?: {
 31:     directLowPrice: number | null;
 32:     highPrice: number;
 33:     lowPrice: number;
 34:     marketPrice: number;
 35:     midPrice: number;
 36:     subTypeName: "Foil";
 37:   };
 38:   lastUpdated: Date;
 39: }
 40: 
 41: export interface HistoricalPrice {
 42:   productId: number;
 43:   date: Date;
 44:   normal?: {
 45:     directLow: number | null;
 46:     high: number;
 47:     low: number;
 48:     market: number;
 49:     mid: number;
 50:   };
 51:   foil?: {
 52:     directLow: number | null;
 53:     high: number;
 54:     low: number;
 55:     market: number;
 56:     mid: number;
 57:   };
 58:   groupId: string;
 59: }
 60: 
 61: export interface SyncTiming {
 62:   startTime: Date;
 63:   endTime?: Date;
 64:   duration?: number;
 65:   groupStartTime?: Date;
 66:   imageStartTime?: Date;
 67:   lastUpdateTime?: Date;
 68: }
 69: 
 70: export interface SyncResult {
 71:   success: boolean;
 72:   itemsProcessed: number;
 73:   itemsUpdated: number;
 74:   errors: string[];
 75:   timing: SyncTiming;
 76: }
 77: 
 78: export interface CardHashData {
 79:   name: string;
 80:   cleanName: string;
 81:   modifiedOn: string;
 82:   extendedData: Array<{
 83:     name: string;
 84:     displayName: string;
 85:     value: string;
 86:   }>;
 87: }
 88: 
 89: export interface SyncOptions {
 90:   groupId?: string;
 91:   forceUpdate?: boolean;
 92:   skipImages?: boolean;
 93:   imagesOnly?: boolean;
 94:   silent?: boolean;
 95:   dryRun?: boolean;
 96: }
 97: 
 98: export interface CardChanges {
 99:   productId: number;
100:   name: string;
101:   cleanName: string;
102:   highResUrl: string;
103:   lowResUrl: string;
104:   lastUpdated: FieldValue;
105:   groupId: number;
106:   isNonCard: boolean;
107:   cardNumbers: string[];
108:   primaryCardNumber: string;
109: }
110: 
111: export interface PriceChanges {
112:   productId: number;
113:   lastUpdated: FieldValue;
114:   groupId: number;
115:   normal?: {
116:     directLowPrice: number | null;
117:     highPrice: number;
118:     lowPrice: number;
119:     marketPrice: number;
120:     midPrice: number;
121:     subTypeName: "Normal";
122:   };
123:   foil?: {
124:     directLowPrice: number | null;
125:     highPrice: number;
126:     lowPrice: number;
127:     marketPrice: number;
128:     midPrice: number;
129:     subTypeName: "Foil";
130:   };
131: }
</file>

<file path="src/utils/api.ts">
  1: import axios, { AxiosError } from "axios";
  2: import { CardProduct, CardPrice } from "../types";
  3: import { logger } from "./logger";
  4: 
  5: export class TcgcsvApi {
  6:   private readonly baseUrl = "https://tcgcsv.com/tcgplayer";
  7:   private readonly categoryId = "24"; // Final Fantasy TCG
  8: 
  9:   private async makeRequest<T>(endpoint: string): Promise<T> {
 10:     const url = `${this.baseUrl}/${endpoint}`;
 11:     logger.info(`Making request to: ${url}`);
 12: 
 13:     try {
 14:       const response = await axios.get<T>(url, {
 15:         timeout: 30000,
 16:         headers: {
 17:           "Accept": "application/json",
 18:           "User-Agent": "FFTCG-Sync-Service/1.0",
 19:         },
 20:       });
 21:       return response.data;
 22:     } catch (error) {
 23:       if (error instanceof AxiosError && error.response?.status === 403) {
 24:         throw new Error(`Access denied to TCGCSV API at path: ${endpoint}`);
 25:       }
 26:       throw error;
 27:     }
 28:   }
 29: 
 30:   async getGroups(): Promise<Array<{ groupId: string }>> {
 31:     const response = await this.makeRequest<{ results: Array<{ groupId: string }> }>(`${this.categoryId}/groups`);
 32:     logger.info(`Retrieved ${response.results.length} groups`);
 33:     return response.results;
 34:   }
 35: 
 36:   async getGroupProducts(groupId: string): Promise<CardProduct[]> {
 37:     const response = await this.makeRequest<{ results: CardProduct[] }>(`${this.categoryId}/${groupId}/products`);
 38:     logger.info(`Retrieved ${response.results.length} products for group ${groupId}`);
 39: 
 40:     // Transform the results to use correct image URLs
 41:     const products = response.results.map((product) => ({
 42:       ...product,
 43:       // No modification needed, keep original TCGPlayer URL
 44:     }));
 45: 
 46:     return products;
 47:   }
 48: 
 49:   async getGroupPrices(groupId: string): Promise<CardPrice[]> {
 50:     interface RawPriceData {
 51:       productId: number;
 52:       lowPrice: number | null;
 53:       midPrice: number | null;
 54:       highPrice: number | null;
 55:       marketPrice: number | null;
 56:       directLowPrice: number | null;
 57:       subTypeName: string;
 58:     }
 59: 
 60:     interface PriceResponse {
 61:       success: boolean;
 62:       errors: string[];
 63:       results: RawPriceData[];
 64:     }
 65: 
 66:     const response = await this.makeRequest<PriceResponse>(`${this.categoryId}/${groupId}/prices`);
 67:     logger.info(`Retrieved ${response.results.length} prices for group ${groupId}`);
 68: 
 69:     // Group prices by productId
 70:     const priceMap = new Map<number, CardPrice>();
 71: 
 72:     response.results.forEach((price) => {
 73:       const existing = priceMap.get(price.productId) || {
 74:         productId: price.productId,
 75:         lastUpdated: new Date(),
 76:       };
 77: 
 78:       if (price.subTypeName === "Normal") {
 79:         existing.normal = {
 80:           directLowPrice: price.directLowPrice,
 81:           highPrice: price.highPrice || 0,
 82:           lowPrice: price.lowPrice || 0,
 83:           marketPrice: price.marketPrice || 0,
 84:           midPrice: price.midPrice || 0,
 85:           subTypeName: "Normal",
 86:         };
 87:       } else if (price.subTypeName === "Foil") {
 88:         existing.foil = {
 89:           directLowPrice: price.directLowPrice,
 90:           highPrice: price.highPrice || 0,
 91:           lowPrice: price.lowPrice || 0,
 92:           marketPrice: price.marketPrice || 0,
 93:           midPrice: price.midPrice || 0,
 94:           subTypeName: "Foil",
 95:         };
 96:       }
 97: 
 98:       priceMap.set(price.productId, existing);
 99:     });
100: 
101:     return Array.from(priceMap.values());
102:   }
103: }
104: 
105: export const tcgcsvApi = new TcgcsvApi();
</file>

<file path="src/utils/cache.ts">
 1: // src/utils/cache.ts
 2: export class Cache<T> {
 3:   private cache = new Map<
 4:     string,
 5:     {
 6:       data: T;
 7:       timestamp: number;
 8:     }
 9:   >();
10:   private readonly ttl: number;
11:   private readonly maxSize: number;
12: 
13:   constructor(ttlMinutes = 15, maxSize = 5000) {
14:     this.ttl = ttlMinutes * 60 * 1000;
15:     this.maxSize = maxSize;
16:   }
17: 
18:   set(key: string, value: T): void {
19:     if (this.cache.size >= this.maxSize) {
20:       const entries = Array.from(this.cache.entries());
21:       const oldestEntries = entries
22:         .sort(([, a], [, b]) => a.timestamp - b.timestamp)
23:         .slice(0, Math.floor(this.maxSize * 0.1));
24: 
25:       oldestEntries.forEach(([key]) => this.cache.delete(key));
26:     }
27: 
28:     this.cache.set(key, {
29:       data: value,
30:       timestamp: Date.now(),
31:     });
32:   }
33: 
34:   setBulk(entries: Array<[string, T]>): void {
35:     entries.forEach(([key, value]) => this.set(key, value));
36:   }
37: 
38:   get(key: string): T | null {
39:     const cached = this.cache.get(key);
40:     if (!cached) return null;
41: 
42:     if (Date.now() - cached.timestamp > this.ttl) {
43:       this.cache.delete(key);
44:       return null;
45:     }
46: 
47:     return cached.data;
48:   }
49: 
50:   getBulk(keys: string[]): Map<string, T> {
51:     const results = new Map<string, T>();
52:     keys.forEach((key) => {
53:       const value = this.get(key);
54:       if (value !== null) {
55:         results.set(key, value);
56:       }
57:     });
58:     return results;
59:   }
60: 
61:   clear(): void {
62:     this.cache.clear();
63:   }
64: 
65:   has(key: string): boolean {
66:     return this.get(key) !== null;
67:   }
68: }
</file>

<file path="src/utils/logger.ts">
 1: // src/utils/logger.ts
 2: import { db } from "../config/firebase";
 3: import { environment } from "../config/environment";
 4: import { SyncResult } from "../types";
 5: 
 6: export type LogData = Record<string, unknown>;
 7: 
 8: export interface SyncStats {
 9:   startTime: Date;
10:   endTime?: Date;
11:   totalItems: number;
12:   successCount: number;
13:   errorCount: number;
14:   duration?: number;
15: }
16: 
17: export class Logger {
18:   private readonly COLLECTION = "logs";
19: 
20:   async info(message: string, data?: LogData | SyncResult): Promise<void> {
21:     await this.log("INFO", message, data);
22:   }
23: 
24:   async error(message: string, data?: LogData | { error: unknown }): Promise<void> {
25:     await this.log("ERROR", message, data);
26:   }
27: 
28:   async logSyncStats(stats: SyncStats): Promise<void> {
29:     const duration = stats.endTime ? (stats.endTime.getTime() - stats.startTime.getTime()) / 1000 : undefined;
30: 
31:     const successRate = ((stats.successCount / stats.totalItems) * 100).toFixed(1);
32: 
33:     console.log({
34:       duration: duration ? `${duration}s` : "unknown",
35:       successRate: `${successRate}%`,
36:       totalItems: stats.totalItems,
37:       successful: stats.successCount,
38:       errors: stats.errorCount,
39:     });
40: 
41:     if (!environment.isLocal) {
42:       await db.collection(this.COLLECTION).add({
43:         type: "SYNC_STATS",
44:         timestamp: new Date(),
45:         stats: {
46:           ...stats,
47:           duration,
48:           successRate: parseFloat(successRate),
49:         },
50:       });
51:     }
52:   }
53: 
54:   async log(
55:     level: "INFO" | "ERROR",
56:     message: string,
57:     metadata?: LogData | SyncResult | { error: unknown }
58:   ): Promise<void> {
59:     const entry = {
60:       timestamp: new Date(),
61:       level,
62:       message,
63:       metadata: metadata || null,
64:       environment: environment.nodeEnv,
65:     };
66: 
67:     // Always log to console with appropriate level
68:     const logFn = level === "ERROR" ? console.error : console.log;
69:     logFn(`[${level}] ${message}`, metadata || "");
70: 
71:     // Only log to Firestore if not in local development
72:     if (!environment.isLocal) {
73:       try {
74:         await db.collection(this.COLLECTION).add(entry);
75:       } catch (error) {
76:         console.error("Failed to write log to Firestore:", error);
77:         // Don't throw the error to prevent disrupting the application
78:       }
79:     }
80:   }
81: }
82: 
83: export const logger = new Logger();
</file>

<file path="src/utils/rateLimiter.ts">
 1: // src/utils/rateLimiter.ts
 2: import { logger } from "./logger";
 3: 
 4: export class RateLimiter {
 5:   private queue: Array<() => Promise<unknown>> = [];
 6:   private processing = false;
 7:   private readonly maxRate = 500;
 8:   private readonly interval = 1000;
 9:   private readonly maxConcurrent = 5;
10:   private currentConcurrent = 0;
11: 
12:   async add<T>(operation: () => Promise<T>): Promise<T> {
13:     return new Promise<T>((resolve, reject) => {
14:       this.queue.push(async () => {
15:         try {
16:           const result = await operation();
17:           resolve(result);
18:           return result;
19:         } catch (error) {
20:           reject(error);
21:           throw error;
22:         }
23:       });
24: 
25:       if (!this.processing) {
26:         void this.process();
27:       }
28:     });
29:   }
30: 
31:   private async process(): Promise<void> {
32:     this.processing = true;
33:     const batchSize = Math.floor(this.maxRate / (this.interval / 1000));
34: 
35:     while (this.queue.length > 0 && this.currentConcurrent < this.maxConcurrent) {
36:       const batch = this.queue.splice(0, Math.min(batchSize, this.queue.length));
37:       this.currentConcurrent++;
38: 
39:       try {
40:         await Promise.all(batch.map((op) => op()));
41:       } catch (error) {
42:         logger.error("Error processing rate-limited batch", { error });
43:       } finally {
44:         this.currentConcurrent--;
45:       }
46: 
47:       if (this.queue.length > 0) {
48:         await new Promise((resolve) => setTimeout(resolve, this.interval));
49:       }
50:     }
51: 
52:     this.processing = this.queue.length > 0;
53:     if (this.processing) {
54:       void this.process();
55:     }
56:   }
57: }
</file>

<file path="src/utils/retention.ts">
 1: import { db } from "../config/firebase";
 2: import { logger } from "./logger";
 3: 
 4: export class RetentionService {
 5:   private readonly RETENTION_CONFIG = {
 6:     logs: 7,
 7:     cardHashes: 7,
 8:     priceHashes: 7,
 9:     syncMetadata: 7,
10:   };
11: 
12:   async cleanOldData(): Promise<void> {
13:     try {
14:       logger.info("Starting data retention cleanup");
15: 
16:       for (const [collection, days] of Object.entries(this.RETENTION_CONFIG)) {
17:         const cutoff = new Date();
18:         cutoff.setDate(cutoff.getDate() - days);
19: 
20:         const snapshot = await db.collection(collection).where("lastUpdated", "<", cutoff).get();
21: 
22:         if (!snapshot.empty) {
23:           const batch = db.batch();
24:           snapshot.docs.forEach((doc) => batch.delete(doc.ref));
25:           await batch.commit();
26: 
27:           logger.info(`Cleaned up ${snapshot.size} documents from ${collection}`);
28:         }
29:       }
30: 
31:       logger.info("Data retention cleanup completed");
32:     } catch (error) {
33:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
34:       logger.error("Data retention cleanup failed", { error: errorMessage });
35:       throw error;
36:     }
37:   }
38: }
39: 
40: export const retention = new RetentionService();
</file>

<file path="src/utils/retry.ts">
 1: // src/utils/retry.ts
 2: import { logger } from "./logger";
 3: 
 4: export class RetryWithBackoff {
 5:   private readonly maxRetries: number;
 6:   private readonly initialDelay: number;
 7:   private readonly maxDelay: number;
 8:   private readonly backoffFactor: number;
 9: 
10:   constructor(maxRetries = 3, initialDelay = 1000, maxDelay = 10000, backoffFactor = 2) {
11:     this.maxRetries = maxRetries;
12:     this.initialDelay = initialDelay;
13:     this.maxDelay = maxDelay;
14:     this.backoffFactor = backoffFactor;
15:   }
16: 
17:   async execute<T>(operation: () => Promise<T>): Promise<T> {
18:     let lastError: Error | null = null;
19:     let delay = this.initialDelay;
20: 
21:     for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
22:       try {
23:         return await operation();
24:       } catch (error) {
25:         lastError = error instanceof Error ? error : new Error(String(error));
26: 
27:         if (attempt === this.maxRetries) {
28:           break;
29:         }
30: 
31:         if (this.isNonRetryableError(lastError)) {
32:           throw lastError;
33:         }
34: 
35:         logger.info(`Retry attempt ${attempt + 1} of ${this.maxRetries}`, {
36:           error: lastError.message,
37:           delay,
38:         });
39: 
40:         await new Promise((resolve) => setTimeout(resolve, delay));
41:         delay = Math.min(delay * this.backoffFactor, this.maxDelay);
42:       }
43:     }
44: 
45:     throw lastError || new Error("Operation failed after retries");
46:   }
47: 
48:   private isNonRetryableError(error: Error): boolean {
49:     const nonRetryableErrors = ["PERMISSION_DENIED", "INVALID_ARGUMENT", "NOT_FOUND", "ALREADY_EXISTS"];
50: 
51:     return nonRetryableErrors.some((errorType) => error.message.includes(errorType));
52:   }
53: }
</file>

<file path="src/utils/timeout.ts">
 1: // src/utils/timeout.ts
 2: export class TimeoutError extends Error {
 3:   constructor(message: string) {
 4:     super(message);
 5:     this.name = "TimeoutError";
 6:   }
 7: }
 8: 
 9: export function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
10:   return Promise.race([
11:     promise,
12:     new Promise<T>((_, reject) => {
13:       setTimeout(() => {
14:         reject(new TimeoutError(`Operation timed out after ${timeoutMs}ms`));
15:       }, timeoutMs);
16:     }),
17:   ]);
18: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "include": [
3:     ".eslintrc.js"
4:   ]
5: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "moduleResolution": "node",
 5:     "noImplicitReturns": true,
 6:     "noUnusedLocals": true,
 7:     "outDir": "lib",
 8:     "sourceMap": true,
 9:     "strict": true,
10:     "target": "es2017",
11:     "skipLibCheck": true, // Add this line
12:     "esModuleInterop": true, // Make sure this is present
13:     "resolveJsonModule": true, // Add this line
14:     "baseUrl": "./src", // Add this line
15:     "paths": {
16:       // Add this section
17:       "*": ["*"]
18:     }
19:   },
20:   "compileOnSave": true,
21:   "include": ["src"],
22:   "exclude": ["node_modules", "lib"]
23: }
</file>

</repository_files>
