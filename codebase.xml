This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-05T06:10:12.885Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
.firebaserc
.gitignore
.npmrc
.prettierrc
.repomixignore
firebase.json
firestore.indexes.json
firestore.rules
package.json
repomix.config.json
src/config/environment.ts
src/config/firebase.ts
src/config/r2.ts
src/index.ts
src/scripts/cleanup.ts
src/scripts/prodSync.ts
src/scripts/setenv.ts
src/scripts/syncAll.ts
src/scripts/syncCards.ts
src/scripts/syncPrices.ts
src/scripts/testSync.ts
src/services/cardSync.ts
src/services/priceSync.ts
src/services/storageService.ts
src/types/index.ts
src/utils/api.ts
src/utils/cache.ts
src/utils/logger.ts
src/utils/rateLimiter.ts
src/utils/retention.ts
src/utils/retry.ts
src/utils/timeout.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     sourceType: "module",
19:   },
20:   ignorePatterns: [
21:     "/lib/**/*",
22:     "/generated/**/*",
23:     "*.js", // Add this line to ignore JS files
24:   ],
25:   plugins: ["@typescript-eslint", "import"],
26:   rules: {
27:     quotes: ["error", "double"],
28:     "import/no-unresolved": 0,
29:     indent: ["error", 2],
30:     "linebreak-style": 0, // Disable linebreak-style checks
31:     "object-curly-spacing": ["error", "always"],
32:     "max-len": ["error", { code: 120 }],
33:     "@typescript-eslint/no-explicit-any": "warn",
34:     "require-jsdoc": 0,
35:     "valid-jsdoc": 0,
36:     "@typescript-eslint/no-var-requires": 0,
37:     camelcase: 0,
38:   },
39: };
</file>

<file path=".firebaserc">
1: {
2:   "projects": {
3:     "default": "fftcg-sync-service"
4:   }
5: }
</file>

<file path=".gitignore">
 1: # Dependencies
 2: node_modules/
 3: 
 4: # Build output
 5: lib/
 6: dist/
 7: 
 8: # Environment variables
 9: .env
10: .env.local
11: .env.*.local
12: 
13: # Service account keys
14: service_account_key.json
15: *-service-account.json
16: 
17: # Firebase
18: .firebase/
19: firebase-debug.log
20: firebase-debug.*.log
21: 
22: # IDE
23: .vscode/
24: .idea/
25: 
26: # Logs
27: *.log
</file>

<file path=".npmrc">
1: //us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/:_authToken=${NPM_TOKEN}
2: @google-cloud:registry=https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/
</file>

<file path=".prettierrc">
1: {
2:   "singleQuote": false,
3:   "trailingComma": "es5",
4:   "bracketSpacing": true,
5:   "semi": true,
6:   "printWidth": 120,
7:   "tabWidth": 2,
8:   "endOfLine": "auto"
9: }
</file>

<file path=".repomixignore">
1: lib/**
2: !*/
3: !.gitignore
4: service_account_key.json
5: !src/**
</file>

<file path="firebase.json">
 1: {
 2:   "functions": {
 3:     "source": ".",
 4:     "codebase": "default",
 5:     "runtime": "nodejs18",
 6:     "ignore": [
 7:       "node_modules",
 8:       ".git",
 9:       "firebase-debug.log",
10:       "firebase-debug.*.log",
11:       "*.local"
12:     ],
13:     "predeploy": [
14:       "npm run lint",
15:       "npm run build"
16:     ]
17:   },
18:   "firestore": {
19:     "rules": "firestore.rules",
20:     "indexes": "firestore.indexes.json"
21:   },
22:   "emulators": {
23:     "functions": {
24:       "port": 5001
25:     },
26:     "firestore": {
27:       "port": 8080
28:     },
29:     "ui": {
30:       "enabled": true
31:     },
32:     "singleProjectMode": true
33:   }
34: }
</file>

<file path="firestore.indexes.json">
 1: {
 2:   "indexes": [],
 3:   "fieldOverrides": [
 4:     {
 5:       "collectionGroup": "cards",
 6:       "fieldPath": "imageMetadata",
 7:       "indexes": []
 8:     },
 9:     {
10:       "collectionGroup": "cards",
11:       "fieldPath": "extendedData",
12:       "indexes": []
13:     },
14:     {
15:       "collectionGroup": "cards",
16:       "fieldPath": "lastUpdated",
17:       "indexes": []
18:     },
19:     {
20:       "collectionGroup": "prices",
21:       "fieldPath": "lastUpdated",
22:       "indexes": []
23:     },
24:     {
25:       "collectionGroup": "historicalPrices",
26:       "fieldPath": "lastUpdated",
27:       "indexes": []
28:     }
29:   ]
30: }
</file>

<file path="firestore.rules">
1: rules_version = '2';
2: service cloud.firestore {
3:   match /databases/{database}/documents {
4:     match /{document=**} {
5:       allow read, write: if false;
6:     }
7:   }
8: }
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "lint": "eslint --ext .js,.ts .",
 5:     "lint:fix": "eslint --ext .js,.ts . --fix",
 6:     "build": "rimraf lib && tsc",
 7:     "build:watch": "tsc --watch",
 8:     "serve": "npm run build && firebase emulators:start --only functions,firestore",
 9:     "shell": "npm run build && firebase functions:shell",
10:     "start": "npm run shell",
11:     "deploy": "firebase deploy --only functions",
12:     "logs": "firebase functions:log"
13:   },
14:   "engines": {
15:     "node": "18"
16:   },
17:   "main": "lib/index.js",
18:   "dependencies": {
19:     "@aws-sdk/client-s3": "^3.485.0",
20:     "@aws-sdk/s3-request-presigner": "^3.485.0",
21:     "axios": "^1.7.7",
22:     "cors": "^2.8.5",
23:     "dotenv": "^16.4.7",
24:     "express": "^4.18.2",
25:     "firebase-admin": "^12.0.0",
26:     "firebase-functions": "^6.2.0"
27:   },
28:   "devDependencies": {
29:     "@types/cors": "^2.8.17",
30:     "@types/express": "^4.17.21",
31:     "@typescript-eslint/eslint-plugin": "^5.12.0",
32:     "@typescript-eslint/parser": "^5.12.0",
33:     "eslint": "^8.9.0",
34:     "eslint-config-google": "^0.14.0",
35:     "eslint-plugin-import": "^2.25.4",
36:     "firebase-functions-test": "^3.1.0",
37:     "rimraf": "^5.0.0",
38:     "typescript": "^4.9.0"
39:   },
40:   "private": true,
41:   "publishConfig": {
42:     "registry": "https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/"
43:   }
44: }
</file>

<file path="repomix.config.json">
 1: {
 2:   "output": {
 3:     "filePath": "C:\\VSCode\\fftcg-sync-service\\codebase.xml",
 4:     "style": "xml",
 5:     "removeComments": false,
 6:     "removeEmptyLines": false,
 7:     "topFilesLength": 5,
 8:     "showLineNumbers": true,
 9:     "copyToClipboard": false
10:   },
11:   "include": [],
12:   "ignore": {
13:     "useGitignore": false,
14:     "useDefaultPatterns": true,
15:     "customPatterns": []
16:   },
17:   "security": {
18:     "enableSecurityCheck": true
19:   }
20: }
</file>

<file path="src/config/environment.ts">
 1: // src/config/environment.ts
 2: import * as functions from "firebase-functions";
 3: import * as dotenv from "dotenv";
 4: 
 5: // Load .env file in development
 6: if (process.env.NODE_ENV !== "production") {
 7:   dotenv.config();
 8: }
 9: 
10: // Helper function to get config value
11: function getConfigValue(key: string): string {
12:   if (process.env.NODE_ENV === "production") {
13:     const config = functions.config();
14:     return config.r2?.[key.toLowerCase().replace("r2_", "")] || "";
15:   }
16:   return process.env[key] || "";
17: }
18: 
19: export const environment = {
20:   nodeEnv: process.env.NODE_ENV || "development",
21:   isLocal: process.env.NODE_ENV !== "production",
22:   r2: {
23:     accountId: getConfigValue("R2_ACCOUNT_ID"),
24:     accessKeyId: getConfigValue("R2_ACCESS_KEY_ID"),
25:     secretAccessKey: getConfigValue("R2_SECRET_ACCESS_KEY"),
26:     bucketName: getConfigValue("R2_BUCKET_NAME"),
27:     storagePath: getConfigValue("R2_STORAGE_PATH"),
28:     customDomain: getConfigValue("R2_CUSTOM_DOMAIN"),
29:   } as { [key: string]: string },
30: };
31: 
32: // Validate required environment variables
33: if (!environment.isLocal) {
34:   const required = ["R2_ACCOUNT_ID", "R2_ACCESS_KEY_ID", "R2_SECRET_ACCESS_KEY", "R2_BUCKET_NAME"];
35:   const missing = required.filter((key) => !(environment.r2[key.toLowerCase()] as string));
36:   if (missing.length) {
37:     throw new Error(`Missing required environment variables: ${missing.join(", ")}`);
38:   }
39: }
</file>

<file path="src/config/firebase.ts">
 1: // src/config/firebase.ts
 2: import * as admin from "firebase-admin";
 3: 
 4: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 5: const db = admin.firestore(app);
 6: 
 7: // Enable ignoreUndefinedProperties and other settings
 8: db.settings({
 9:   ignoreUndefinedProperties: true,
10:   timestampsInSnapshots: true,
11: });
12: 
13: export { db };
14: 
15: export const COLLECTION = {
16:   CARDS: "cards",
17:   PRICES: "prices",
18:   SYNC_METADATA: "syncMetadata",
19:   LOGS: "logs",
20:   CARD_HASHES: "cardHashes",
21:   PRICE_HASHES: "priceHashes",
22:   IMAGE_METADATA: "imageMetadata",
23:   HISTORICAL_PRICES: "historicalPrices",
24:   CARD_DELTAS: "cardDeltas",
25:   PRICE_DELTAS: "priceDeltas",
26: } as const;
27: 
28: export const BASE_URL = "https://tcgcsv.com/tcgplayer";
29: export const FFTCG_CATEGORY_ID = "24";
30: 
31: export const runtimeOpts = {
32:   timeoutSeconds: 540,
33:   memory: "1GiB",
34: } as const;
</file>

<file path="src/config/r2.ts">
 1: // src/config/r2.ts
 2: 
 3: import * as dotenv from "dotenv";
 4: dotenv.config();
 5: 
 6: export const R2_CONFIG = {
 7:   ACCOUNT_ID: process.env.R2_ACCOUNT_ID || "",
 8:   ACCESS_KEY_ID: process.env.R2_ACCESS_KEY_ID || "",
 9:   SECRET_ACCESS_KEY: process.env.R2_SECRET_ACCESS_KEY || "",
10:   BUCKET_NAME: process.env.R2_BUCKET_NAME || "",
11:   STORAGE_PATH: process.env.R2_STORAGE_PATH || "",
12:   CUSTOM_DOMAIN: process.env.R2_CUSTOM_DOMAIN || "",
13: } as const;
14: 
15: if (!R2_CONFIG.ACCOUNT_ID) {
16:   console.warn("Missing R2_ACCOUNT_ID in .env file");
17: }
18: if (!R2_CONFIG.ACCESS_KEY_ID) {
19:   console.warn("Missing R2_ACCESS_KEY_ID in .env file");
20: }
21: if (!R2_CONFIG.SECRET_ACCESS_KEY) {
22:   console.warn("Missing R2_SECRET_ACCESS_KEY in .env file");
23: }
24: if (!R2_CONFIG.BUCKET_NAME) {
25:   console.warn("Missing R2_BUCKET_NAME in .env file");
26: }
27: if (!R2_CONFIG.STORAGE_PATH) {
28:   console.warn("Missing R2_STORAGE_PATH in .env file");
29: }
30: if (!R2_CONFIG.CUSTOM_DOMAIN) {
31:   console.warn("Missing R2_CUSTOM_DOMAIN in .env file");
32: }
33: 
34: console.log("R2 Config:", R2_CONFIG);
</file>

<file path="src/index.ts">
  1: // src/index.ts
  2: import { onCall, HttpsError } from "firebase-functions/v2/https";
  3: import { onSchedule } from "firebase-functions/v2/scheduler";
  4: import { logger } from "firebase-functions/v2";
  5: import { cardSync } from "./services/cardSync";
  6: import { priceSync } from "./services/priceSync";
  7: import { retention } from "./utils/retention";
  8: import { runtimeOpts } from "./config/firebase";
  9: import * as dotenv from "dotenv";
 10: 
 11: dotenv.config();
 12: 
 13: // Manual card sync endpoint as a callable function
 14: export const manualCardSync = onCall(
 15:   {
 16:     memory: runtimeOpts.memory,
 17:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 18:     region: "us-central1",
 19:   },
 20:   async (request) => {
 21:     try {
 22:       const forceUpdate = request.data.force === true;
 23:       const groupId = request.data.groupId as string | undefined;
 24: 
 25:       const result = await cardSync.syncCards({
 26:         forceUpdate,
 27:         groupId,
 28:         skipImages: false,
 29:         imagesOnly: false,
 30:         silent: false,
 31:         dryRun: false,
 32:       });
 33: 
 34:       return result;
 35:     } catch (error) {
 36:       logger.error("Manual card sync failed", { error });
 37:       throw new HttpsError(
 38:         "internal",
 39:         error instanceof Error ? error.message : "Unknown error"
 40:       );
 41:     }
 42:   }
 43: );
 44: 
 45: // Manual price sync endpoint as a callable function
 46: export const manualPriceSync = onCall(
 47:   {
 48:     memory: runtimeOpts.memory,
 49:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 50:     region: "us-central1",
 51:   },
 52:   async (request) => {
 53:     try {
 54:       const forceUpdate = request.data.force === true;
 55:       const groupId = request.data.groupId as string | undefined;
 56: 
 57:       const result = await priceSync.syncPrices({
 58:         forceUpdate,
 59:         groupId,
 60:         silent: false,
 61:         dryRun: false,
 62:       });
 63: 
 64:       return result;
 65:     } catch (error) {
 66:       logger.error("Manual price sync failed", { error });
 67:       throw new HttpsError(
 68:         "internal",
 69:         error instanceof Error ? error.message : "Unknown error"
 70:       );
 71:     }
 72:   }
 73: );
 74: 
 75: // Manual cleanup endpoint as a callable function
 76: export const manualCleanup = onCall(
 77:   {
 78:     memory: runtimeOpts.memory,
 79:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 80:     region: "us-central1",
 81:   },
 82:   async () => {
 83:     try {
 84:       await retention.cleanOldData();
 85:       return { success: true };
 86:     } catch (error) {
 87:       logger.error("Manual cleanup failed", { error });
 88:       throw new HttpsError(
 89:         "internal",
 90:         error instanceof Error ? error.message : "Unknown error"
 91:       );
 92:     }
 93:   }
 94: );
 95: 
 96: // Scheduled Functions
 97: export const scheduledCardSync = onSchedule(
 98:   {
 99:     schedule: "0 21 * * *", // Daily at 21:00 UTC
100:     timeZone: "UTC",
101:     memory: runtimeOpts.memory,
102:     timeoutSeconds: runtimeOpts.timeoutSeconds,
103:     retryCount: 3,
104:   },
105:   async () => {
106:     try {
107:       logger.info("Starting scheduled card sync");
108:       const result = await cardSync.syncCards({
109:         forceUpdate: false,
110:         skipImages: false,
111:         imagesOnly: false,
112:         silent: false,
113:         dryRun: false,
114:       });
115:       logger.info("Card sync completed", result);
116:     } catch (error) {
117:       logger.error("Scheduled card sync failed", { error });
118:       throw error;
119:     }
120:   }
121: );
122: 
123: export const scheduledPriceSync = onSchedule(
124:   {
125:     schedule: "30 21 * * *", // Daily at 21:30 UTC
126:     timeZone: "UTC",
127:     memory: runtimeOpts.memory,
128:     timeoutSeconds: runtimeOpts.timeoutSeconds,
129:     retryCount: 3,
130:   },
131:   async () => {
132:     try {
133:       logger.info("Starting scheduled price sync");
134:       const result = await priceSync.syncPrices({
135:         forceUpdate: false,
136:         silent: false,
137:         dryRun: false,
138:       });
139:       logger.info("Price sync completed", result);
140:     } catch (error) {
141:       logger.error("Scheduled price sync failed", { error });
142:       throw error;
143:     }
144:   }
145: );
146: 
147: export const scheduledCleanup = onSchedule(
148:   {
149:     schedule: "0 22 * * *", // Daily at 22:00 UTC
150:     timeZone: "UTC",
151:     memory: runtimeOpts.memory,
152:     timeoutSeconds: runtimeOpts.timeoutSeconds,
153:     retryCount: 3,
154:   },
155:   async () => {
156:     try {
157:       logger.info("Starting scheduled cleanup");
158:       await retention.cleanOldData();
159:       logger.info("Cleanup completed");
160:     } catch (error) {
161:       logger.error("Scheduled cleanup failed", { error });
162:       throw error;
163:     }
164:   }
165: );
</file>

<file path="src/scripts/cleanup.ts">
 1: import { retention } from "../utils/retention";
 2: 
 3: async function main() {
 4:   console.log("Starting manual cleanup...");
 5:   try {
 6:     await retention.cleanOldData();
 7:     console.log("Cleanup completed successfully");
 8:   } catch (error) {
 9:     console.error("Cleanup failed:", error);
10:     process.exit(1);
11:   }
12: }
13: 
14: main();
</file>

<file path="src/scripts/prodSync.ts">
  1: // src/scripts/prodSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger, LogData } from "../utils/logger";
  5: 
  6: 
  7: interface SyncStats {
  8:   success: boolean;
  9:   itemsProcessed: number;
 10:   itemsUpdated: number;
 11:   errors: string[];
 12:   duration: number;
 13: }
 14: 
 15: interface SyncOptions {
 16:   forceUpdate?: boolean;
 17:   groupId?: string;
 18:   cardsOnly?: boolean;
 19:   pricesOnly?: boolean;
 20: }
 21: 
 22: // Move runProductionSync into a class for better organization
 23: class ProductionSync {
 24:   async run(options: SyncOptions = {}) {
 25:     const startTime = Date.now();
 26:     const results: {
 27:       cards?: SyncStats;
 28:       prices?: SyncStats;
 29:     } = {};
 30: 
 31:     try {
 32:       logger.info("Starting production sync", { options } as LogData);
 33: 
 34:       // Run card sync if not prices-only
 35:       if (!options.pricesOnly) {
 36:         logger.info("Starting card sync...");
 37:         const cardResult = await cardSync.syncCards({
 38:           forceUpdate: options.forceUpdate,
 39:           groupId: options.groupId,
 40:         });
 41: 
 42:         results.cards = {
 43:           success: cardResult.success,
 44:           itemsProcessed: cardResult.itemsProcessed,
 45:           itemsUpdated: cardResult.itemsUpdated,
 46:           errors: cardResult.errors,
 47:           duration: cardResult.timing.duration || 0,
 48:         };
 49: 
 50:         logger.info("Card sync completed", { stats: results.cards } as LogData);
 51:       }
 52: 
 53:       // Run price sync if not cards-only
 54:       if (!options.cardsOnly) {
 55:         logger.info("Starting price sync...");
 56:         const priceResult = await priceSync.syncPrices({
 57:           forceUpdate: options.forceUpdate,
 58:           groupId: options.groupId,
 59:         });
 60: 
 61:         results.prices = {
 62:           success: priceResult.success,
 63:           itemsProcessed: priceResult.itemsProcessed,
 64:           itemsUpdated: priceResult.itemsUpdated,
 65:           errors: priceResult.errors,
 66:           duration: priceResult.timing.duration || 0,
 67:         };
 68: 
 69:         logger.info("Price sync completed", { stats: results.prices } as LogData);
 70:       }
 71: 
 72:       const totalDuration = (Date.now() - startTime) / 1000;
 73:       logger.info(`Full sync completed in ${totalDuration}s`, { results } as LogData);
 74: 
 75:       return results;
 76:     } catch (error) {
 77:       logger.error("Production sync failed", { error } as LogData);
 78:       throw error;
 79:     }
 80:   }
 81: }
 82: 
 83: function parseArgs(args: string[]): SyncOptions {
 84:   const options: SyncOptions = {};
 85: 
 86:   for (let i = 0; i < args.length; i++) {
 87:     switch (args[i]) {
 88:     case "--force":
 89:       options.forceUpdate = true;
 90:       break;
 91:     case "--group":
 92:       options.groupId = args[++i];
 93:       break;
 94:     case "--cards-only":
 95:       options.cardsOnly = true;
 96:       break;
 97:     case "--prices-only":
 98:       options.pricesOnly = true;
 99:       break;
100:     case "--help":
101:       printHelp();
102:       process.exit(0);
103:     }
104:   }
105: 
106:   return options;
107: }
108: 
109: function printHelp() {
110:   console.log(`
111: Usage: npx ts-node src/scripts/prodSync.ts [options]
112: 
113: Options:
114:   --force         Force update all items regardless of changes
115:   --group <id>    Sync specific group ID only
116:   --cards-only    Only sync card data
117:   --prices-only   Only sync price data
118:   --help          Show this help message
119:   
120: Examples:
121:   npx ts-node src/scripts/prodSync.ts
122:   npx ts-node src/scripts/prodSync.ts --force
123:   npx ts-node src/scripts/prodSync.ts --group 23244
124:   npx ts-node src/scripts/prodSync.ts --cards-only
125:   `);
126: }
127: 
128: // Create singleton instance
129: export const productionSync = new ProductionSync();
130: 
131: // Command line execution
132: async function main() {
133:   const args = process.argv.slice(2);
134:   const options = parseArgs(args);
135: 
136:   console.log("Starting production sync with options:", options);
137: 
138:   try {
139:     const results = await productionSync.run(options);
140:     console.log("Sync completed successfully!");
141:     console.log(JSON.stringify(results, null, 2));
142:     process.exit(0);
143:   } catch (error) {
144:     console.error("Sync failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Run if called directly
150: if (require.main === module) {
151:   main();
152: }
</file>

<file path="src/scripts/setenv.ts">
 1: // scripts/setenv.ts
 2: import * as dotenv from "dotenv";
 3: import { exec } from "child_process";
 4: import { promisify } from "util";
 5: 
 6: const execAsync = promisify(exec);
 7: 
 8: async function setFirebaseConfig() {
 9:   try {
10:     dotenv.config();
11: 
12:     const config = {
13:       account_id: process.env.R2_ACCOUNT_ID,
14:       access_key_id: process.env.R2_ACCESS_KEY_ID,
15:       secret_access_key: process.env.R2_SECRET_ACCESS_KEY,
16:       bucket_name: process.env.R2_BUCKET_NAME,
17:       storage_path: process.env.R2_STORAGE_PATH,
18:       custom_domain: process.env.R2_CUSTOM_DOMAIN,
19:     };
20: 
21:     // Remove existing config
22:     await execAsync("firebase functions:config:unset r2");
23: 
24:     // Set new config
25:     const configString = Object.entries(config)
26:       .map(([key, value]) => `r2.${key}="${value}"`)
27:       .join(" ");
28: 
29:     await execAsync(`firebase functions:config:set ${configString}`);
30:     console.log("Firebase config updated successfully");
31:   } catch (error) {
32:     console.error("Error setting Firebase config:", error);
33:   }
34: }
35: 
36: setFirebaseConfig();
</file>

<file path="src/scripts/syncAll.ts">
 1: import { cardSync } from "../services/cardSync";
 2: import { priceSync } from "../services/priceSync";
 3: 
 4: async function main() {
 5:   console.log("Starting full sync...");
 6: 
 7:   try {
 8:     console.log("\n1. Running card sync...");
 9:     const cardResult = await cardSync.syncCards();
10:     console.log("Card sync completed:", {
11:       success: cardResult.success,
12:       processed: cardResult.itemsProcessed,
13:       updated: cardResult.itemsUpdated,
14:       errors: cardResult.errors.length,
15:     });
16: 
17:     console.log("\n2. Running price sync...");
18:     const priceResult = await priceSync.syncPrices();
19:     console.log("Price sync completed:", {
20:       success: priceResult.success,
21:       processed: priceResult.itemsProcessed,
22:       updated: priceResult.itemsUpdated,
23:       errors: priceResult.errors.length,
24:     });
25: 
26:     const allErrors = [...cardResult.errors, ...priceResult.errors];
27:     if (allErrors.length > 0) {
28:       console.log("\nErrors encountered:");
29:       allErrors.forEach((error) => console.log(`- ${error}`));
30:     }
31: 
32:     console.log("\nFull sync completed!");
33:   } catch (error) {
34:     console.error("Full sync failed:", error);
35:     process.exit(1);
36:   }
37: }
38: 
39: main();
</file>

<file path="src/scripts/syncCards.ts">
 1: import { cardSync } from "../services/cardSync";
 2: 
 3: async function main() {
 4:   try {
 5:     console.log("Starting manual card sync...");
 6:     const result = await cardSync.syncCards();
 7:     console.log("Card sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Card sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/syncPrices.ts">
 1: import { priceSync } from "../services/priceSync";
 2: 
 3: async function main() {
 4:   console.log("Starting manual price sync...");
 5:   try {
 6:     const result = await priceSync.syncPrices();
 7:     console.log("Price sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Price sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/testSync.ts">
  1: // src/scripts/testSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger } from "../utils/logger";
  5: import { withTimeout, TimeoutError } from "../utils/timeout";
  6: import { storageService } from "../services/storageService";
  7: 
  8: const MAX_SYNC_TIME = 30 * 60 * 1000; // 30 minutes
  9: const TEST_GROUP_ID = "23244"; // Dawn of Heroes
 10: const TEST_PRODUCT_ID = 508343; // Example product ID
 11: const IMAGE_BASE_URL = "https://fftcgcompanion.com/card-images";
 12: 
 13: async function testImageProcessing() {
 14:   try {
 15:     logger.info("Testing image processing...");
 16: 
 17:     // Test with a valid image URL using correct format
 18:     const validImageResult = await storageService.processAndStoreImage(
 19:       `${IMAGE_BASE_URL}/${TEST_GROUP_ID}/${TEST_PRODUCT_ID}_200w.jpg`,
 20:       TEST_PRODUCT_ID,
 21:       TEST_GROUP_ID,
 22:       "1-001" // Example card number
 23:     );
 24: 
 25:     logger.info("Valid image processing result:", {
 26:       highResUrl: validImageResult.highResUrl,
 27:       lowResUrl: validImageResult.lowResUrl,
 28:       isPlaceholder: validImageResult.metadata.isPlaceholder,
 29:       originalUrl: validImageResult.metadata.originalUrl,
 30:     });
 31: 
 32:     // Verify the image URLs follow the correct pattern
 33:     const urlPattern = new RegExp(`^${IMAGE_BASE_URL}/.*_[24]00w.jpg$`);
 34:     const isValidImageUrl = urlPattern.test(validImageResult.metadata.originalUrl || "");
 35: 
 36:     if (!isValidImageUrl) {
 37:       logger.error("Image URL pattern does not match expected format", {
 38:         url: validImageResult.metadata.originalUrl,
 39:         expectedPattern: `${IMAGE_BASE_URL}/{groupId}/{productId}_200w.jpg`,
 40:       });
 41:     }
 42: 
 43:     // Test with invalid/missing image (should return placeholder)
 44:     const placeholderResult = await storageService.processAndStoreImage(
 45:       undefined,
 46:       TEST_PRODUCT_ID,
 47:       TEST_GROUP_ID,
 48:       "1-001"
 49:     );
 50: 
 51:     logger.info("Placeholder image result:", {
 52:       highResUrl: placeholderResult.highResUrl,
 53:       lowResUrl: placeholderResult.lowResUrl,
 54:       isPlaceholder: placeholderResult.metadata.isPlaceholder,
 55:     });
 56: 
 57:     return {
 58:       validImage: {
 59:         success: validImageResult.metadata.isPlaceholder !== true,
 60:         correctUrlPattern: isValidImageUrl,
 61:         urls: {
 62:           original: validImageResult.metadata.originalUrl,
 63:           highRes: validImageResult.highResUrl,
 64:           lowRes: validImageResult.lowResUrl,
 65:         },
 66:       },
 67:       placeholderImage: {
 68:         success: placeholderResult.metadata.isPlaceholder === true,
 69:         urls: {
 70:           highRes: placeholderResult.highResUrl,
 71:           lowRes: placeholderResult.lowResUrl,
 72:         },
 73:       },
 74:     };
 75:   } catch (error) {
 76:     logger.error("Image processing test failed:", { error });
 77:     throw error;
 78:   }
 79: }
 80: 
 81: async function testSync() {
 82:   try {
 83:     logger.info("Starting test sync with group " + TEST_GROUP_ID);
 84: 
 85:     // Test image processing first
 86:     logger.info("Testing image processing capabilities...");
 87:     const imageResults = await testImageProcessing();
 88:     logger.info("Image processing test results:", imageResults);
 89: 
 90:     // Monitor card sync with timeout
 91:     const cardResult = await withTimeout(
 92:       cardSync.syncCards({
 93:         groupId: TEST_GROUP_ID,
 94:         forceUpdate: true,
 95:       }),
 96:       MAX_SYNC_TIME
 97:     );
 98: 
 99:     logger.info("Card sync results:", {
100:       processed: cardResult.itemsProcessed,
101:       updated: cardResult.itemsUpdated,
102:       errors: cardResult.errors,
103:       timing: cardResult.timing,
104:     });
105: 
106:     // Monitor price sync with timeout
107:     const priceResult = await withTimeout(
108:       priceSync.syncPrices({
109:         groupId: TEST_GROUP_ID,
110:         forceUpdate: true,
111:       }),
112:       MAX_SYNC_TIME
113:     );
114: 
115:     logger.info("Price sync results:", {
116:       processed: priceResult.itemsProcessed,
117:       updated: priceResult.itemsUpdated,
118:       errors: priceResult.errors,
119:       timing: priceResult.timing,
120:     });
121: 
122:     // Validate results
123:     const validationResults = {
124:       imageProcessing: imageResults,
125:       cardSync: {
126:         success: cardResult.success,
127:         hasUpdates: cardResult.itemsUpdated > 0,
128:         hasErrors: cardResult.errors.length > 0,
129:       },
130:       priceSync: {
131:         success: priceResult.success,
132:         hasUpdates: priceResult.itemsUpdated > 0,
133:         hasErrors: priceResult.errors.length > 0,
134:       },
135:     };
136: 
137:     logger.info("Test validation results:", validationResults);
138: 
139:     // Log any errors
140:     const allErrors = [...cardResult.errors, ...priceResult.errors];
141:     if (allErrors.length > 0) {
142:       logger.error("Errors during sync:", { errors: allErrors });
143:     }
144: 
145:     return validationResults;
146:   } catch (error) {
147:     if (error instanceof TimeoutError) {
148:       logger.error("Sync operation timed out", { error });
149:     } else {
150:       logger.error("Test sync failed:", { error });
151:     }
152:     throw error;
153:   }
154: }
155: 
156: // Execute if run directly
157: if (require.main === module) {
158:   testSync()
159:     .then((results) => {
160:       console.log("Test sync completed successfully!");
161:       console.log("Results:", JSON.stringify(results, null, 2));
162:       process.exit(0);
163:     })
164:     .catch((error) => {
165:       console.error("Test failed:", error);
166:       process.exit(1);
167:     });
168: }
169: 
170: export { testSync, testImageProcessing };
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { storageService } from "./storageService";
  5: import { CardProduct, SyncResult, CardHashData, SyncOptions, CardChanges } from "../types";
  6: import { logger } from "../utils/logger";
  7: import { RateLimiter } from "../utils/rateLimiter";
  8: import { Cache } from "../utils/cache";
  9: import { RetryWithBackoff } from "../utils/retry";
 10: import * as crypto from "crypto";
 11: import { FieldValue } from "firebase-admin/firestore";
 12: 
 13: export class CardSyncService {
 14:   private readonly BATCH_SIZE = 1000;
 15:   private readonly MAX_PARALLEL_BATCHES = 5;
 16:   private readonly MAX_BATCH_OPERATIONS = 450; // Buffer below Firestore's 500 limit
 17: 
 18:   private readonly rateLimiter = new RateLimiter();
 19:   private readonly cache = new Cache<string>(15); // 15 minute TTL
 20:   private readonly retry = new RetryWithBackoff();
 21: 
 22:   private calculateHash(data: CardHashData): string {
 23:     return crypto
 24:       .createHash("md5")
 25:       .update(JSON.stringify(data))
 26:       .digest("hex");
 27:   }
 28: 
 29:   private async getStoredHash(productId: number): Promise<string | null> {
 30:     const cacheKey = `hash_${productId}`;
 31:     const cached = this.cache.get(cacheKey);
 32:     if (cached) return cached;
 33: 
 34:     const doc = await this.retry.execute(() =>
 35:       db.collection(COLLECTION.CARD_HASHES)
 36:         .doc(productId.toString())
 37:         .get()
 38:     );
 39: 
 40:     const hash = doc.exists ? doc.data()?.hash : null;
 41:     if (hash) this.cache.set(cacheKey, hash);
 42: 
 43:     return hash;
 44:   }
 45: 
 46:   private async updateStoredHash(productId: number, hash: string): Promise<void> {
 47:     await this.retry.execute(() =>
 48:       db.collection(COLLECTION.CARD_HASHES)
 49:         .doc(productId.toString())
 50:         .set({
 51:           hash,
 52:           lastUpdated: FieldValue.serverTimestamp(),
 53:         }, { merge: true })
 54:     );
 55:     this.cache.set(`hash_${productId}`, hash);
 56:   }
 57: 
 58:   private getCardNumbers(card: CardProduct): string[] {
 59:     const numbers: string[] = [];
 60:     card.extendedData
 61:       .filter((data) => data.name === "Number")
 62:       .forEach((numberField) => {
 63:         const vals = numberField.value.split(/[,;/]/).map((n) => n.trim());
 64:         numbers.push(...vals);
 65:       });
 66: 
 67:     if (numbers.length === 0) {
 68:       numbers.push(`P${card.productId}`);
 69:     }
 70: 
 71:     return [...new Set(numbers)];
 72:   }
 73: 
 74:   private isNonCardProduct(card: CardProduct): boolean {
 75:     const cardType = card.extendedData.find((data) => data.name === "CardType")?.value;
 76:     return !cardType || cardType.toLowerCase() === "sealed product";
 77:   }
 78: 
 79:   private async saveDeltaUpdate(card: CardProduct, changes: CardChanges): Promise<void> {
 80:     await this.rateLimiter.add(async () => {
 81:       await db.collection(COLLECTION.CARD_DELTAS)
 82:         .add({
 83:           productId: card.productId,
 84:           changes,
 85:           timestamp: FieldValue.serverTimestamp(),
 86:         });
 87:     });
 88:   }
 89: 
 90:   private async processCardBatch(
 91:     cards: CardProduct[],
 92:     groupId: string,
 93:     options: { forceUpdate?: boolean } = {}
 94:   ): Promise<{
 95:   processed: number;
 96:   updated: number;
 97:   errors: string[];
 98: }> {
 99:     const result = {
100:       processed: 0,
101:       updated: 0,
102:       errors: [] as string[],
103:     };
104: 
105:     const writeQueue: Array<() => Promise<void>> = [];
106:     let batch = db.batch(); // Changed from const to let
107:     let batchCount = 0;
108: 
109:     const commitBatch = async () => {
110:       if (batchCount > 0) {
111:         try {
112:           await this.rateLimiter.add(async () => {
113:             await this.retry.execute(() => batch.commit());
114:           });
115:           batch = db.batch(); // Create new batch after commit
116:           batchCount = 0;
117:         } catch (error) {
118:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
119:           result.errors.push(`Error committing batch: ${errorMessage}`);
120:           logger.error("Error committing batch", { error: errorMessage });
121:           // Create a new batch even if commit fails
122:           batch = db.batch();
123:           batchCount = 0;
124:         }
125:       }
126:     };
127: 
128:     // Pre-fetch hashes in bulk
129:     const productIds = cards.map((card) => card.productId);
130:     const hashPromises = productIds.map((id) => this.getStoredHash(id));
131:     const storedHashes = await Promise.all(hashPromises);
132:     const hashMap = new Map(productIds.map((id, index) => [id, storedHashes[index]]));
133: 
134:     for (const card of cards) {
135:       try {
136:         result.processed++;
137: 
138:         const relevantData: CardHashData = {
139:           name: card.name,
140:           cleanName: card.cleanName,
141:           modifiedOn: card.modifiedOn,
142:           extendedData: card.extendedData,
143:         };
144: 
145:         const currentHash = this.calculateHash(relevantData);
146:         const storedHash = hashMap.get(card.productId);
147: 
148:         if (currentHash === storedHash && !options.forceUpdate) {
149:           logger.info(`Skipping card ${card.productId} - no changes`);
150:           continue;
151:         }
152: 
153:         const cardNumbers = this.getCardNumbers(card);
154:         const primaryCardNumber = cardNumbers[0];
155: 
156:         const imagePromise = this.retry.execute(() =>
157:           storageService.processAndStoreImage(
158:             card.imageUrl,
159:             card.productId,
160:             groupId,
161:             primaryCardNumber
162:           )
163:         );
164: 
165:         writeQueue.push(async () => {
166:           try {
167:             const imageResult = await imagePromise;
168:             const cardDoc = {
169:               productId: card.productId,
170:               name: card.name,
171:               cleanName: card.cleanName,
172:               highResUrl: imageResult.highResUrl,
173:               lowResUrl: imageResult.lowResUrl,
174:               lastUpdated: FieldValue.serverTimestamp(),
175:               groupId: parseInt(groupId),
176:               isNonCard: this.isNonCardProduct(card),
177:               cardNumbers,
178:               primaryCardNumber,
179:             };
180: 
181:             const cardRef = db.collection(COLLECTION.CARDS)
182:               .doc(card.productId.toString());
183: 
184:             batch.set(cardRef, cardDoc, { merge: true });
185: 
186:             // Store extended data in subcollection
187:             const extendedDataRef = cardRef.collection("extendedData");
188:             card.extendedData.forEach((data) => {
189:               batch.set(extendedDataRef.doc(data.name), data);
190:             });
191: 
192:             // Store image metadata in subcollection
193:             batch.set(
194:               cardRef.collection("metadata").doc("image"),
195:               imageResult.metadata
196:             );
197: 
198:             batchCount++;
199: 
200:             if (batchCount >= this.MAX_BATCH_OPERATIONS) {
201:               await commitBatch();
202:             }
203: 
204:             await this.updateStoredHash(card.productId, currentHash);
205:             await this.saveDeltaUpdate(card, cardDoc);
206: 
207:             result.updated++;
208:             logger.info(
209:               `Updated card ${card.productId}: ${card.name} with numbers: ${cardNumbers.join(", ")}`
210:             );
211:           } catch (error) {
212:             const errorMessage = error instanceof Error ? error.message : "Unknown error";
213:             result.errors.push(`Error processing write operation for card ${card.productId}: ${errorMessage}`);
214:             logger.error(`Error processing write operation for card ${card.productId}`, { error: errorMessage });
215:           }
216:         });
217:       } catch (error) {
218:         const errorMessage = error instanceof Error ? error.message : "Unknown error";
219:         result.errors.push(`Error processing card ${card.productId}: ${errorMessage}`);
220:         logger.error(`Error processing card ${card.productId}`, { error: errorMessage });
221:       }
222:     }
223: 
224:     // Process queued writes with controlled concurrency
225:     const chunks = [];
226:     for (let i = 0; i < writeQueue.length; i += this.MAX_PARALLEL_BATCHES) {
227:       chunks.push(writeQueue.slice(i, i + this.MAX_PARALLEL_BATCHES));
228:     }
229: 
230:     for (const chunk of chunks) {
231:       await Promise.all(chunk.map((write) => write()));
232:       await commitBatch();
233:     }
234: 
235:     // Final commit if there are any remaining operations
236:     await commitBatch();
237: 
238:     return result;
239:   }
240: 
241:   private async processCardBatches(
242:     cards: CardProduct[],
243:     groupId: string,
244:     options: { forceUpdate?: boolean } = {}
245:   ): Promise<{
246:     processed: number;
247:     updated: number;
248:     errors: string[];
249:   }> {
250:     const batches = [];
251:     for (let i = 0; i < cards.length; i += this.BATCH_SIZE) {
252:       batches.push(cards.slice(i, i + this.BATCH_SIZE));
253:     }
254: 
255:     const results = [];
256:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
257:       const batchPromises = batches
258:         .slice(i, i + this.MAX_PARALLEL_BATCHES)
259:         .map((batch) => this.processCardBatch(batch, groupId, options));
260:       const batchResults = await Promise.all(batchPromises);
261:       results.push(...batchResults);
262: 
263:       // Add delay between large batch processing
264:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
265:         await new Promise((resolve) => setTimeout(resolve, 1000));
266:       }
267:     }
268: 
269:     return results.reduce(
270:       (acc, curr) => ({
271:         processed: acc.processed + curr.processed,
272:         updated: acc.updated + curr.updated,
273:         errors: [...acc.errors, ...curr.errors],
274:       }),
275:       { processed: 0, updated: 0, errors: [] }
276:     );
277:   }
278: 
279:   async syncCards(options: SyncOptions = {}): Promise<SyncResult> {
280:     const result: SyncResult = {
281:       success: true,
282:       itemsProcessed: 0,
283:       itemsUpdated: 0,
284:       errors: [],
285:       timing: {
286:         startTime: new Date(),
287:       },
288:     };
289: 
290:     try {
291:       logger.info("Starting card sync", { options });
292: 
293:       const groups = options.groupId ?
294:         [{ groupId: options.groupId }] :
295:         await tcgcsvApi.getGroups();
296: 
297:       logger.info(`Found ${groups.length} groups to process`);
298: 
299:       for (const group of groups) {
300:         result.timing.groupStartTime = new Date();
301:         try {
302:           const cards = await tcgcsvApi.getGroupProducts(group.groupId);
303: 
304:           // Process cards in optimized batches
305:           const batchResults = await this.processCardBatches(
306:             cards,
307:             group.groupId,
308:             options
309:           );
310: 
311:           result.itemsProcessed += batchResults.processed;
312:           result.itemsUpdated += batchResults.updated;
313:           result.errors.push(...batchResults.errors);
314: 
315:           // Add delay between groups
316:           if (groups.length > 1) {
317:             await new Promise((resolve) => setTimeout(resolve, 2000));
318:           }
319:         } catch (error) {
320:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
321:           result.errors.push(
322:             `Error processing group ${group.groupId}: ${errorMessage}`
323:           );
324:           logger.error(`Error processing group ${group.groupId}`, {
325:             error: errorMessage,
326:           });
327:         }
328:       }
329:     } catch (error) {
330:       result.success = false;
331:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
332:       result.errors.push(`Card sync failed: ${errorMessage}`);
333:       logger.error("Card sync failed", { error: errorMessage });
334:     }
335: 
336:     result.timing.endTime = new Date();
337:     result.timing.duration =
338:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
339: 
340:     logger.logSyncStats({
341:       startTime: result.timing.startTime,
342:       endTime: result.timing.endTime,
343:       totalItems: result.itemsProcessed,
344:       successCount: result.itemsUpdated,
345:       errorCount: result.errors.length,
346:       duration: result.timing.duration,
347:     });
348: 
349:     return result;
350:   }
351: }
352: 
353: export const cardSync = new CardSyncService();
</file>

<file path="src/services/priceSync.ts">
  1: // src/services/priceSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { CardPrice, SyncResult, SyncOptions } from "../types";
  5: import { logger } from "../utils/logger";
  6: import { RateLimiter } from "../utils/rateLimiter";
  7: import { Cache } from "../utils/cache";
  8: import { RetryWithBackoff } from "../utils/retry";
  9: import * as crypto from "crypto";
 10: import { FieldValue, WriteResult } from "firebase-admin/firestore";
 11: 
 12: export class PriceSyncService {
 13:   private readonly BATCH_SIZE = 1000;
 14:   private readonly MAX_PARALLEL_BATCHES = 5;
 15:   private readonly MAX_BATCH_OPERATIONS = 450;
 16: 
 17:   private readonly rateLimiter = new RateLimiter();
 18:   private readonly cache = new Cache<string>(15);
 19:   private readonly retry = new RetryWithBackoff();
 20: 
 21:   private calculateHash(price: CardPrice): string {
 22:     const relevantData = {
 23:       normal: price.normal,
 24:       foil: price.foil,
 25:       lastUpdated: price.lastUpdated,
 26:     };
 27:     return crypto.createHash("md5").update(JSON.stringify(relevantData)).digest("hex");
 28:   }
 29: 
 30:   private async getStoredHash(productId: number): Promise<string | null> {
 31:     const cacheKey = `price_hash_${productId}`;
 32:     const cached = this.cache.get(cacheKey);
 33:     if (cached) return cached;
 34: 
 35:     const doc = await this.retry.execute(() =>
 36:       db.collection(COLLECTION.PRICE_HASHES)
 37:         .doc(productId.toString())
 38:         .get()
 39:     );
 40: 
 41:     const hash = doc.exists ? doc.data()?.hash : null;
 42:     if (hash) this.cache.set(cacheKey, hash);
 43: 
 44:     return hash;
 45:   }
 46: 
 47:   private validatePrice(price: CardPrice): boolean {
 48:     const validatePriceData = (data: typeof price.normal | typeof price.foil) => {
 49:       if (!data) return false;
 50:       return (
 51:         typeof data.marketPrice === "number" &&
 52:         data.marketPrice >= 0 &&
 53:         typeof data.lowPrice === "number" &&
 54:         data.lowPrice >= 0 &&
 55:         typeof data.highPrice === "number" &&
 56:         data.highPrice >= 0
 57:       );
 58:     };
 59: 
 60:     return validatePriceData(price.normal) || validatePriceData(price.foil);
 61:   }
 62: 
 63:   private async processPriceBatch(
 64:     prices: CardPrice[],
 65:     groupId: string,
 66:     options: { forceUpdate?: boolean } = {}
 67:   ): Promise<{
 68:     processed: number;
 69:     updated: number;
 70:     errors: string[];
 71:   }> {
 72:     const result = {
 73:       processed: 0,
 74:       updated: 0,
 75:       errors: [] as string[],
 76:     };
 77: 
 78:     let batch = db.batch();
 79:     let batchCount = 0;
 80:     const batchPromises: Promise<WriteResult[]>[] = []; // Updated type here
 81: 
 82:     // Pre-fetch all hashes at once
 83:     const productIds = prices.map((price) => price.productId);
 84:     const hashPromises = productIds.map((id) => this.getStoredHash(id));
 85:     const storedHashes = await Promise.all(hashPromises);
 86:     const hashMap = new Map(productIds.map((id, index) => [id, storedHashes[index]]));
 87: 
 88:     // Prepare historical prices in bulk
 89:     const today = new Date();
 90:     today.setHours(0, 0, 0, 0);
 91:     let historicalBatch = db.batch();
 92:     let historicalCount = 0;
 93: 
 94:     for (const price of prices) {
 95:       try {
 96:         result.processed++;
 97: 
 98:         if (!this.validatePrice(price)) continue;
 99: 
100:         const currentHash = this.calculateHash(price);
101:         const storedHash = hashMap.get(price.productId);
102: 
103:         if (currentHash === storedHash && !options.forceUpdate) continue;
104: 
105:         // Main price document
106:         const priceDoc = {
107:           productId: price.productId,
108:           lastUpdated: FieldValue.serverTimestamp(),
109:           groupId: parseInt(groupId),
110:           ...(price.normal && { normal: price.normal }),
111:           ...(price.foil && { foil: price.foil }),
112:         };
113: 
114:         // Add to main batch
115:         const priceRef = db.collection(COLLECTION.PRICES)
116:           .doc(price.productId.toString());
117:         batch.set(priceRef, priceDoc, { merge: true });
118:         batchCount++;
119: 
120:         // Add to historical batch
121:         const docId = `${price.productId}_${today.toISOString().split("T")[0]}`;
122:         const historicalRef = db.collection(COLLECTION.HISTORICAL_PRICES).doc(docId);
123:         const historicalPrice = {
124:           productId: price.productId,
125:           groupId,
126:           date: today,
127:           timestamp: FieldValue.serverTimestamp(),
128:           ...(price.normal && {
129:             normal: {
130:               directLow: price.normal.directLowPrice,
131:               high: price.normal.highPrice,
132:               low: price.normal.lowPrice,
133:               market: price.normal.marketPrice,
134:               mid: price.normal.midPrice,
135:             },
136:           }),
137:           ...(price.foil && {
138:             foil: {
139:               directLow: price.foil.directLowPrice,
140:               high: price.foil.highPrice,
141:               low: price.foil.lowPrice,
142:               market: price.foil.marketPrice,
143:               mid: price.foil.midPrice,
144:             },
145:           }),
146:         };
147:         historicalBatch.set(historicalRef, historicalPrice, { merge: true });
148:         historicalCount++;
149: 
150:         // Update hash in same batch
151:         const hashRef = db.collection(COLLECTION.PRICE_HASHES)
152:           .doc(price.productId.toString());
153:         batch.set(hashRef, {
154:           hash: currentHash,
155:           lastUpdated: FieldValue.serverTimestamp(),
156:         }, { merge: true });
157:         batchCount++;
158: 
159:         // Commit batch if reaching limit
160:         if (batchCount >= this.MAX_BATCH_OPERATIONS) {
161:           batchPromises.push(
162:             this.rateLimiter.add(async () => this.retry.execute(() => batch.commit())) // Added async
163:           );
164:           batch = db.batch();
165:           batchCount = 0;
166:         }
167: 
168:         // Commit historical batch if reaching limit
169:         if (historicalCount >= this.MAX_BATCH_OPERATIONS) {
170:           batchPromises.push(
171:             this.rateLimiter.add(async () => this.retry.execute(() => historicalBatch.commit())) // Added async
172:           );
173:           historicalBatch = db.batch();
174:           historicalCount = 0;
175:         }
176: 
177:         result.updated++;
178:       } catch (error) {
179:         const errorMessage = error instanceof Error ? error.message : "Unknown error";
180:         result.errors.push(`Error processing price for product ${price.productId}: ${errorMessage}`);
181:       }
182:     }
183: 
184:     // Commit any remaining batches
185:     if (batchCount > 0) {
186:       batchPromises.push(
187:         this.rateLimiter.add(async () => this.retry.execute(() => batch.commit())) // Added async
188:       );
189:     }
190: 
191:     if (historicalCount > 0) {
192:       batchPromises.push(
193:         this.rateLimiter.add(async () => this.retry.execute(() => historicalBatch.commit())) // Added async
194:       );
195:     }
196: 
197:     // Wait for all batch commits to complete
198:     await Promise.all(batchPromises);
199: 
200:     return result;
201:   }
202: 
203:   private async processPriceBatches(
204:     prices: CardPrice[],
205:     groupId: string,
206:     options: { forceUpdate?: boolean } = {}
207:   ): Promise<{
208:     processed: number;
209:     updated: number;
210:     errors: string[];
211:   }> {
212:     const batches = [];
213:     for (let i = 0; i < prices.length; i += this.BATCH_SIZE) {
214:       batches.push(prices.slice(i, i + this.BATCH_SIZE));
215:     }
216: 
217:     const results = [];
218:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
219:       const batchPromises = batches
220:         .slice(i, i + this.MAX_PARALLEL_BATCHES)
221:         .map((batch) => this.processPriceBatch(batch, groupId, options));
222:       const batchResults = await Promise.all(batchPromises);
223:       results.push(...batchResults);
224: 
225:       // Add delay between large batch processing
226:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
227:         await new Promise((resolve) => setTimeout(resolve, 1000));
228:       }
229:     }
230: 
231:     return results.reduce(
232:       (acc, curr) => ({
233:         processed: acc.processed + curr.processed,
234:         updated: acc.updated + curr.updated,
235:         errors: [...acc.errors, ...curr.errors],
236:       }),
237:       { processed: 0, updated: 0, errors: [] }
238:     );
239:   }
240: 
241:   async syncPrices(options: SyncOptions = {}): Promise<SyncResult> {
242:     const result: SyncResult = {
243:       success: true,
244:       itemsProcessed: 0,
245:       itemsUpdated: 0,
246:       errors: [],
247:       timing: {
248:         startTime: new Date(),
249:       },
250:     };
251: 
252:     try {
253:       logger.info("Starting price sync", { options });
254: 
255:       const groups = options.groupId ?
256:         [{ groupId: options.groupId }] :
257:         await tcgcsvApi.getGroups();
258: 
259:       logger.info(`Found ${groups.length} groups to process`);
260: 
261:       for (const group of groups) {
262:         result.timing.groupStartTime = new Date();
263:         try {
264:           const prices = await tcgcsvApi.getGroupPrices(group.groupId);
265: 
266:           const batchResults = await this.processPriceBatches(
267:             prices,
268:             group.groupId,
269:             options
270:           );
271: 
272:           result.itemsProcessed += batchResults.processed;
273:           result.itemsUpdated += batchResults.updated;
274:           result.errors.push(...batchResults.errors);
275: 
276:           // Add delay between groups
277:           if (groups.length > 1) {
278:             await new Promise((resolve) => setTimeout(resolve, 2000));
279:           }
280:         } catch (error) {
281:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
282:           result.errors.push(
283:             `Error processing prices for group ${group.groupId}: ${errorMessage}`
284:           );
285:           logger.error(`Error processing prices for group ${group.groupId}`, {
286:             error: errorMessage,
287:           });
288:         }
289:       }
290:     } catch (error) {
291:       result.success = false;
292:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
293:       result.errors.push(`Price sync failed: ${errorMessage}`);
294:       logger.error("Price sync failed", { error: errorMessage });
295:     }
296: 
297:     result.timing.endTime = new Date();
298:     result.timing.duration =
299:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
300: 
301:     logger.info(`Price sync completed in ${result.timing.duration}s`, {
302:       processed: result.itemsProcessed,
303:       updated: result.itemsUpdated,
304:       errors: result.errors.length,
305:       timing: result.timing,
306:     });
307: 
308:     return result;
309:   }
310: }
311: 
312: export const priceSync = new PriceSyncService();
</file>

<file path="src/services/storageService.ts">
  1: // src/services/storageService.ts
  2: import { S3Client, PutObjectCommand, HeadObjectCommand } from "@aws-sdk/client-s3";
  3: import axios from "axios";
  4: import { R2_CONFIG } from "../config/r2";
  5: import { logger } from "../utils/logger";
  6: 
  7: interface ImageResult {
  8:   highResUrl: string;
  9:   lowResUrl: string;
 10:   metadata: {
 11:     contentType: string;
 12:     productId: string;
 13:     groupId: string;
 14:     lastUpdated: string;
 15:     isPlaceholder?: boolean;
 16:     originalUrl?: string;
 17:     existingImage?: boolean;
 18:     errorMessage?: string;
 19:   };
 20: }
 21: 
 22: export class StorageService {
 23:   private client: S3Client;
 24:   private readonly bucket: string;
 25:   private readonly customDomain: string;
 26:   private readonly storagePath: string;
 27:   private readonly maxRetries = 3;
 28:   private readonly timeoutMs = 30000; // 30 seconds
 29:   private readonly PLACEHOLDER_URL = "https://fftcgcompanion.com/card-images/image-coming-soon.jpeg";
 30:   private readonly validImagePatterns = [
 31:     "_200w.", // Match _200w followed by any extension
 32:     "_400w.", // Match _400w followed by any extension
 33:     "_1000x1000.", // Match _1000x1000 followed by any extension
 34:   ];
 35: 
 36:   constructor() {
 37:     this.client = new S3Client({
 38:       region: "auto",
 39:       endpoint: `https://${R2_CONFIG.ACCOUNT_ID}.r2.cloudflarestorage.com`,
 40:       credentials: {
 41:         accessKeyId: R2_CONFIG.ACCESS_KEY_ID,
 42:         secretAccessKey: R2_CONFIG.SECRET_ACCESS_KEY,
 43:       },
 44:       forcePathStyle: true,
 45:     });
 46: 
 47:     this.bucket = R2_CONFIG.BUCKET_NAME;
 48:     this.customDomain = R2_CONFIG.CUSTOM_DOMAIN;
 49:     this.storagePath = R2_CONFIG.STORAGE_PATH;
 50:   }
 51: 
 52:   private isValidImageUrl(url: string | undefined): boolean {
 53:     if (!url) return false;
 54: 
 55:     // Check if it's TCGPlayer's missing image SVG
 56:     if (url.includes("image-missing.svg")) {
 57:       logger.info(`TCGPlayer missing image URL detected: ${url}, using our placeholder`);
 58:       return false;
 59:     }
 60: 
 61:     // If URL contains any of our valid patterns, it's a valid TCGPlayer image URL
 62:     const isValidPattern = this.validImagePatterns.some((pattern) => url.includes(pattern));
 63: 
 64:     // If URL doesn't match our patterns, consider it invalid
 65:     if (!isValidPattern) {
 66:       logger.info(`Invalid image URL pattern: ${url}, using placeholder`);
 67:       return false;
 68:     }
 69: 
 70:     return true;
 71:   }
 72: 
 73:   private async checkImageExists(path: string): Promise<boolean> {
 74:     try {
 75:       await this.client.send(
 76:         new HeadObjectCommand({
 77:           Bucket: this.bucket,
 78:           Key: path,
 79:         })
 80:       );
 81:       return true;
 82:     } catch (error) {
 83:       return false;
 84:     }
 85:   }
 86: 
 87:   private async validateImage(buffer: Buffer): Promise<boolean> {
 88:     if (buffer.length < 4) return false;
 89: 
 90:     const header = buffer.slice(0, 4);
 91:     // JPEG magic number: FF D8 FF
 92:     const isJPEG = header[0] === 0xff && header[1] === 0xd8 && header[2] === 0xff;
 93:     // PNG magic number: 89 50 4E 47
 94:     const isPNG = header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4e && header[3] === 0x47;
 95: 
 96:     return isJPEG || isPNG;
 97:   }
 98: 
 99:   private async downloadImage(url: string, retries = this.maxRetries): Promise<Buffer> {
100:     let lastError: Error | null = null;
101: 
102:     for (let attempt = 0; attempt <= retries; attempt++) {
103:       try {
104:         const response = await axios.get(url, {
105:           responseType: "arraybuffer",
106:           timeout: this.timeoutMs,
107:           headers: {
108:             "User-Agent": "FFTCG-Sync-Service/1.0",
109:             "Accept": "image/jpeg,image/png,image/*",
110:           },
111:           maxContentLength: 10 * 1024 * 1024, // 10MB max
112:           validateStatus: (status) => status === 200, // Only accept 200 status
113:         });
114: 
115:         const buffer = Buffer.from(response.data);
116: 
117:         if (await this.validateImage(buffer)) {
118:           return buffer;
119:         } else {
120:           throw new Error("Invalid image format");
121:         }
122:       } catch (error) {
123:         const axiosError = error as { response?: { status?: number } };
124: 
125:         // If we get a 403, this means the image doesn't exist or access is denied
126:         // Don't retry and don't log as error since this is an expected case
127:         if (axiosError?.response?.status === 403) {
128:           logger.info(`Image not available (403) for URL: ${url}`);
129:           throw new Error("IMAGE_NOT_AVAILABLE");
130:         }
131: 
132:         // For other errors, continue with retry logic
133:         lastError = error instanceof Error ? error : new Error(String(error));
134: 
135:         if (attempt === retries) {
136:           logger.error(`Failed to download image after ${retries + 1} attempts`, {
137:             url,
138:             error: lastError.message,
139:             status: axiosError?.response?.status,
140:           });
141:           break;
142:         }
143: 
144:         // Only log retries for non-403 errors
145:         logger.info(`Retrying image download (attempt ${attempt + 1}/${retries})`, {
146:           url,
147:           status: axiosError?.response?.status,
148:         });
149: 
150:         await new Promise((resolve) => setTimeout(resolve, 2000 * Math.pow(2, attempt)));
151:       }
152:     }
153: 
154:     throw lastError || new Error("Download failed after retries");
155:   }
156: 
157:   private async uploadToR2WithRetry(
158:     buffer: Buffer,
159:     path: string,
160:     metadata: Record<string, string>,
161:     retries = this.maxRetries
162:   ): Promise<string> {
163:     let lastError: Error | null = null;
164: 
165:     const stringMetadata = Object.entries(metadata).reduce(
166:       (acc, [key, value]) => ({
167:         ...acc,
168:         [key]: String(value),
169:       }),
170:       {}
171:     );
172: 
173:     for (let attempt = 0; attempt <= retries; attempt++) {
174:       try {
175:         await this.client.send(
176:           new PutObjectCommand({
177:             Bucket: this.bucket,
178:             Key: path,
179:             Body: buffer,
180:             ContentType: "image/jpeg",
181:             Metadata: stringMetadata,
182:             ContentLength: buffer.length,
183:             CacheControl: "public, max-age=31536000", // Cache for 1 year
184:             ACL: "public-read",
185:           })
186:         );
187:         return `${this.customDomain}/${path}`;
188:       } catch (error) {
189:         lastError = error instanceof Error ? error : new Error(String(error));
190:         logger.error(`Upload attempt ${attempt + 1} failed`, {
191:           path,
192:           error: lastError.message,
193:         });
194:         if (attempt === retries) break;
195:         await new Promise((resolve) => setTimeout(resolve, 1000 * (attempt + 1)));
196:       }
197:     }
198: 
199:     throw lastError || new Error("Upload failed after retries");
200:   }
201: 
202:   private getImagePath(groupId: string, cardNumber: string, resolution: "200w" | "400w"): string {
203:     return `${this.storagePath}/${groupId}/${cardNumber}_${resolution}.jpg`;
204:   }
205: 
206:   public async processAndStoreImage(
207:     imageUrl: string | undefined,
208:     productId: number,
209:     groupId: string,
210:     cardNumber: string
211:   ): Promise<ImageResult> {
212:     const baseMetadata = {
213:       productId: productId.toString(),
214:       groupId,
215:       lastUpdated: new Date().toISOString(),
216:       contentType: "image/jpeg",
217:     };
218: 
219:     // Check for valid TCGPlayer URL first
220:     if (!this.isValidImageUrl(imageUrl)) {
221:       logger.info(`Invalid or missing image URL for product ${productId}, using placeholder`);
222:       return {
223:         highResUrl: this.PLACEHOLDER_URL,
224:         lowResUrl: this.PLACEHOLDER_URL,
225:         metadata: {
226:           ...baseMetadata,
227:           isPlaceholder: true,
228:           originalUrl: imageUrl,
229:           errorMessage: "Invalid or missing image URL",
230:         },
231:       };
232:     }
233: 
234:     try {
235:       // Check if images already exist in R2
236:       const highResPath = this.getImagePath(groupId, cardNumber, "400w");
237:       const lowResPath = this.getImagePath(groupId, cardNumber, "200w");
238: 
239:       const [highResExists, lowResExists] = await Promise.all([
240:         this.checkImageExists(highResPath),
241:         this.checkImageExists(lowResPath),
242:       ]);
243: 
244:       // If both images exist, return their URLs
245:       if (highResExists && lowResExists) {
246:         const existingHighResUrl = `${this.customDomain}/${highResPath}`;
247:         const existingLowResUrl = `${this.customDomain}/${lowResPath}`;
248: 
249:         logger.info(`Using existing images for product ${productId}`);
250:         return {
251:           highResUrl: existingHighResUrl,
252:           lowResUrl: existingLowResUrl,
253:           metadata: {
254:             ...baseMetadata,
255:             originalUrl: imageUrl,
256:             existingImage: true,
257:           },
258:         };
259:       }
260: 
261:       try {
262:         const baseUrl = imageUrl || "";
263:         const highResTcgUrl = baseUrl.replace("/fit-in/", "/fit-in/437x437/");
264:         const lowResTcgUrl = baseUrl.replace("/fit-in/", "/fit-in/223x223/");
265: 
266:         const [highResBuffer, lowResBuffer] = await Promise.all([
267:           this.downloadImage(highResTcgUrl),
268:           this.downloadImage(lowResTcgUrl),
269:         ]);
270: 
271:         // Upload both versions to R2
272:         const [storedHighResUrl, storedLowResUrl] = await Promise.all([
273:           this.uploadToR2WithRetry(highResBuffer, highResPath, baseMetadata),
274:           this.uploadToR2WithRetry(lowResBuffer, lowResPath, baseMetadata),
275:         ]);
276: 
277:         return {
278:           highResUrl: storedHighResUrl,
279:           lowResUrl: storedLowResUrl,
280:           metadata: {
281:             ...baseMetadata,
282:             originalUrl: imageUrl,
283:           },
284:         };
285:       } catch (unknownError: unknown) {
286:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
287: 
288:         // Only log as error if it's not an expected case
289:         if (error.message !== "IMAGE_NOT_AVAILABLE") {
290:           logger.error(`Failed to process images for ${productId}`, { error });
291:         }
292: 
293:         return {
294:           highResUrl: this.PLACEHOLDER_URL,
295:           lowResUrl: this.PLACEHOLDER_URL,
296:           metadata: {
297:             ...baseMetadata,
298:             isPlaceholder: true,
299:             originalUrl: imageUrl,
300:             errorMessage:
301:               error.message === "IMAGE_NOT_AVAILABLE" ? "Image not available from source" : "Image processing failed",
302:           },
303:         };
304:       }
305:     } catch (unknownError: unknown) {
306:       const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
307: 
308:       // Only log as error if it's not an expected case
309:       if (error.message !== "IMAGE_NOT_AVAILABLE") {
310:         logger.error(`Failed to process images for ${productId}`, { error });
311:       }
312: 
313:       return {
314:         highResUrl: this.PLACEHOLDER_URL,
315:         lowResUrl: this.PLACEHOLDER_URL,
316:         metadata: {
317:           ...baseMetadata,
318:           isPlaceholder: true,
319:           originalUrl: imageUrl,
320:           errorMessage:
321:             error.message === "IMAGE_NOT_AVAILABLE" ? "Image not available from source" : "Image processing failed",
322:         },
323:       };
324:     }
325:   }
326: }
327: 
328: export const storageService = new StorageService();
</file>

<file path="src/types/index.ts">
  1: import { FieldValue } from "firebase-admin/firestore";
  2: 
  3: export interface CardProduct {
  4:   productId: number;
  5:   name: string;
  6:   cleanName: string;
  7:   imageUrl?: string;
  8:   categoryId: number;
  9:   groupId: number;
 10:   url: string;
 11:   modifiedOn: string;
 12:   imageCount: number;
 13:   extendedData: Array<{
 14:     name: string;
 15:     displayName: string;
 16:     value: string;
 17:   }>;
 18: }
 19: 
 20: export interface CardPrice {
 21:   productId: number;
 22:   normal?: {
 23:     directLowPrice: number | null;
 24:     highPrice: number;
 25:     lowPrice: number;
 26:     marketPrice: number;
 27:     midPrice: number;
 28:     subTypeName: "Normal";
 29:   };
 30:   foil?: {
 31:     directLowPrice: number | null;
 32:     highPrice: number;
 33:     lowPrice: number;
 34:     marketPrice: number;
 35:     midPrice: number;
 36:     subTypeName: "Foil";
 37:   };
 38:   lastUpdated: Date;
 39: }
 40: 
 41: export interface HistoricalPrice {
 42:   productId: number;
 43:   date: Date;
 44:   normal?: {
 45:     directLow: number | null;
 46:     high: number;
 47:     low: number;
 48:     market: number;
 49:     mid: number;
 50:   };
 51:   foil?: {
 52:     directLow: number | null;
 53:     high: number;
 54:     low: number;
 55:     market: number;
 56:     mid: number;
 57:   };
 58:   groupId: string;
 59: }
 60: 
 61: export interface SyncTiming {
 62:   startTime: Date;
 63:   endTime?: Date;
 64:   duration?: number;
 65:   groupStartTime?: Date;
 66:   imageStartTime?: Date;
 67:   lastUpdateTime?: Date;
 68: }
 69: 
 70: export interface SyncResult {
 71:   success: boolean;
 72:   itemsProcessed: number;
 73:   itemsUpdated: number;
 74:   errors: string[];
 75:   timing: SyncTiming;
 76: }
 77: 
 78: export interface CardHashData {
 79:   name: string;
 80:   cleanName: string;
 81:   modifiedOn: string;
 82:   extendedData: Array<{
 83:     name: string;
 84:     displayName: string;
 85:     value: string;
 86:   }>;
 87: }
 88: 
 89: export interface SyncOptions {
 90:   groupId?: string;
 91:   forceUpdate?: boolean;
 92:   skipImages?: boolean;
 93:   imagesOnly?: boolean;
 94:   silent?: boolean;
 95:   dryRun?: boolean;
 96: }
 97: 
 98: export interface CardChanges {
 99:   productId: number;
100:   name: string;
101:   cleanName: string;
102:   highResUrl: string;
103:   lowResUrl: string;
104:   lastUpdated: FieldValue;
105:   groupId: number;
106:   isNonCard: boolean;
107:   cardNumbers: string[];
108:   primaryCardNumber: string;
109: }
110: 
111: export interface PriceChanges {
112:   productId: number;
113:   lastUpdated: FieldValue;
114:   groupId: number;
115:   normal?: {
116:     directLowPrice: number | null;
117:     highPrice: number;
118:     lowPrice: number;
119:     marketPrice: number;
120:     midPrice: number;
121:     subTypeName: "Normal";
122:   };
123:   foil?: {
124:     directLowPrice: number | null;
125:     highPrice: number;
126:     lowPrice: number;
127:     marketPrice: number;
128:     midPrice: number;
129:     subTypeName: "Foil";
130:   };
131: }
</file>

<file path="src/utils/api.ts">
  1: import axios, { AxiosError } from "axios";
  2: import { CardProduct, CardPrice } from "../types";
  3: import { logger } from "./logger";
  4: 
  5: export class TcgcsvApi {
  6:   private readonly baseUrl = "https://tcgcsv.com/tcgplayer";
  7:   private readonly categoryId = "24"; // Final Fantasy TCG
  8: 
  9:   private async makeRequest<T>(endpoint: string): Promise<T> {
 10:     const url = `${this.baseUrl}/${endpoint}`;
 11:     logger.info(`Making request to: ${url}`);
 12: 
 13:     try {
 14:       const response = await axios.get<T>(url, {
 15:         timeout: 30000,
 16:         headers: {
 17:           "Accept": "application/json",
 18:           "User-Agent": "FFTCG-Sync-Service/1.0",
 19:         },
 20:       });
 21:       return response.data;
 22:     } catch (error) {
 23:       if (error instanceof AxiosError && error.response?.status === 403) {
 24:         throw new Error(`Access denied to TCGCSV API at path: ${endpoint}`);
 25:       }
 26:       throw error;
 27:     }
 28:   }
 29: 
 30:   async getGroups(): Promise<Array<{ groupId: string }>> {
 31:     const response = await this.makeRequest<{ results: Array<{ groupId: string }> }>(`${this.categoryId}/groups`);
 32:     logger.info(`Retrieved ${response.results.length} groups`);
 33:     return response.results;
 34:   }
 35: 
 36:   async getGroupProducts(groupId: string): Promise<CardProduct[]> {
 37:     const response = await this.makeRequest<{ results: CardProduct[] }>(`${this.categoryId}/${groupId}/products`);
 38:     logger.info(`Retrieved ${response.results.length} products for group ${groupId}`);
 39: 
 40:     // Transform the results to use correct image URLs
 41:     const products = response.results.map((product) => ({
 42:       ...product,
 43:       // No modification needed, keep original TCGPlayer URL
 44:     }));
 45: 
 46:     return products;
 47:   }
 48: 
 49:   async getGroupPrices(groupId: string): Promise<CardPrice[]> {
 50:     interface RawPriceData {
 51:       productId: number;
 52:       lowPrice: number | null;
 53:       midPrice: number | null;
 54:       highPrice: number | null;
 55:       marketPrice: number | null;
 56:       directLowPrice: number | null;
 57:       subTypeName: string;
 58:     }
 59: 
 60:     interface PriceResponse {
 61:       success: boolean;
 62:       errors: string[];
 63:       results: RawPriceData[];
 64:     }
 65: 
 66:     const response = await this.makeRequest<PriceResponse>(`${this.categoryId}/${groupId}/prices`);
 67:     logger.info(`Retrieved ${response.results.length} prices for group ${groupId}`);
 68: 
 69:     // Group prices by productId
 70:     const priceMap = new Map<number, CardPrice>();
 71: 
 72:     response.results.forEach((price) => {
 73:       const existing = priceMap.get(price.productId) || {
 74:         productId: price.productId,
 75:         lastUpdated: new Date(),
 76:       };
 77: 
 78:       if (price.subTypeName === "Normal") {
 79:         existing.normal = {
 80:           directLowPrice: price.directLowPrice,
 81:           highPrice: price.highPrice || 0,
 82:           lowPrice: price.lowPrice || 0,
 83:           marketPrice: price.marketPrice || 0,
 84:           midPrice: price.midPrice || 0,
 85:           subTypeName: "Normal",
 86:         };
 87:       } else if (price.subTypeName === "Foil") {
 88:         existing.foil = {
 89:           directLowPrice: price.directLowPrice,
 90:           highPrice: price.highPrice || 0,
 91:           lowPrice: price.lowPrice || 0,
 92:           marketPrice: price.marketPrice || 0,
 93:           midPrice: price.midPrice || 0,
 94:           subTypeName: "Foil",
 95:         };
 96:       }
 97: 
 98:       priceMap.set(price.productId, existing);
 99:     });
100: 
101:     return Array.from(priceMap.values());
102:   }
103: }
104: 
105: export const tcgcsvApi = new TcgcsvApi();
</file>

<file path="src/utils/cache.ts">
 1: // src/utils/cache.ts
 2: export class Cache<T> {
 3:   private cache = new Map<
 4:     string,
 5:     {
 6:       data: T;
 7:       timestamp: number;
 8:     }
 9:   >();
10:   private readonly ttl: number;
11:   private readonly maxSize: number;
12: 
13:   constructor(ttlMinutes = 15, maxSize = 5000) {
14:     this.ttl = ttlMinutes * 60 * 1000;
15:     this.maxSize = maxSize;
16:   }
17: 
18:   set(key: string, value: T): void {
19:     if (this.cache.size >= this.maxSize) {
20:       const entries = Array.from(this.cache.entries());
21:       const oldestEntries = entries
22:         .sort(([, a], [, b]) => a.timestamp - b.timestamp)
23:         .slice(0, Math.floor(this.maxSize * 0.1));
24: 
25:       oldestEntries.forEach(([key]) => this.cache.delete(key));
26:     }
27: 
28:     this.cache.set(key, {
29:       data: value,
30:       timestamp: Date.now(),
31:     });
32:   }
33: 
34:   setBulk(entries: Array<[string, T]>): void {
35:     entries.forEach(([key, value]) => this.set(key, value));
36:   }
37: 
38:   get(key: string): T | null {
39:     const cached = this.cache.get(key);
40:     if (!cached) return null;
41: 
42:     if (Date.now() - cached.timestamp > this.ttl) {
43:       this.cache.delete(key);
44:       return null;
45:     }
46: 
47:     return cached.data;
48:   }
49: 
50:   getBulk(keys: string[]): Map<string, T> {
51:     const results = new Map<string, T>();
52:     keys.forEach((key) => {
53:       const value = this.get(key);
54:       if (value !== null) {
55:         results.set(key, value);
56:       }
57:     });
58:     return results;
59:   }
60: 
61:   clear(): void {
62:     this.cache.clear();
63:   }
64: 
65:   has(key: string): boolean {
66:     return this.get(key) !== null;
67:   }
68: }
</file>

<file path="src/utils/logger.ts">
 1: // src/utils/logger.ts
 2: import { db } from "../config/firebase";
 3: import { environment } from "../config/environment";
 4: import { SyncResult } from "../types";
 5: 
 6: export type LogData = Record<string, unknown>;
 7: 
 8: export interface SyncStats {
 9:   startTime: Date;
10:   endTime?: Date;
11:   totalItems: number;
12:   successCount: number;
13:   errorCount: number;
14:   duration?: number;
15: }
16: 
17: export class Logger {
18:   private readonly COLLECTION = "logs";
19: 
20:   async info(message: string, data?: LogData | SyncResult): Promise<void> {
21:     await this.log("INFO", message, data);
22:   }
23: 
24:   async error(message: string, data?: LogData | { error: unknown }): Promise<void> {
25:     await this.log("ERROR", message, data);
26:   }
27: 
28:   async logSyncStats(stats: SyncStats): Promise<void> {
29:     const duration = stats.endTime ? (stats.endTime.getTime() - stats.startTime.getTime()) / 1000 : undefined;
30: 
31:     const successRate = ((stats.successCount / stats.totalItems) * 100).toFixed(1);
32: 
33:     console.log({
34:       duration: duration ? `${duration}s` : "unknown",
35:       successRate: `${successRate}%`,
36:       totalItems: stats.totalItems,
37:       successful: stats.successCount,
38:       errors: stats.errorCount,
39:     });
40: 
41:     if (!environment.isLocal) {
42:       await db.collection(this.COLLECTION).add({
43:         type: "SYNC_STATS",
44:         timestamp: new Date(),
45:         stats: {
46:           ...stats,
47:           duration,
48:           successRate: parseFloat(successRate),
49:         },
50:       });
51:     }
52:   }
53: 
54:   async log(
55:     level: "INFO" | "ERROR",
56:     message: string,
57:     metadata?: LogData | SyncResult | { error: unknown }
58:   ): Promise<void> {
59:     const entry = {
60:       timestamp: new Date(),
61:       level,
62:       message,
63:       metadata: metadata || null,
64:       environment: environment.nodeEnv,
65:     };
66: 
67:     // Always log to console with appropriate level
68:     const logFn = level === "ERROR" ? console.error : console.log;
69:     logFn(`[${level}] ${message}`, metadata || "");
70: 
71:     // Only log to Firestore if not in local development
72:     if (!environment.isLocal) {
73:       try {
74:         await db.collection(this.COLLECTION).add(entry);
75:       } catch (error) {
76:         console.error("Failed to write log to Firestore:", error);
77:         // Don't throw the error to prevent disrupting the application
78:       }
79:     }
80:   }
81: }
82: 
83: export const logger = new Logger();
</file>

<file path="src/utils/rateLimiter.ts">
 1: // src/utils/rateLimiter.ts
 2: import { logger } from "./logger";
 3: 
 4: export class RateLimiter {
 5:   private queue: Array<() => Promise<unknown>> = [];
 6:   private processing = false;
 7:   private readonly maxRate = 500;
 8:   private readonly interval = 1000;
 9:   private readonly maxConcurrent = 5;
10:   private currentConcurrent = 0;
11: 
12:   async add<T>(operation: () => Promise<T>): Promise<T> {
13:     return new Promise<T>((resolve, reject) => {
14:       this.queue.push(async () => {
15:         try {
16:           const result = await operation();
17:           resolve(result);
18:           return result;
19:         } catch (error) {
20:           reject(error);
21:           throw error;
22:         }
23:       });
24: 
25:       if (!this.processing) {
26:         void this.process();
27:       }
28:     });
29:   }
30: 
31:   private async process(): Promise<void> {
32:     this.processing = true;
33:     const batchSize = Math.floor(this.maxRate / (this.interval / 1000));
34: 
35:     while (this.queue.length > 0 && this.currentConcurrent < this.maxConcurrent) {
36:       const batch = this.queue.splice(0, Math.min(batchSize, this.queue.length));
37:       this.currentConcurrent++;
38: 
39:       try {
40:         await Promise.all(batch.map((op) => op()));
41:       } catch (error) {
42:         logger.error("Error processing rate-limited batch", { error });
43:       } finally {
44:         this.currentConcurrent--;
45:       }
46: 
47:       if (this.queue.length > 0) {
48:         await new Promise((resolve) => setTimeout(resolve, this.interval));
49:       }
50:     }
51: 
52:     this.processing = this.queue.length > 0;
53:     if (this.processing) {
54:       void this.process();
55:     }
56:   }
57: }
</file>

<file path="src/utils/retention.ts">
 1: import { db } from "../config/firebase";
 2: import { logger } from "./logger";
 3: 
 4: export class RetentionService {
 5:   private readonly RETENTION_CONFIG = {
 6:     logs: 7,
 7:     cardHashes: 7,
 8:     priceHashes: 7,
 9:     syncMetadata: 7,
10:   };
11: 
12:   async cleanOldData(): Promise<void> {
13:     try {
14:       logger.info("Starting data retention cleanup");
15: 
16:       for (const [collection, days] of Object.entries(this.RETENTION_CONFIG)) {
17:         const cutoff = new Date();
18:         cutoff.setDate(cutoff.getDate() - days);
19: 
20:         const snapshot = await db.collection(collection).where("lastUpdated", "<", cutoff).get();
21: 
22:         if (!snapshot.empty) {
23:           const batch = db.batch();
24:           snapshot.docs.forEach((doc) => batch.delete(doc.ref));
25:           await batch.commit();
26: 
27:           logger.info(`Cleaned up ${snapshot.size} documents from ${collection}`);
28:         }
29:       }
30: 
31:       logger.info("Data retention cleanup completed");
32:     } catch (error) {
33:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
34:       logger.error("Data retention cleanup failed", { error: errorMessage });
35:       throw error;
36:     }
37:   }
38: }
39: 
40: export const retention = new RetentionService();
</file>

<file path="src/utils/retry.ts">
 1: // src/utils/retry.ts
 2: import { logger } from "./logger";
 3: 
 4: export class RetryWithBackoff {
 5:   private readonly maxRetries: number;
 6:   private readonly initialDelay: number;
 7:   private readonly maxDelay: number;
 8:   private readonly backoffFactor: number;
 9: 
10:   constructor(maxRetries = 3, initialDelay = 1000, maxDelay = 10000, backoffFactor = 2) {
11:     this.maxRetries = maxRetries;
12:     this.initialDelay = initialDelay;
13:     this.maxDelay = maxDelay;
14:     this.backoffFactor = backoffFactor;
15:   }
16: 
17:   async execute<T>(operation: () => Promise<T>): Promise<T> {
18:     let lastError: Error | null = null;
19:     let delay = this.initialDelay;
20: 
21:     for (let attempt = 0; attempt <= this.maxRetries; attempt++) {
22:       try {
23:         return await operation();
24:       } catch (error) {
25:         lastError = error instanceof Error ? error : new Error(String(error));
26: 
27:         if (attempt === this.maxRetries) {
28:           break;
29:         }
30: 
31:         if (this.isNonRetryableError(lastError)) {
32:           throw lastError;
33:         }
34: 
35:         logger.info(`Retry attempt ${attempt + 1} of ${this.maxRetries}`, {
36:           error: lastError.message,
37:           delay,
38:         });
39: 
40:         await new Promise((resolve) => setTimeout(resolve, delay));
41:         delay = Math.min(delay * this.backoffFactor, this.maxDelay);
42:       }
43:     }
44: 
45:     throw lastError || new Error("Operation failed after retries");
46:   }
47: 
48:   private isNonRetryableError(error: Error): boolean {
49:     const nonRetryableErrors = ["PERMISSION_DENIED", "INVALID_ARGUMENT", "NOT_FOUND", "ALREADY_EXISTS"];
50: 
51:     return nonRetryableErrors.some((errorType) => error.message.includes(errorType));
52:   }
53: }
</file>

<file path="src/utils/timeout.ts">
 1: // src/utils/timeout.ts
 2: export class TimeoutError extends Error {
 3:   constructor(message: string) {
 4:     super(message);
 5:     this.name = "TimeoutError";
 6:   }
 7: }
 8: 
 9: export function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
10:   return Promise.race([
11:     promise,
12:     new Promise<T>((_, reject) => {
13:       setTimeout(() => {
14:         reject(new TimeoutError(`Operation timed out after ${timeoutMs}ms`));
15:       }, timeoutMs);
16:     }),
17:   ]);
18: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "include": [
3:     ".eslintrc.js"
4:   ]
5: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "moduleResolution": "node",
 5:     "noImplicitReturns": true,
 6:     "noUnusedLocals": true,
 7:     "outDir": "lib",
 8:     "sourceMap": true,
 9:     "strict": true,
10:     "target": "es2017",
11:     "skipLibCheck": true, // Add this line
12:     "esModuleInterop": true, // Make sure this is present
13:     "resolveJsonModule": true, // Add this line
14:     "baseUrl": "./src", // Add this line
15:     "paths": {
16:       // Add this section
17:       "*": ["*"]
18:     }
19:   },
20:   "compileOnSave": true,
21:   "include": ["src"],
22:   "exclude": ["node_modules", "lib"]
23: }
</file>

</repository_files>
