This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-17T05:38:50.747Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
.firebaserc
.gitignore
.npmrc
.prettierrc
.repomixignore
firebase.json
firestore.indexes.json
firestore.rules
package.json
repomix.config.json
src/config/firebase.ts
src/index.ts
src/scripts/cleanup.ts
src/scripts/prodSync.ts
src/scripts/setenv.ts
src/scripts/syncAll.ts
src/scripts/syncCards.ts
src/scripts/syncPrices.ts
src/scripts/testSync.ts
src/services/cardSync.ts
src/services/priceSync.ts
src/services/storageService.ts
src/types/index.ts
src/utils/api.ts
src/utils/cache.ts
src/utils/logger.ts
src/utils/rateLimiter.ts
src/utils/retention.ts
src/utils/retry.ts
src/utils/timeout.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     sourceType: "module",
19:   },
20:   ignorePatterns: [
21:     "/lib/**/*",
22:     "/generated/**/*",
23:     "*.js", // Add this line to ignore JS files
24:   ],
25:   plugins: ["@typescript-eslint", "import"],
26:   rules: {
27:     quotes: ["error", "double"],
28:     "import/no-unresolved": 0,
29:     indent: ["error", 2],
30:     "linebreak-style": 0, // Disable linebreak-style checks
31:     "object-curly-spacing": ["error", "always"],
32:     "max-len": ["error", { code: 120 }],
33:     "@typescript-eslint/no-explicit-any": "warn",
34:     "require-jsdoc": 0,
35:     "valid-jsdoc": 0,
36:     "@typescript-eslint/no-var-requires": 0,
37:     camelcase: 0,
38:   },
39: };
</file>

<file path=".firebaserc">
1: {
2:   "projects": {
3:     "default": "fftcg-sync-service"
4:   }
5: }
</file>

<file path=".gitignore">
 1: # Dependencies
 2: node_modules/
 3: 
 4: # Build output
 5: lib/
 6: dist/
 7: 
 8: # Environment variables
 9: .env
10: .env.local
11: .env.*.local
12: 
13: # Service account keys
14: service_account_key.json
15: *-service-account.json
16: 
17: # Firebase
18: .firebase/
19: firebase-debug.log
20: firebase-debug.*.log
21: 
22: # IDE
23: .vscode/
24: .idea/
25: 
26: # Logs
27: *.log
28: 
29: codebase.xml
</file>

<file path=".npmrc">
1: //us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/:_authToken=${NPM_TOKEN}
2: @google-cloud:registry=https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/
</file>

<file path=".prettierrc">
1: {
2:   "singleQuote": false,
3:   "trailingComma": "es5",
4:   "bracketSpacing": true,
5:   "semi": true,
6:   "printWidth": 120,
7:   "tabWidth": 2,
8:   "endOfLine": "auto"
9: }
</file>

<file path=".repomixignore">
1: lib/**
2: !*/
3: !.gitignore
4: service_account_key.json
5: !src/**
</file>

<file path="firebase.json">
 1: {
 2:   "functions": {
 3:     "source": ".",
 4:     "codebase": "default",
 5:     "runtime": "nodejs18",
 6:     "ignore": [
 7:       "node_modules",
 8:       ".git",
 9:       "firebase-debug.log",
10:       "firebase-debug.*.log",
11:       "*.local"
12:     ],
13:     "predeploy": [
14:       "npm run lint",
15:       "npm run build"
16:     ]
17:   },
18:   "firestore": {
19:     "rules": "firestore.rules",
20:     "indexes": "firestore.indexes.json"
21:   },
22:   "emulators": {
23:     "functions": {
24:       "port": 5001
25:     },
26:     "firestore": {
27:       "port": 8080
28:     },
29:     "ui": {
30:       "enabled": true
31:     },
32:     "singleProjectMode": true
33:   }
34: }
</file>

<file path="firestore.indexes.json">
 1: {
 2:   "indexes": [],
 3:   "fieldOverrides": [
 4:     {
 5:       "collectionGroup": "cards",
 6:       "fieldPath": "imageMetadata",
 7:       "indexes": []
 8:     },
 9:     {
10:       "collectionGroup": "cards",
11:       "fieldPath": "extendedData",
12:       "indexes": []
13:     },
14:     {
15:       "collectionGroup": "cards",
16:       "fieldPath": "lastUpdated",
17:       "indexes": []
18:     },
19:     {
20:       "collectionGroup": "prices",
21:       "fieldPath": "lastUpdated",
22:       "indexes": []
23:     },
24:     {
25:       "collectionGroup": "historicalPrices",
26:       "fieldPath": "lastUpdated",
27:       "indexes": []
28:     }
29:   ]
30: }
</file>

<file path="firestore.rules">
1: rules_version = '2';
2: service cloud.firestore {
3:   match /databases/{database}/documents {
4:     match /{document=**} {
5:       allow read, write: if false;
6:     }
7:   }
8: }
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "lint": "eslint --ext .js,.ts .",
 5:     "lint:fix": "eslint --ext .js,.ts . --fix",
 6:     "build": "rimraf lib && tsc",
 7:     "build:watch": "tsc --watch",
 8:     "serve": "npm run build && firebase emulators:start --only functions,firestore",
 9:     "shell": "npm run build && firebase functions:shell",
10:     "start": "npm run shell",
11:     "deploy": "firebase deploy --only functions",
12:     "logs": "firebase functions:log"
13:   },
14:   "engines": {
15:     "node": "18"
16:   },
17:   "main": "lib/index.js",
18:   "dependencies": {
19:     "@aws-sdk/client-s3": "^3.485.0",
20:     "@aws-sdk/s3-request-presigner": "^3.485.0",
21:     "axios": "^1.7.7",
22:     "cors": "^2.8.5",
23:     "dotenv": "^16.4.7",
24:     "express": "^4.18.2",
25:     "firebase-admin": "^12.0.0",
26:     "firebase-functions": "^6.2.0"
27:   },
28:   "devDependencies": {
29:     "@types/cors": "^2.8.17",
30:     "@types/express": "^4.17.21",
31:     "@typescript-eslint/eslint-plugin": "^5.12.0",
32:     "@typescript-eslint/parser": "^5.12.0",
33:     "eslint": "^8.9.0",
34:     "eslint-config-google": "^0.14.0",
35:     "eslint-plugin-import": "^2.25.4",
36:     "firebase-functions-test": "^3.1.0",
37:     "rimraf": "^5.0.0",
38:     "typescript": "^4.9.0"
39:   },
40:   "private": true,
41:   "publishConfig": {
42:     "registry": "https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/"
43:   }
44: }
</file>

<file path="repomix.config.json">
 1: {
 2:   "output": {
 3:     "filePath": "firestore_codebase.xml",
 4:     "style": "xml",
 5:     "removeComments": false,
 6:     "removeEmptyLines": false,
 7:     "topFilesLength": 5,
 8:     "showLineNumbers": true,
 9:     "copyToClipboard": false
10:   },
11:   "include": [],
12:   "ignore": {
13:     "useGitignore": false,
14:     "useDefaultPatterns": true,
15:     "customPatterns": []
16:   },
17:   "security": {
18:     "enableSecurityCheck": true
19:   }
20: }
</file>

<file path="src/config/firebase.ts">
 1: // src/config/firebase.ts
 2: import * as admin from "firebase-admin";
 3: 
 4: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 5: const db = admin.firestore(app);
 6: 
 7: // Enable ignoreUndefinedProperties and other settings
 8: db.settings({
 9:   ignoreUndefinedProperties: true,
10:   timestampsInSnapshots: true,
11: });
12: 
13: export { db };
14: 
15: export const COLLECTION = {
16:   CARDS: "cards",
17:   PRICES: "prices",
18:   SYNC_METADATA: "syncMetadata",
19:   LOGS: "logs",
20:   CARD_HASHES: "cardHashes",
21:   PRICE_HASHES: "priceHashes",
22:   IMAGE_METADATA: "imageMetadata",
23:   HISTORICAL_PRICES: "historicalPrices",
24:   CARD_DELTAS: "cardDeltas",
25:   PRICE_DELTAS: "priceDeltas",
26: } as const;
27: 
28: export const BASE_URL = "https://tcgcsv.com/tcgplayer";
29: export const FFTCG_CATEGORY_ID = "24";
30: 
31: export const runtimeOpts = {
32:   timeoutSeconds: 540,
33:   memory: "1GiB",
34: } as const;
</file>

<file path="src/index.ts">
  1: // src/index.ts
  2: import { onCall, HttpsError } from "firebase-functions/v2/https";
  3: import { onSchedule } from "firebase-functions/v2/scheduler";
  4: import { logger } from "firebase-functions/v2";
  5: import { cardSync } from "./services/cardSync";
  6: import { priceSync } from "./services/priceSync";
  7: import { retention } from "./utils/retention";
  8: import { runtimeOpts } from "./config/firebase";
  9: import * as dotenv from "dotenv";
 10: 
 11: dotenv.config();
 12: 
 13: // Manual card sync endpoint as a callable function
 14: export const manualCardSync = onCall(
 15:   {
 16:     memory: runtimeOpts.memory,
 17:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 18:     region: "us-central1",
 19:   },
 20:   async (request) => {
 21:     try {
 22:       const forceUpdate = request.data.force === true;
 23:       const groupId = request.data.groupId as string | undefined;
 24: 
 25:       const result = await cardSync.syncCards({
 26:         forceUpdate,
 27:         groupId,
 28:         skipImages: false,
 29:         imagesOnly: false,
 30:         silent: false,
 31:         dryRun: false,
 32:       });
 33: 
 34:       return result;
 35:     } catch (error) {
 36:       logger.error("Manual card sync failed", { error });
 37:       throw new HttpsError(
 38:         "internal",
 39:         error instanceof Error ? error.message : "Unknown error"
 40:       );
 41:     }
 42:   }
 43: );
 44: 
 45: // Manual price sync endpoint as a callable function
 46: export const manualPriceSync = onCall(
 47:   {
 48:     memory: runtimeOpts.memory,
 49:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 50:     region: "us-central1",
 51:   },
 52:   async (request) => {
 53:     try {
 54:       const forceUpdate = request.data.force === true;
 55:       const groupId = request.data.groupId as string | undefined;
 56: 
 57:       const result = await priceSync.syncPrices({
 58:         forceUpdate,
 59:         groupId,
 60:         silent: false,
 61:         dryRun: false,
 62:       });
 63: 
 64:       return result;
 65:     } catch (error) {
 66:       logger.error("Manual price sync failed", { error });
 67:       throw new HttpsError(
 68:         "internal",
 69:         error instanceof Error ? error.message : "Unknown error"
 70:       );
 71:     }
 72:   }
 73: );
 74: 
 75: // Manual cleanup endpoint as a callable function
 76: export const manualCleanup = onCall(
 77:   {
 78:     memory: runtimeOpts.memory,
 79:     timeoutSeconds: runtimeOpts.timeoutSeconds,
 80:     region: "us-central1",
 81:   },
 82:   async () => {
 83:     try {
 84:       await retention.cleanOldData();
 85:       return { success: true };
 86:     } catch (error) {
 87:       logger.error("Manual cleanup failed", { error });
 88:       throw new HttpsError(
 89:         "internal",
 90:         error instanceof Error ? error.message : "Unknown error"
 91:       );
 92:     }
 93:   }
 94: );
 95: 
 96: // Scheduled Functions
 97: export const scheduledCardSync = onSchedule(
 98:   {
 99:     schedule: "0 21 * * *", // Daily at 21:00 UTC
100:     timeZone: "UTC",
101:     memory: runtimeOpts.memory,
102:     timeoutSeconds: runtimeOpts.timeoutSeconds,
103:     retryCount: 3,
104:   },
105:   async () => {
106:     try {
107:       logger.info("Starting scheduled card sync");
108:       const result = await cardSync.syncCards({
109:         forceUpdate: false,
110:         skipImages: false,
111:         imagesOnly: false,
112:         silent: false,
113:         dryRun: false,
114:       });
115:       logger.info("Card sync completed", result);
116:     } catch (error) {
117:       logger.error("Scheduled card sync failed", { error });
118:       throw error;
119:     }
120:   }
121: );
122: 
123: export const scheduledPriceSync = onSchedule(
124:   {
125:     schedule: "30 21 * * *", // Daily at 21:30 UTC
126:     timeZone: "UTC",
127:     memory: runtimeOpts.memory,
128:     timeoutSeconds: runtimeOpts.timeoutSeconds,
129:     retryCount: 3,
130:   },
131:   async () => {
132:     try {
133:       logger.info("Starting scheduled price sync");
134:       const result = await priceSync.syncPrices({
135:         forceUpdate: false,
136:         silent: false,
137:         dryRun: false,
138:       });
139:       logger.info("Price sync completed", result);
140:     } catch (error) {
141:       logger.error("Scheduled price sync failed", { error });
142:       throw error;
143:     }
144:   }
145: );
146: 
147: export const scheduledCleanup = onSchedule(
148:   {
149:     schedule: "0 22 * * *", // Daily at 22:00 UTC
150:     timeZone: "UTC",
151:     memory: runtimeOpts.memory,
152:     timeoutSeconds: runtimeOpts.timeoutSeconds,
153:     retryCount: 3,
154:   },
155:   async () => {
156:     try {
157:       logger.info("Starting scheduled cleanup");
158:       await retention.cleanOldData();
159:       logger.info("Cleanup completed");
160:     } catch (error) {
161:       logger.error("Scheduled cleanup failed", { error });
162:       throw error;
163:     }
164:   }
165: );
</file>

<file path="src/scripts/cleanup.ts">
 1: import { retention } from "../utils/retention";
 2: 
 3: async function main() {
 4:   console.log("Starting manual cleanup...");
 5:   try {
 6:     await retention.cleanOldData();
 7:     console.log("Cleanup completed successfully");
 8:   } catch (error) {
 9:     console.error("Cleanup failed:", error);
10:     process.exit(1);
11:   }
12: }
13: 
14: main();
</file>

<file path="src/scripts/prodSync.ts">
  1: // src/scripts/prodSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger, LogData } from "../utils/logger";
  5: 
  6: 
  7: interface SyncStats {
  8:   success: boolean;
  9:   itemsProcessed: number;
 10:   itemsUpdated: number;
 11:   errors: string[];
 12:   duration: number;
 13: }
 14: 
 15: interface SyncOptions {
 16:   forceUpdate?: boolean;
 17:   groupId?: string;
 18:   cardsOnly?: boolean;
 19:   pricesOnly?: boolean;
 20: }
 21: 
 22: // Move runProductionSync into a class for better organization
 23: class ProductionSync {
 24:   async run(options: SyncOptions = {}) {
 25:     const startTime = Date.now();
 26:     const results: {
 27:       cards?: SyncStats;
 28:       prices?: SyncStats;
 29:     } = {};
 30: 
 31:     try {
 32:       logger.info("Starting production sync", { options } as LogData);
 33: 
 34:       // Run card sync if not prices-only
 35:       if (!options.pricesOnly) {
 36:         logger.info("Starting card sync...");
 37:         const cardResult = await cardSync.syncCards({
 38:           forceUpdate: options.forceUpdate,
 39:           groupId: options.groupId,
 40:         });
 41: 
 42:         results.cards = {
 43:           success: cardResult.success,
 44:           itemsProcessed: cardResult.itemsProcessed,
 45:           itemsUpdated: cardResult.itemsUpdated,
 46:           errors: cardResult.errors,
 47:           duration: cardResult.timing.duration || 0,
 48:         };
 49: 
 50:         logger.info("Card sync completed", { stats: results.cards } as LogData);
 51:       }
 52: 
 53:       // Run price sync if not cards-only
 54:       if (!options.cardsOnly) {
 55:         logger.info("Starting price sync...");
 56:         const priceResult = await priceSync.syncPrices({
 57:           forceUpdate: options.forceUpdate,
 58:           groupId: options.groupId,
 59:         });
 60: 
 61:         results.prices = {
 62:           success: priceResult.success,
 63:           itemsProcessed: priceResult.itemsProcessed,
 64:           itemsUpdated: priceResult.itemsUpdated,
 65:           errors: priceResult.errors,
 66:           duration: priceResult.timing.duration || 0,
 67:         };
 68: 
 69:         logger.info("Price sync completed", { stats: results.prices } as LogData);
 70:       }
 71: 
 72:       const totalDuration = (Date.now() - startTime) / 1000;
 73:       logger.info(`Full sync completed in ${totalDuration}s`, { results } as LogData);
 74: 
 75:       return results;
 76:     } catch (error) {
 77:       logger.error("Production sync failed", { error } as LogData);
 78:       throw error;
 79:     }
 80:   }
 81: }
 82: 
 83: function parseArgs(args: string[]): SyncOptions {
 84:   const options: SyncOptions = {};
 85: 
 86:   for (let i = 0; i < args.length; i++) {
 87:     switch (args[i]) {
 88:     case "--force":
 89:       options.forceUpdate = true;
 90:       break;
 91:     case "--group":
 92:       options.groupId = args[++i];
 93:       break;
 94:     case "--cards-only":
 95:       options.cardsOnly = true;
 96:       break;
 97:     case "--prices-only":
 98:       options.pricesOnly = true;
 99:       break;
100:     case "--help":
101:       printHelp();
102:       process.exit(0);
103:     }
104:   }
105: 
106:   return options;
107: }
108: 
109: function printHelp() {
110:   console.log(`
111: Usage: npx ts-node src/scripts/prodSync.ts [options]
112: 
113: Options:
114:   --force         Force update all items regardless of changes
115:   --group <id>    Sync specific group ID only
116:   --cards-only    Only sync card data
117:   --prices-only   Only sync price data
118:   --help          Show this help message
119:   
120: Examples:
121:   npx ts-node src/scripts/prodSync.ts
122:   npx ts-node src/scripts/prodSync.ts --force
123:   npx ts-node src/scripts/prodSync.ts --group 23244
124:   npx ts-node src/scripts/prodSync.ts --cards-only
125:   `);
126: }
127: 
128: // Create singleton instance
129: export const productionSync = new ProductionSync();
130: 
131: // Command line execution
132: async function main() {
133:   const args = process.argv.slice(2);
134:   const options = parseArgs(args);
135: 
136:   console.log("Starting production sync with options:", options);
137: 
138:   try {
139:     const results = await productionSync.run(options);
140:     console.log("Sync completed successfully!");
141:     console.log(JSON.stringify(results, null, 2));
142:     process.exit(0);
143:   } catch (error) {
144:     console.error("Sync failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Run if called directly
150: if (require.main === module) {
151:   main();
152: }
</file>

<file path="src/scripts/setenv.ts">
 1: // scripts/setenv.ts
 2: import * as dotenv from "dotenv";
 3: import { exec } from "child_process";
 4: import { promisify } from "util";
 5: 
 6: const execAsync = promisify(exec);
 7: 
 8: async function setFirebaseConfig() {
 9:   try {
10:     dotenv.config();
11: 
12:     const config = {
13:       account_id: process.env.R2_ACCOUNT_ID,
14:       access_key_id: process.env.R2_ACCESS_KEY_ID,
15:       secret_access_key: process.env.R2_SECRET_ACCESS_KEY,
16:       bucket_name: process.env.R2_BUCKET_NAME,
17:       storage_path: process.env.R2_STORAGE_PATH,
18:       custom_domain: process.env.R2_CUSTOM_DOMAIN,
19:     };
20: 
21:     // Remove existing config
22:     await execAsync("firebase functions:config:unset r2");
23: 
24:     // Set new config
25:     const configString = Object.entries(config)
26:       .map(([key, value]) => `r2.${key}="${value}"`)
27:       .join(" ");
28: 
29:     await execAsync(`firebase functions:config:set ${configString}`);
30:     console.log("Firebase config updated successfully");
31:   } catch (error) {
32:     console.error("Error setting Firebase config:", error);
33:   }
34: }
35: 
36: setFirebaseConfig();
</file>

<file path="src/scripts/syncAll.ts">
 1: import { cardSync } from "../services/cardSync";
 2: import { priceSync } from "../services/priceSync";
 3: 
 4: async function main() {
 5:   console.log("Starting full sync...");
 6: 
 7:   try {
 8:     console.log("\n1. Running card sync...");
 9:     const cardResult = await cardSync.syncCards();
10:     console.log("Card sync completed:", {
11:       success: cardResult.success,
12:       processed: cardResult.itemsProcessed,
13:       updated: cardResult.itemsUpdated,
14:       errors: cardResult.errors.length,
15:     });
16: 
17:     console.log("\n2. Running price sync...");
18:     const priceResult = await priceSync.syncPrices();
19:     console.log("Price sync completed:", {
20:       success: priceResult.success,
21:       processed: priceResult.itemsProcessed,
22:       updated: priceResult.itemsUpdated,
23:       errors: priceResult.errors.length,
24:     });
25: 
26:     const allErrors = [...cardResult.errors, ...priceResult.errors];
27:     if (allErrors.length > 0) {
28:       console.log("\nErrors encountered:");
29:       allErrors.forEach((error) => console.log(`- ${error}`));
30:     }
31: 
32:     console.log("\nFull sync completed!");
33:   } catch (error) {
34:     console.error("Full sync failed:", error);
35:     process.exit(1);
36:   }
37: }
38: 
39: main();
</file>

<file path="src/scripts/syncCards.ts">
 1: // src/scripts/syncCards.ts
 2: import { cardSync } from "../services/cardSync";
 3: 
 4: function parseArgs(args: string[]): { forceUpdate?: boolean; groupId?: string } {
 5:   const options: { forceUpdate?: boolean; groupId?: string } = {};
 6: 
 7:   for (let i = 0; i < args.length; i++) {
 8:     switch (args[i]) {
 9:       case "--force":
10:         options.forceUpdate = true;
11:         break;
12:       case "--group":
13:         options.groupId = args[++i];
14:         break;
15:     }
16:   }
17: 
18:   return options;
19: }
20: 
21: async function main() {
22:   try {
23:     const args = process.argv.slice(2);
24:     const options = parseArgs(args);
25: 
26:     console.log("Starting manual card sync with options:", options);
27:     const result = await cardSync.syncCards(options);
28:     console.log("Card sync completed:", {
29:       success: result.success,
30:       processed: result.itemsProcessed,
31:       updated: result.itemsUpdated,
32:       errors: result.errors.length,
33:       duration: `${result.timing.duration}s`,
34:     });
35: 
36:     if (result.errors.length > 0) {
37:       console.log("\nErrors encountered:");
38:       result.errors.forEach((error) => console.log(`- ${error}`));
39:     }
40:   } catch (error) {
41:     console.error("Card sync failed:", error);
42:     process.exit(1);
43:   } finally {
44:     // Force exit after a short delay to allow final logs to be written
45:     setTimeout(() => process.exit(0), 1000);
46:   }
47: }
48: 
49: main();
</file>

<file path="src/scripts/syncPrices.ts">
 1: import { priceSync } from "../services/priceSync";
 2: 
 3: async function main() {
 4:   console.log("Starting manual price sync...");
 5:   try {
 6:     const result = await priceSync.syncPrices();
 7:     console.log("Price sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Price sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/testSync.ts">
  1: // src/scripts/testSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger } from "../utils/logger";
  5: import { withTimeout, TimeoutError } from "../utils/timeout";
  6: import { storageService } from "../services/storageService";
  7: 
  8: const MAX_SYNC_TIME = 30 * 60 * 1000; // 30 minutes
  9: const TEST_GROUP_ID = "23244"; // Dawn of Heroes
 10: const TEST_PRODUCT_ID = 508343; // Example product ID
 11: const IMAGE_BASE_URL = "https://fftcgcompanion.com/card-images";
 12: 
 13: async function testImageProcessing() {
 14:   try {
 15:     logger.info("Testing image processing...");
 16: 
 17:     // Test with a valid image URL using correct format
 18:     const validImageResult = await storageService.processAndStoreImage(
 19:       `${IMAGE_BASE_URL}/${TEST_GROUP_ID}/${TEST_PRODUCT_ID}_200w.jpg`,
 20:       TEST_PRODUCT_ID,
 21:       TEST_GROUP_ID,
 22:       "1-001" // Example card number
 23:     );
 24: 
 25:     logger.info("Valid image processing result:", {
 26:       highResUrl: validImageResult.highResUrl,
 27:       lowResUrl: validImageResult.lowResUrl,
 28:       isPlaceholder: validImageResult.metadata.isPlaceholder,
 29:       originalUrl: validImageResult.metadata.originalUrl,
 30:     });
 31: 
 32:     // Verify the image URLs follow the correct pattern
 33:     const urlPattern = new RegExp(`^${IMAGE_BASE_URL}/.*_[24]00w.jpg$`);
 34:     const isValidImageUrl = urlPattern.test(validImageResult.metadata.originalUrl || "");
 35: 
 36:     if (!isValidImageUrl) {
 37:       logger.error("Image URL pattern does not match expected format", {
 38:         url: validImageResult.metadata.originalUrl,
 39:         expectedPattern: `${IMAGE_BASE_URL}/{groupId}/{productId}_200w.jpg`,
 40:       });
 41:     }
 42: 
 43:     // Test with invalid/missing image (should return placeholder)
 44:     const placeholderResult = await storageService.processAndStoreImage(
 45:       undefined,
 46:       TEST_PRODUCT_ID,
 47:       TEST_GROUP_ID,
 48:       "1-001"
 49:     );
 50: 
 51:     logger.info("Placeholder image result:", {
 52:       highResUrl: placeholderResult.highResUrl,
 53:       lowResUrl: placeholderResult.lowResUrl,
 54:       isPlaceholder: placeholderResult.metadata.isPlaceholder,
 55:     });
 56: 
 57:     return {
 58:       validImage: {
 59:         success: validImageResult.metadata.isPlaceholder !== true,
 60:         correctUrlPattern: isValidImageUrl,
 61:         urls: {
 62:           original: validImageResult.metadata.originalUrl,
 63:           highRes: validImageResult.highResUrl,
 64:           lowRes: validImageResult.lowResUrl,
 65:         },
 66:       },
 67:       placeholderImage: {
 68:         success: placeholderResult.metadata.isPlaceholder === true,
 69:         urls: {
 70:           highRes: placeholderResult.highResUrl,
 71:           lowRes: placeholderResult.lowResUrl,
 72:         },
 73:       },
 74:     };
 75:   } catch (error) {
 76:     logger.error("Image processing test failed:", { error });
 77:     throw error;
 78:   }
 79: }
 80: 
 81: async function testSync() {
 82:   try {
 83:     logger.info("Starting test sync with group " + TEST_GROUP_ID);
 84: 
 85:     // Test image processing first
 86:     logger.info("Testing image processing capabilities...");
 87:     const imageResults = await testImageProcessing();
 88:     logger.info("Image processing test results:", imageResults);
 89: 
 90:     // Monitor card sync with timeout
 91:     const cardResult = await withTimeout(
 92:       cardSync.syncCards({
 93:         groupId: TEST_GROUP_ID,
 94:         forceUpdate: true,
 95:       }),
 96:       MAX_SYNC_TIME
 97:     );
 98: 
 99:     logger.info("Card sync results:", {
100:       processed: cardResult.itemsProcessed,
101:       updated: cardResult.itemsUpdated,
102:       errors: cardResult.errors,
103:       timing: cardResult.timing,
104:     });
105: 
106:     // Monitor price sync with timeout
107:     const priceResult = await withTimeout(
108:       priceSync.syncPrices({
109:         groupId: TEST_GROUP_ID,
110:         forceUpdate: true,
111:       }),
112:       MAX_SYNC_TIME
113:     );
114: 
115:     logger.info("Price sync results:", {
116:       processed: priceResult.itemsProcessed,
117:       updated: priceResult.itemsUpdated,
118:       errors: priceResult.errors,
119:       timing: priceResult.timing,
120:     });
121: 
122:     // Validate results
123:     const validationResults = {
124:       imageProcessing: imageResults,
125:       cardSync: {
126:         success: cardResult.success,
127:         hasUpdates: cardResult.itemsUpdated > 0,
128:         hasErrors: cardResult.errors.length > 0,
129:       },
130:       priceSync: {
131:         success: priceResult.success,
132:         hasUpdates: priceResult.itemsUpdated > 0,
133:         hasErrors: priceResult.errors.length > 0,
134:       },
135:     };
136: 
137:     logger.info("Test validation results:", validationResults);
138: 
139:     // Log any errors
140:     const allErrors = [...cardResult.errors, ...priceResult.errors];
141:     if (allErrors.length > 0) {
142:       logger.error("Errors during sync:", { errors: allErrors });
143:     }
144: 
145:     return validationResults;
146:   } catch (error) {
147:     if (error instanceof TimeoutError) {
148:       logger.error("Sync operation timed out", { error });
149:     } else {
150:       logger.error("Test sync failed:", { error });
151:     }
152:     throw error;
153:   }
154: }
155: 
156: // Execute if run directly
157: if (require.main === module) {
158:   testSync()
159:     .then((results) => {
160:       console.log("Test sync completed successfully!");
161:       console.log("Results:", JSON.stringify(results, null, 2));
162:       process.exit(0);
163:     })
164:     .catch((error) => {
165:       console.error("Test failed:", error);
166:       process.exit(1);
167:     });
168: }
169: 
170: export { testSync, testImageProcessing };
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { storageService } from "./storageService";
  5: import { CardProduct, SyncResult, CardHashData, SyncOptions, CardChanges } from "../types";
  6: import { logger } from "../utils/logger";
  7: import { RateLimiter } from "../utils/rateLimiter";
  8: import { Cache } from "../utils/cache";
  9: import { RetryWithBackoff } from "../utils/retry";
 10: import * as crypto from "crypto";
 11: import { FieldValue } from "firebase-admin/firestore";
 12: 
 13: export class CardSyncService {
 14:   private readonly BATCH_SIZE = 500; // Optimized batch size
 15:   private readonly MAX_PARALLEL_BATCHES = 3; // Reduced for better control
 16:   private readonly MAX_BATCH_OPERATIONS = 499; // Just under Firestore's limit
 17:   private readonly IMAGE_CONCURRENCY = 5; // Control parallel image processing
 18: 
 19:   private readonly rateLimiter = new RateLimiter();
 20:   private readonly cache = new Cache<string>(15);
 21:   private readonly retry = new RetryWithBackoff();
 22: 
 23:   private calculateHash(data: CardHashData): string {
 24:     return crypto
 25:       .createHash("md5")
 26:       .update(JSON.stringify(data))
 27:       .digest("hex");
 28:   }
 29: 
 30:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 31:     const hashMap = new Map<number, string>();
 32:     const uncachedIds: number[] = [];
 33: 
 34:     // Check cache first
 35:     productIds.forEach((id) => {
 36:       const cacheKey = `hash_${id}`;
 37:       const cached = this.cache.get(cacheKey);
 38:       if (cached) {
 39:         hashMap.set(id, cached);
 40:       } else {
 41:         uncachedIds.push(id);
 42:       }
 43:     });
 44: 
 45:     if (uncachedIds.length === 0) {
 46:       return hashMap;
 47:     }
 48: 
 49:     // Batch get uncached hashes
 50:     const chunks = [];
 51:     for (let i = 0; i < uncachedIds.length; i += 10) {
 52:       chunks.push(uncachedIds.slice(i, i + 10));
 53:     }
 54: 
 55:     await Promise.all(chunks.map(async (chunk) => {
 56:       const refs = chunk.map((id) =>
 57:         db.collection(COLLECTION.CARD_HASHES).doc(id.toString())
 58:       );
 59: 
 60:       const snapshots = await this.retry.execute(() =>
 61:         db.getAll(...refs)
 62:       );
 63: 
 64:       snapshots.forEach((snap, index) => {
 65:         const id = chunk[index];
 66:         const hash = snap.exists ? snap.data()?.hash : null;
 67:         if (hash) {
 68:           hashMap.set(id, hash);
 69:           this.cache.set(`hash_${id}`, hash);
 70:         }
 71:       });
 72:     }));
 73: 
 74:     return hashMap;
 75:   }
 76: 
 77:   private getCardNumbers(card: CardProduct): string[] {
 78:     const numbers: string[] = [];
 79:     card.extendedData
 80:       .filter((data) => data.name === "Number")
 81:       .forEach((numberField) => {
 82:         const vals = numberField.value.split(/[,;/]/).map((n) => n.trim());
 83:         numbers.push(...vals);
 84:       });
 85: 
 86:     if (numbers.length === 0) {
 87:       numbers.push(`P${card.productId}`);
 88:     }
 89: 
 90:     return [...new Set(numbers)];
 91:   }
 92: 
 93:   private isNonCardProduct(card: CardProduct): boolean {
 94:     const cardType = card.extendedData.find((data) => data.name === "CardType")?.value;
 95:     return !cardType || cardType.toLowerCase() === "sealed product";
 96:   }
 97: 
 98:   private async saveDeltaUpdate(
 99:     batch: FirebaseFirestore.WriteBatch,
100:     card: CardProduct,
101:     changes: CardChanges
102:   ): Promise<void> {
103:   // Here we want to use an auto-generated ID since deltas are meant
104:   // to be new documents recording historical changes
105:     const deltaRef = db.collection(COLLECTION.CARD_DELTAS).doc();
106: 
107:     // No merge needed since this is a new delta document
108:     batch.set(deltaRef, {
109:       productId: card.productId,
110:       changes,
111:       timestamp: FieldValue.serverTimestamp(),
112:     });
113:   }
114: 
115:   private async processCardBatch(
116:     cards: CardProduct[],
117:     groupId: string,
118:     options: { forceUpdate?: boolean } = {}
119:   ): Promise<{
120:   processed: number;
121:   updated: number;
122:   errors: string[];
123: }> {
124:     const result = {
125:       processed: 0,
126:       updated: 0,
127:       errors: [] as string[],
128:     };
129: 
130:     try {
131:     // Pre-fetch all hashes in one go
132:       const productIds = cards.map((card) => card.productId);
133:       const hashMap = await this.getStoredHashes(productIds);
134: 
135:       // Process images in controlled parallel chunks
136:       const imageProcessingChunks: Array<Promise<{
137:       card: CardProduct;
138:       imageResult: Awaited<ReturnType<typeof storageService.processAndStoreImage>>;
139:     }>> = [];
140: 
141:       // Process images with controlled concurrency
142:       for (let i = 0; i < cards.length; i += this.IMAGE_CONCURRENCY) {
143:         const chunk = cards.slice(i, i + this.IMAGE_CONCURRENCY);
144:         const chunkPromises = chunk.map(async (card) => {
145:           try {
146:             const cardNumbers = this.getCardNumbers(card);
147:             const primaryCardNumber = cardNumbers[0];
148: 
149:             const imageResult = await this.retry.execute(() =>
150:               storageService.processAndStoreImage(
151:                 card.imageUrl,
152:                 card.productId,
153:                 groupId,
154:                 primaryCardNumber
155:               )
156:             );
157: 
158:             return { card, imageResult };
159:           } catch (error) {
160:             const errorMessage = error instanceof Error ? error.message : "Unknown error";
161:             result.errors.push(`Image processing failed for card ${card.productId}: ${errorMessage}`);
162:             throw error;
163:           }
164:         });
165: 
166:         imageProcessingChunks.push(...chunkPromises);
167: 
168:         if (i + this.IMAGE_CONCURRENCY < cards.length) {
169:           await new Promise((resolve) => setTimeout(resolve, 500));
170:         }
171:       }
172: 
173:       // Wait for current chunk of image processing to complete
174:       const processedImages = await Promise.allSettled(imageProcessingChunks);
175: 
176:       // Create smaller sub-batches to prevent exceeding Firestore limits
177:       const SUB_BATCH_SIZE = 20; // Reduced batch size for better control
178:       const subBatches: Array<{
179:       card: CardProduct;
180:       imageResult: Awaited<ReturnType<typeof storageService.processAndStoreImage>>;
181:     }[]> = [];
182: 
183:       const successfulImages = processedImages
184:         .filter((result): result is PromiseFulfilledResult<{
185:         card: CardProduct;
186:         imageResult: Awaited<ReturnType<typeof storageService.processAndStoreImage>>;
187:       }> => result.status === "fulfilled")
188:         .map((result) => result.value);
189: 
190:       // Split into sub-batches
191:       for (let i = 0; i < successfulImages.length; i += SUB_BATCH_SIZE) {
192:         subBatches.push(successfulImages.slice(i, i + SUB_BATCH_SIZE));
193:       }
194: 
195:       // Process each sub-batch
196:       for (const subBatch of subBatches) {
197:         let mainBatch = db.batch();
198:         let batchCount = 0;
199: 
200:         for (const { card, imageResult } of subBatch) {
201:           result.processed++;
202: 
203:           try {
204:             const relevantData: CardHashData = {
205:               name: card.name,
206:               cleanName: card.cleanName,
207:               modifiedOn: card.modifiedOn,
208:               extendedData: card.extendedData,
209:             };
210: 
211:             const currentHash = this.calculateHash(relevantData);
212:             const storedHash = hashMap.get(card.productId);
213: 
214:             if (currentHash === storedHash && !options.forceUpdate) {
215:               logger.info(`Skipping card ${card.productId} - no changes`);
216:               continue;
217:             }
218: 
219:             const cardNumbers = this.getCardNumbers(card);
220:             const primaryCardNumber = cardNumbers[0];
221: 
222:             const cardDoc = {
223:               productId: card.productId,
224:               name: card.name,
225:               cleanName: card.cleanName,
226:               fullResUrl: imageResult.fullResUrl,
227:               highResUrl: imageResult.highResUrl,
228:               lowResUrl: imageResult.lowResUrl,
229:               lastUpdated: FieldValue.serverTimestamp(),
230:               groupId: parseInt(groupId),
231:               isNonCard: this.isNonCardProduct(card),
232:               cardNumbers,
233:               primaryCardNumber,
234:             };
235: 
236:             // Main card document
237:             const cardRef = db.collection(COLLECTION.CARDS)
238:               .doc(card.productId.toString());
239:             mainBatch.set(cardRef, cardDoc, { merge: true });
240:             batchCount++;
241: 
242:             // Extended data subcollection
243:             const extendedDataRef = cardRef.collection("extendedData");
244:             card.extendedData.forEach((data) => {
245:               mainBatch.set(extendedDataRef.doc(data.name), data, { merge: true }); // Add merge: true
246:             });
247: 
248:             // Image metadata
249:             mainBatch.set(
250:               cardRef.collection("metadata").doc("image"),
251:               imageResult.metadata,
252:               { merge: true } // Add merge: true
253:             );
254:             batchCount++;
255: 
256:             // Update hash
257:             const hashRef = db.collection(COLLECTION.CARD_HASHES)
258:               .doc(card.productId.toString());
259:             mainBatch.set(hashRef, {
260:               hash: currentHash,
261:               lastUpdated: FieldValue.serverTimestamp(),
262:             }, { merge: true }); // Ensure merge: true is here
263:             batchCount++;
264: 
265:             // Save delta update
266:             await this.saveDeltaUpdate(mainBatch, card, cardDoc);
267:             batchCount++;
268: 
269:             // Update cache
270:             this.cache.set(`hash_${card.productId}`, currentHash);
271: 
272:             // If batch is getting full, commit it and start a new one
273:             if (batchCount >= this.MAX_BATCH_OPERATIONS) {
274:               await this.rateLimiter.add(() =>
275:                 this.retry.execute(() => mainBatch.commit())
276:               );
277:               mainBatch = db.batch();
278:               batchCount = 0;
279:             }
280: 
281:             result.updated++;
282:             logger.info(
283:               `Updated card ${card.productId}: ${card.name} with numbers: ${cardNumbers.join(", ")}`
284:             );
285:           } catch (error) {
286:             const errorMessage = error instanceof Error ? error.message : "Unknown error";
287:             result.errors.push(`Error processing card ${card.productId}: ${errorMessage}`);
288:             logger.error(`Error processing card ${card.productId}`, { error: errorMessage });
289:           }
290:         }
291: 
292:         // Commit any remaining operations in the final batch
293:         if (batchCount > 0) {
294:           await this.rateLimiter.add(() =>
295:             this.retry.execute(() => mainBatch.commit())
296:           );
297:         }
298:       }
299:     } catch (error) {
300:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
301:       result.errors.push(`Batch processing error: ${errorMessage}`);
302:       logger.error("Batch processing error", { error: errorMessage });
303:     }
304: 
305:     return result;
306:   }
307: 
308:   private async processCardBatches(
309:     cards: CardProduct[],
310:     groupId: string,
311:     options: { forceUpdate?: boolean } = {}
312:   ): Promise<{
313:     processed: number;
314:     updated: number;
315:     errors: string[];
316:   }> {
317:     // Split into optimally sized batches
318:     const batches: CardProduct[][] = [];
319:     for (let i = 0; i < cards.length; i += this.BATCH_SIZE) {
320:       batches.push(cards.slice(i, i + this.BATCH_SIZE));
321:     }
322: 
323:     const results = [];
324:     // Process batches with controlled parallelism
325:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
326:       const currentBatches = batches.slice(i, i + this.MAX_PARALLEL_BATCHES);
327:       const batchPromises = currentBatches.map((batch) =>
328:         this.processCardBatch(batch, groupId, options)
329:       );
330: 
331:       const batchResults = await Promise.all(batchPromises);
332:       results.push(...batchResults);
333: 
334:       // Add delay between batch groups to prevent rate limiting
335:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
336:         await new Promise((resolve) => setTimeout(resolve, 2000));
337:       }
338:     }
339: 
340:     // Combine results
341:     return results.reduce(
342:       (acc, curr) => ({
343:         processed: acc.processed + curr.processed,
344:         updated: acc.updated + curr.updated,
345:         errors: [...acc.errors, ...curr.errors],
346:       }),
347:       { processed: 0, updated: 0, errors: [] }
348:     );
349:   }
350: 
351:   async syncCards(options: SyncOptions = {}): Promise<SyncResult> {
352:     const result: SyncResult = {
353:       success: true,
354:       itemsProcessed: 0,
355:       itemsUpdated: 0,
356:       errors: [],
357:       timing: {
358:         startTime: new Date(),
359:       },
360:     };
361: 
362:     try {
363:       logger.info("Starting card sync", { options });
364: 
365:       // Get groups to process
366:       const groups = options.groupId ?
367:         [{ groupId: options.groupId }] :
368:         await tcgcsvApi.getGroups();
369: 
370:       logger.info(`Found ${groups.length} groups to process`);
371: 
372:       // Process each group sequentially to prevent overload
373:       for (const group of groups) {
374:         result.timing.groupStartTime = new Date();
375:         try {
376:           // Get cards for current group with retry
377:           const cards = await this.retry.execute(() =>
378:             tcgcsvApi.getGroupProducts(group.groupId)
379:           );
380: 
381:           logger.info(`Processing ${cards.length} cards for group ${group.groupId}`);
382: 
383:           // Process cards in optimized batches
384:           const batchResults = await this.processCardBatches(
385:             cards,
386:             group.groupId,
387:             options
388:           );
389: 
390:           // Update results
391:           result.itemsProcessed += batchResults.processed;
392:           result.itemsUpdated += batchResults.updated;
393:           result.errors.push(...batchResults.errors);
394: 
395:           // Calculate and log group timing
396:           const groupEndTime = new Date();
397:           const groupStartTime = result.timing.groupStartTime || new Date();
398:           const groupDuration = (groupEndTime.getTime() - groupStartTime.getTime()) / 1000;
399: 
400:           logger.info(`Completed group ${group.groupId} in ${groupDuration}s`, {
401:             processed: batchResults.processed,
402:             updated: batchResults.updated,
403:             errors: batchResults.errors.length,
404:           });
405: 
406:           // Add delay between groups
407:           if (groups.length > 1) {
408:             await new Promise((resolve) => setTimeout(resolve, 3000));
409:           }
410:         } catch (error) {
411:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
412:           result.errors.push(
413:             `Error processing cards for group ${group.groupId}: ${errorMessage}`
414:           );
415:           logger.error(`Error processing group ${group.groupId}`, {
416:             error: errorMessage,
417:           });
418:         }
419:       }
420:     } catch (error) {
421:       result.success = false;
422:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
423:       result.errors.push(`Card sync failed: ${errorMessage}`);
424:       logger.error("Card sync failed", { error: errorMessage });
425:     }
426: 
427:     // Calculate final timing
428:     result.timing.endTime = new Date();
429:     result.timing.duration =
430:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
431: 
432:     // Log final results
433:     logger.info(`Card sync completed in ${result.timing.duration}s`, {
434:       processed: result.itemsProcessed,
435:       updated: result.itemsUpdated,
436:       errors: result.errors.length,
437:       timing: result.timing,
438:     });
439: 
440:     return result;
441:   }
442: }
443: 
444: export const cardSync = new CardSyncService();
</file>

<file path="src/services/priceSync.ts">
  1: // src/services/priceSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { CardPrice, SyncResult, SyncOptions } from "../types";
  5: import { logger } from "../utils/logger";
  6: import { RateLimiter } from "../utils/rateLimiter";
  7: import { Cache } from "../utils/cache";
  8: import { RetryWithBackoff } from "../utils/retry";
  9: import * as crypto from "crypto";
 10: import { FieldValue, WriteResult } from "firebase-admin/firestore";
 11: 
 12: export class PriceSyncService {
 13:   private readonly BATCH_SIZE = 500; // Optimized batch size
 14:   private readonly MAX_PARALLEL_BATCHES = 3; // Reduced parallel operations
 15:   private readonly MAX_BATCH_OPERATIONS = 499; // Just under Firestore's limit
 16: 
 17:   private readonly rateLimiter = new RateLimiter();
 18:   private readonly cache = new Cache<string>(15);
 19:   private readonly retry = new RetryWithBackoff();
 20: 
 21:   private calculateHash(price: CardPrice): string {
 22:     const relevantData = {
 23:       normal: price.normal,
 24:       foil: price.foil,
 25:       lastUpdated: price.lastUpdated,
 26:     };
 27:     return crypto.createHash("md5").update(JSON.stringify(relevantData)).digest("hex");
 28:   }
 29: 
 30:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 31:     const hashMap = new Map<number, string>();
 32:     const uncachedIds: number[] = [];
 33: 
 34:     // Check cache first
 35:     productIds.forEach((id) => {
 36:       const cacheKey = `price_hash_${id}`;
 37:       const cached = this.cache.get(cacheKey);
 38:       if (cached) {
 39:         hashMap.set(id, cached);
 40:       } else {
 41:         uncachedIds.push(id);
 42:       }
 43:     });
 44: 
 45:     if (uncachedIds.length === 0) {
 46:       return hashMap;
 47:     }
 48: 
 49:     // Batch get uncached hashes
 50:     const chunks = [];
 51:     for (let i = 0; i < uncachedIds.length; i += 10) {
 52:       chunks.push(uncachedIds.slice(i, i + 10));
 53:     }
 54: 
 55:     await Promise.all(chunks.map(async (chunk) => {
 56:       const refs = chunk.map((id) =>
 57:         db.collection(COLLECTION.PRICE_HASHES).doc(id.toString())
 58:       );
 59: 
 60:       const snapshots = await this.retry.execute(() =>
 61:         db.getAll(...refs)
 62:       );
 63: 
 64:       snapshots.forEach((snap, index) => {
 65:         const id = chunk[index];
 66:         const hash = snap.exists ? snap.data()?.hash : null;
 67:         if (hash) {
 68:           hashMap.set(id, hash);
 69:           this.cache.set(`price_hash_${id}`, hash);
 70:         }
 71:       });
 72:     }));
 73: 
 74:     return hashMap;
 75:   }
 76: 
 77:   private validatePrice(price: CardPrice): boolean {
 78:     const validatePriceData = (data: typeof price.normal | typeof price.foil) => {
 79:       if (!data) return false;
 80:       return (
 81:         typeof data.marketPrice === "number" &&
 82:         data.marketPrice >= 0 &&
 83:         typeof data.lowPrice === "number" &&
 84:         data.lowPrice >= 0 &&
 85:         typeof data.highPrice === "number" &&
 86:         data.highPrice >= 0
 87:       );
 88:     };
 89: 
 90:     return validatePriceData(price.normal) || validatePriceData(price.foil);
 91:   }
 92: 
 93:   private async processPriceBatch(
 94:     prices: CardPrice[],
 95:     groupId: string,
 96:     options: { forceUpdate?: boolean } = {}
 97:   ): Promise<{
 98:     processed: number;
 99:     updated: number;
100:     errors: string[];
101:   }> {
102:     const result = {
103:       processed: 0,
104:       updated: 0,
105:       errors: [] as string[],
106:     };
107: 
108:     try {
109:       // Pre-fetch all hashes in one go
110:       const productIds = prices.map((price) => price.productId);
111:       const hashMap = await this.getStoredHashes(productIds);
112: 
113:       // Prepare batches
114:       let mainBatch = db.batch();
115:       let historicalBatch = db.batch();
116:       let mainOps = 0;
117:       let historicalOps = 0;
118:       const batchPromises: Promise<WriteResult[]>[] = [];
119: 
120:       // Prepare date once
121:       const today = new Date();
122:       today.setHours(0, 0, 0, 0);
123: 
124:       for (const price of prices) {
125:         try {
126:           result.processed++;
127: 
128:           if (!this.validatePrice(price)) continue;
129: 
130:           const currentHash = this.calculateHash(price);
131:           const storedHash = hashMap.get(price.productId);
132: 
133:           if (currentHash === storedHash && !options.forceUpdate) {
134:             continue;
135:           }
136: 
137:           // Prepare documents
138:           const priceDoc = {
139:             productId: price.productId,
140:             lastUpdated: FieldValue.serverTimestamp(),
141:             groupId: parseInt(groupId),
142:             ...(price.normal && { normal: price.normal }),
143:             ...(price.foil && { foil: price.foil }),
144:           };
145: 
146:           const historicalDoc = {
147:             productId: price.productId,
148:             groupId,
149:             date: today,
150:             timestamp: FieldValue.serverTimestamp(),
151:             ...(price.normal && {
152:               normal: {
153:                 directLow: price.normal.directLowPrice,
154:                 high: price.normal.highPrice,
155:                 low: price.normal.lowPrice,
156:                 market: price.normal.marketPrice,
157:                 mid: price.normal.midPrice,
158:               },
159:             }),
160:             ...(price.foil && {
161:               foil: {
162:                 directLow: price.foil.directLowPrice,
163:                 high: price.foil.highPrice,
164:                 low: price.foil.lowPrice,
165:                 market: price.foil.marketPrice,
166:                 mid: price.foil.midPrice,
167:               },
168:             }),
169:           };
170: 
171:           // Add to main batch
172:           const priceRef = db.collection(COLLECTION.PRICES).doc(price.productId.toString());
173:           mainBatch.set(priceRef, priceDoc, { merge: true });
174:           mainOps++;
175: 
176:           // Add hash update to same batch
177:           const hashRef = db.collection(COLLECTION.PRICE_HASHES).doc(price.productId.toString());
178:           mainBatch.set(hashRef, {
179:             hash: currentHash,
180:             lastUpdated: FieldValue.serverTimestamp(),
181:           }, { merge: true });
182:           mainOps++;
183: 
184:           // Add to historical batch
185:           const docId = `${price.productId}_${today.toISOString().split("T")[0]}`;
186:           const historicalRef = db.collection(COLLECTION.HISTORICAL_PRICES).doc(docId);
187:           historicalBatch.set(historicalRef, historicalDoc, { merge: true });
188:           historicalOps++;
189: 
190:           // Commit batches if reaching limits
191:           if (mainOps >= this.MAX_BATCH_OPERATIONS) {
192:             batchPromises.push(
193:               this.rateLimiter.add(() => this.retry.execute(() => mainBatch.commit()))
194:             );
195:             mainBatch = db.batch();
196:             mainOps = 0;
197:           }
198: 
199:           if (historicalOps >= this.MAX_BATCH_OPERATIONS) {
200:             batchPromises.push(
201:               this.rateLimiter.add(() => this.retry.execute(() => historicalBatch.commit()))
202:             );
203:             historicalBatch = db.batch();
204:             historicalOps = 0;
205:           }
206: 
207:           result.updated++;
208: 
209:           // Update cache
210:           this.cache.set(`price_hash_${price.productId}`, currentHash);
211:         } catch (error) {
212:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
213:           result.errors.push(`Error processing price for product ${price.productId}: ${errorMessage}`);
214:         }
215:       }
216: 
217:       // Commit remaining batches
218:       if (mainOps > 0) {
219:         batchPromises.push(
220:           this.rateLimiter.add(() => this.retry.execute(() => mainBatch.commit()))
221:         );
222:       }
223: 
224:       if (historicalOps > 0) {
225:         batchPromises.push(
226:           this.rateLimiter.add(() => this.retry.execute(() => historicalBatch.commit()))
227:         );
228:       }
229: 
230:       // Wait for all batches to complete
231:       await Promise.all(batchPromises);
232:     } catch (error) {
233:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
234:       result.errors.push(`Batch processing error: ${errorMessage}`);
235:     }
236: 
237:     return result;
238:   }
239: 
240:   private async processPriceBatches(
241:     prices: CardPrice[],
242:     groupId: string,
243:     options: { forceUpdate?: boolean } = {}
244:   ): Promise<{
245:     processed: number;
246:     updated: number;
247:     errors: string[];
248:   }> {
249:     // Split into optimally sized batches
250:     const batches: CardPrice[][] = [];
251:     for (let i = 0; i < prices.length; i += this.BATCH_SIZE) {
252:       batches.push(prices.slice(i, i + this.BATCH_SIZE));
253:     }
254: 
255:     const results = [];
256:     // Process batches with controlled parallelism
257:     for (let i = 0; i < batches.length; i += this.MAX_PARALLEL_BATCHES) {
258:       const currentBatches = batches.slice(i, i + this.MAX_PARALLEL_BATCHES);
259:       const batchPromises = currentBatches.map((batch) =>
260:         this.processPriceBatch(batch, groupId, options)
261:       );
262: 
263:       const batchResults = await Promise.all(batchPromises);
264:       results.push(...batchResults);
265: 
266:       // Add delay between batch groups to prevent rate limiting
267:       if (i + this.MAX_PARALLEL_BATCHES < batches.length) {
268:         await new Promise((resolve) => setTimeout(resolve, 1000));
269:       }
270:     }
271: 
272:     // Combine results
273:     return results.reduce(
274:       (acc, curr) => ({
275:         processed: acc.processed + curr.processed,
276:         updated: acc.updated + curr.updated,
277:         errors: [...acc.errors, ...curr.errors],
278:       }),
279:       { processed: 0, updated: 0, errors: [] }
280:     );
281:   }
282: 
283:   async syncPrices(options: SyncOptions = {}): Promise<SyncResult> {
284:     const result: SyncResult = {
285:       success: true,
286:       itemsProcessed: 0,
287:       itemsUpdated: 0,
288:       errors: [],
289:       timing: {
290:         startTime: new Date(),
291:       },
292:     };
293: 
294:     try {
295:       logger.info("Starting price sync", { options });
296: 
297:       // Get groups to process
298:       const groups = options.groupId ?
299:         [{ groupId: options.groupId }] :
300:         await tcgcsvApi.getGroups();
301: 
302:       logger.info(`Found ${groups.length} groups to process`);
303: 
304:       // Process each group sequentially to prevent overload
305:       for (const group of groups) {
306:         result.timing.groupStartTime = new Date();
307:         try {
308:           // Get prices for current group
309:           const prices = await tcgcsvApi.getGroupPrices(group.groupId);
310:           logger.info(`Processing ${prices.length} prices for group ${group.groupId}`);
311: 
312:           // Process prices in optimized batches
313:           const batchResults = await this.processPriceBatches(
314:             prices,
315:             group.groupId,
316:             options
317:           );
318: 
319:           // Update results
320:           result.itemsProcessed += batchResults.processed;
321:           result.itemsUpdated += batchResults.updated;
322:           result.errors.push(...batchResults.errors);
323: 
324:           // Add delay between groups
325:           if (groups.length > 1) {
326:             await new Promise((resolve) => setTimeout(resolve, 2000));
327:           }
328:         } catch (error) {
329:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
330:           result.errors.push(
331:             `Error processing prices for group ${group.groupId}: ${errorMessage}`
332:           );
333:           logger.error(`Error processing prices for group ${group.groupId}`, {
334:             error: errorMessage,
335:           });
336:         }
337:       }
338:     } catch (error) {
339:       result.success = false;
340:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
341:       result.errors.push(`Price sync failed: ${errorMessage}`);
342:       logger.error("Price sync failed", { error: errorMessage });
343:     }
344: 
345:     // Calculate final timing
346:     result.timing.endTime = new Date();
347:     result.timing.duration =
348:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
349: 
350:     // Log final results
351:     logger.info(`Price sync completed in ${result.timing.duration}s`, {
352:       processed: result.itemsProcessed,
353:       updated: result.itemsUpdated,
354:       errors: result.errors.length,
355:       timing: result.timing,
356:     });
357: 
358:     return result;
359:   }
360: }
361: 
362: export const priceSync = new PriceSyncService();
</file>

<file path="src/services/storageService.ts">
  1: // src/services/storageService.ts
  2: import { S3Client, PutObjectCommand, HeadObjectCommand } from "@aws-sdk/client-s3";
  3: import axios from "axios";
  4: import { R2_CONFIG } from "../config/r2";
  5: import { logger } from "../utils/logger";
  6: 
  7: interface ImageResult {
  8:   fullResUrl: string;
  9:   highResUrl: string;
 10:   lowResUrl: string;
 11:   metadata: {
 12:     contentType: string;
 13:     productId: string;
 14:     groupId: string;
 15:     lastUpdated: string;
 16:     isPlaceholder?: boolean;
 17:     originalUrl?: string;
 18:     existingImage?: boolean;
 19:     errorMessage?: string;
 20:   };
 21: }
 22: 
 23: export class StorageService {
 24:   private client: S3Client;
 25:   private readonly bucket: string;
 26:   private readonly customDomain: string;
 27:   private readonly storagePath: string;
 28:   private readonly maxRetries = 3;
 29:   private readonly timeoutMs = 30000; // 30 seconds
 30:   private readonly PLACEHOLDER_URL = "https://fftcgcompanion.com/card-images/image-coming-soon.jpeg";
 31:   private readonly validImagePatterns = [
 32:     "_in_1000x1000.", // Highest priority
 33:     "_400w.", // Medium priority
 34:     "_200w.", // Lowest priority
 35:   ];
 36: 
 37:   constructor() {
 38:     this.client = new S3Client({
 39:       region: "auto",
 40:       endpoint: `https://${R2_CONFIG.ACCOUNT_ID}.r2.cloudflarestorage.com`,
 41:       credentials: {
 42:         accessKeyId: R2_CONFIG.ACCESS_KEY_ID,
 43:         secretAccessKey: R2_CONFIG.SECRET_ACCESS_KEY,
 44:       },
 45:       forcePathStyle: true,
 46:     });
 47: 
 48:     this.bucket = R2_CONFIG.BUCKET_NAME;
 49:     this.customDomain = R2_CONFIG.CUSTOM_DOMAIN;
 50:     this.storagePath = R2_CONFIG.STORAGE_PATH;
 51:   }
 52: 
 53:   private isValidImageUrl(url: string | undefined): boolean {
 54:     if (!url) return false;
 55: 
 56:     // Check if it's TCGPlayer's missing image SVG
 57:     if (url.includes("image-missing.svg")) {
 58:       logger.info(`TCGPlayer missing image URL detected: ${url}, using our placeholder`);
 59:       return false;
 60:     }
 61: 
 62:     // If URL contains any of our valid patterns, it's a valid TCGPlayer image URL
 63:     const isValidPattern = this.validImagePatterns.some((pattern) => url.includes(pattern));
 64: 
 65:     // If URL doesn't match our patterns, consider it invalid
 66:     if (!isValidPattern) {
 67:       logger.info(`Invalid image URL pattern: ${url}, using placeholder`);
 68:       return false;
 69:     }
 70: 
 71:     return true;
 72:   }
 73: 
 74:   private async checkImageExists(path: string): Promise<boolean> {
 75:     try {
 76:       await this.client.send(
 77:         new HeadObjectCommand({
 78:           Bucket: this.bucket,
 79:           Key: path,
 80:         })
 81:       );
 82:       return true;
 83:     } catch (error) {
 84:       // Check for specific S3 errors
 85:       if (error instanceof Error) {
 86:         // NoSuchKey or 404 means the image doesn't exist
 87:         if (error.name === "NotFound" || error.name === "NoSuchKey") {
 88:           return false;
 89:         }
 90: 
 91:         // Log other errors but don't fail the whole process
 92:         logger.info(`Image check error for ${path}: ${error.message}`);
 93:       }
 94:       return false;
 95:     }
 96:   }
 97: 
 98:   private async validateImage(buffer: Buffer): Promise<boolean> {
 99:     if (buffer.length < 4) return false;
100: 
101:     const header = buffer.slice(0, 4);
102:     // JPEG magic number: FF D8 FF
103:     const isJPEG = header[0] === 0xff && header[1] === 0xd8 && header[2] === 0xff;
104:     // PNG magic number: 89 50 4E 47
105:     const isPNG = header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4e && header[3] === 0x47;
106: 
107:     return isJPEG || isPNG;
108:   }
109: 
110:   private async downloadImage(url: string, retries = this.maxRetries): Promise<Buffer> {
111:     let lastError: Error | null = null;
112: 
113:     for (let attempt = 0; attempt <= retries; attempt++) {
114:       try {
115:         const response = await axios.get(url, {
116:           responseType: "arraybuffer",
117:           timeout: this.timeoutMs,
118:           headers: {
119:             "User-Agent": "FFTCG-Sync-Service/1.0",
120:             Accept: "image/jpeg,image/png,image/*",
121:           },
122:           maxContentLength: 10 * 1024 * 1024, // 10MB max
123:           validateStatus: (status) => status === 200, // Only accept 200 status
124:         });
125: 
126:         const buffer = Buffer.from(response.data);
127: 
128:         if (await this.validateImage(buffer)) {
129:           return buffer;
130:         } else {
131:           throw new Error("Invalid image format");
132:         }
133:       } catch (unknownError) {
134:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
135:         const axiosError = unknownError as { response?: { status?: number } };
136: 
137:         // If we get a 403, this means the image doesn't exist or access is denied
138:         // Don't retry and don't log as error since this is an expected case
139:         if (axiosError?.response?.status === 403) {
140:           logger.info(`Image not available (403) for URL: ${url}`);
141:           throw new Error("IMAGE_NOT_AVAILABLE");
142:         }
143: 
144:         lastError = error;
145: 
146:         if (attempt === retries) {
147:           logger.error(`Failed to download image after ${retries + 1} attempts`, {
148:             url,
149:             error: error.message,
150:             stack: error.stack,
151:             status: axiosError?.response?.status,
152:           });
153:           break;
154:         }
155: 
156:         // Only log retries for non-403 errors
157:         logger.info(`Retrying image download (attempt ${attempt + 1}/${retries})`, {
158:           url,
159:           status: axiosError?.response?.status,
160:         });
161: 
162:         await new Promise((resolve) => setTimeout(resolve, 2000 * Math.pow(2, attempt)));
163:       }
164:     }
165: 
166:     throw lastError || new Error("Download failed after retries");
167:   }
168: 
169:   private async uploadToR2WithRetry(
170:     buffer: Buffer,
171:     path: string,
172:     metadata: Record<string, string>,
173:     retries = this.maxRetries
174:   ): Promise<string> {
175:     let lastError: Error | null = null;
176: 
177:     const stringMetadata = Object.entries(metadata).reduce(
178:       (acc, [key, value]) => ({
179:         ...acc,
180:         [key]: String(value),
181:       }),
182:       {}
183:     );
184: 
185:     for (let attempt = 0; attempt <= retries; attempt++) {
186:       try {
187:         await this.client.send(
188:           new PutObjectCommand({
189:             Bucket: this.bucket,
190:             Key: path,
191:             Body: buffer,
192:             ContentType: "image/jpeg",
193:             Metadata: stringMetadata,
194:             ContentLength: buffer.length,
195:             CacheControl: "public, max-age=31536000", // Cache for 1 year
196:             ACL: "public-read",
197:           })
198:         );
199:         return `${this.customDomain}/${path}`;
200:       } catch (unknownError) {
201:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
202:         lastError = error;
203: 
204:         logger.error(`Upload attempt ${attempt + 1} failed`, {
205:           path,
206:           error: error.message,
207:           stack: error.stack,
208:         });
209: 
210:         if (attempt === retries) break;
211:         await new Promise((resolve) => setTimeout(resolve, 1000 * (attempt + 1)));
212:       }
213:     }
214: 
215:     throw lastError || new Error("Upload failed after retries");
216:   }
217: 
218:   private getImagePath(groupId: string, cardNumber: string, resolution: "1000x1000" | "400w" | "200w"): string {
219:     const suffix = resolution === "1000x1000" ? "_in_1000x1000" : `_${resolution}`;
220:     return `${this.storagePath}/${groupId}/${cardNumber}${suffix}.jpg`;
221:   }
222: 
223:   private getPlaceholderResult(
224:     baseMetadata: {
225:       contentType: string;
226:       productId: string;
227:       groupId: string;
228:       lastUpdated: string;
229:     },
230:     originalUrl?: string
231:   ): ImageResult {
232:     return {
233:       fullResUrl: this.PLACEHOLDER_URL,
234:       highResUrl: this.PLACEHOLDER_URL,
235:       lowResUrl: this.PLACEHOLDER_URL,
236:       metadata: {
237:         ...baseMetadata,
238:         isPlaceholder: true,
239:         originalUrl,
240:         errorMessage: originalUrl ? "Invalid image URL" : "Image URL missing",
241:       },
242:     };
243:   }
244: 
245:   public async processAndStoreImage(
246:     imageUrl: string | undefined,
247:     productId: number,
248:     groupId: string,
249:     cardNumber: string
250:   ): Promise<ImageResult> {
251:     const baseMetadata = {
252:       productId: productId.toString(),
253:       groupId,
254:       lastUpdated: new Date().toISOString(),
255:       contentType: "image/jpeg",
256:     };
257: 
258:     try {
259:       if (!this.isValidImageUrl(imageUrl)) {
260:         return this.getPlaceholderResult(baseMetadata, imageUrl);
261:       }
262: 
263:       // Check if images already exist in R2
264:       const fullResPath = this.getImagePath(groupId, cardNumber, "1000x1000");
265:       const highResPath = this.getImagePath(groupId, cardNumber, "400w");
266:       const lowResPath = this.getImagePath(groupId, cardNumber, "200w");
267: 
268:       const [fullResExists, highResExists, lowResExists] = await Promise.all([
269:         this.checkImageExists(fullResPath).catch(() => false),
270:         this.checkImageExists(highResPath).catch(() => false),
271:         this.checkImageExists(lowResPath).catch(() => false),
272:       ]);
273: 
274:       // If all images exist, return their URLs
275:       if (fullResExists && highResExists && lowResExists) {
276:         const existingFullResUrl = `${this.customDomain}/${fullResPath}`;
277:         const existingHighResUrl = `${this.customDomain}/${highResPath}`;
278:         const existingLowResUrl = `${this.customDomain}/${lowResPath}`;
279: 
280:         logger.info(`Using existing images for product ${productId}:`, {
281:           fullResUrl: existingFullResUrl,
282:           highResUrl: existingHighResUrl,
283:           lowResUrl: existingLowResUrl,
284:         });
285: 
286:         return {
287:           fullResUrl: existingFullResUrl,
288:           highResUrl: existingHighResUrl,
289:           lowResUrl: existingLowResUrl,
290:           metadata: {
291:             ...baseMetadata,
292:             originalUrl: imageUrl,
293:             existingImage: true,
294:           },
295:         };
296:       }
297: 
298:       try {
299:         const baseUrl = imageUrl || "";
300:         // Create URLs for different resolutions
301:         const fullResTcgUrl = baseUrl.replace(/_[^.]+\./, "_in_1000x1000.");
302:         const highResTcgUrl = baseUrl.replace(/_[^.]+\./, "_400w.");
303:         const lowResTcgUrl = baseUrl.replace(/_[^.]+\./, "_200w.");
304: 
305:         logger.info(`Attempting to download images for product ${productId}:`, {
306:           fullRes: fullResTcgUrl,
307:           highRes: highResTcgUrl,
308:           lowRes: lowResTcgUrl,
309:         });
310: 
311:         // Try to download each resolution
312:         const [fullResBuffer, highResBuffer, lowResBuffer] = await Promise.all([
313:           this.downloadImage(fullResTcgUrl).catch((error) => {
314:             logger.info(`Failed to download full resolution image: ${error.message}`);
315:             return null;
316:           }),
317:           this.downloadImage(highResTcgUrl).catch((error) => {
318:             logger.info(`Failed to download high resolution image: ${error.message}`);
319:             return null;
320:           }),
321:           this.downloadImage(lowResTcgUrl).catch((error) => {
322:             logger.info(`Failed to download low resolution image: ${error.message}`);
323:             return null;
324:           }),
325:         ]);
326: 
327:         // Log which resolutions were successfully downloaded
328:         logger.info(`Download results for product ${productId}:`, {
329:           fullResDownloaded: !!fullResBuffer,
330:           highResDownloaded: !!highResBuffer,
331:           lowResDownloaded: !!lowResBuffer,
332:         });
333: 
334:         // Prepare arrays for successful uploads
335:         const uploadPromises: Promise<string>[] = [];
336:         const uploadPaths: string[] = [];
337: 
338:         // Add available images to upload queue
339:         if (fullResBuffer) {
340:           uploadPromises.push(this.uploadToR2WithRetry(fullResBuffer, fullResPath, baseMetadata));
341:           uploadPaths.push(fullResPath);
342:         }
343:         if (highResBuffer) {
344:           uploadPromises.push(this.uploadToR2WithRetry(highResBuffer, highResPath, baseMetadata));
345:           uploadPaths.push(highResPath);
346:         }
347:         if (lowResBuffer) {
348:           uploadPromises.push(this.uploadToR2WithRetry(lowResBuffer, lowResPath, baseMetadata));
349:           uploadPaths.push(lowResPath);
350:         }
351: 
352:         const uploadedUrls = await Promise.all(uploadPromises);
353: 
354:         // Create a map of paths to URLs
355:         const urlMap = uploadPaths.reduce((map, path, index) => {
356:           map[path] = uploadedUrls[index];
357:           return map;
358:         }, {} as { [key: string]: string });
359: 
360:         // Determine which URLs to use, falling back to the highest available resolution
361:         const result: ImageResult = {
362:           fullResUrl: urlMap[fullResPath] || urlMap[highResPath] || urlMap[lowResPath] || this.PLACEHOLDER_URL,
363:           highResUrl: urlMap[highResPath] || urlMap[fullResPath] || urlMap[lowResPath] || this.PLACEHOLDER_URL,
364:           lowResUrl: urlMap[lowResPath] || urlMap[highResPath] || urlMap[fullResPath] || this.PLACEHOLDER_URL,
365:           metadata: {
366:             ...baseMetadata,
367:             originalUrl: imageUrl,
368:           },
369:         };
370: 
371:         // Log the final URLs being stored
372:         logger.info(`Final image URLs for product ${productId}:`, {
373:           fullResUrl: result.fullResUrl,
374:           highResUrl: result.highResUrl,
375:           lowResUrl: result.lowResUrl,
376:           isPlaceholder: result.fullResUrl === this.PLACEHOLDER_URL,
377:           originalUrl: imageUrl,
378:           fallbacksUsed: {
379:             fullRes: result.fullResUrl !== urlMap[fullResPath],
380:             highRes: result.highResUrl !== urlMap[highResPath],
381:             lowRes: result.lowResUrl !== urlMap[lowResPath],
382:           },
383:         });
384: 
385:         return result;
386:       } catch (unknownError) {
387:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
388: 
389:         if (error.message !== "IMAGE_NOT_AVAILABLE") {
390:           logger.error(`Failed to process images for ${productId}`, {
391:             error: error.message,
392:             stack: error.stack,
393:           });
394:         }
395: 
396:         return this.getPlaceholderResult(baseMetadata, imageUrl);
397:       }
398:     } catch (error) {
399:       logger.error(`Failed to process images for ${productId}`, {
400:         error: error instanceof Error ? error.message : "Unknown error",
401:         imageUrl,
402:         groupId,
403:         cardNumber,
404:       });
405:       return this.getPlaceholderResult(baseMetadata, imageUrl);
406:     }
407:   }
408: }
409: 
410: export const storageService = new StorageService();
</file>

<file path="src/types/index.ts">
  1: import { FieldValue } from "firebase-admin/firestore";
  2: 
  3: export interface CardProduct {
  4:   productId: number;
  5:   name: string;
  6:   cleanName: string;
  7:   imageUrl?: string;
  8:   categoryId: number;
  9:   groupId: number;
 10:   url: string;
 11:   modifiedOn: string;
 12:   imageCount: number;
 13:   extendedData: Array<{
 14:     name: string;
 15:     displayName: string;
 16:     value: string;
 17:   }>;
 18: }
 19: 
 20: export interface CardPrice {
 21:   productId: number;
 22:   normal?: {
 23:     directLowPrice: number | null;
 24:     highPrice: number;
 25:     lowPrice: number;
 26:     marketPrice: number;
 27:     midPrice: number;
 28:     subTypeName: "Normal";
 29:   };
 30:   foil?: {
 31:     directLowPrice: number | null;
 32:     highPrice: number;
 33:     lowPrice: number;
 34:     marketPrice: number;
 35:     midPrice: number;
 36:     subTypeName: "Foil";
 37:   };
 38:   lastUpdated: Date;
 39: }
 40: 
 41: export interface HistoricalPrice {
 42:   productId: number;
 43:   date: Date;
 44:   normal?: {
 45:     directLow: number | null;
 46:     high: number;
 47:     low: number;
 48:     market: number;
 49:     mid: number;
 50:   };
 51:   foil?: {
 52:     directLow: number | null;
 53:     high: number;
 54:     low: number;
 55:     market: number;
 56:     mid: number;
 57:   };
 58:   groupId: string;
 59: }
 60: 
 61: export interface SyncTiming {
 62:   startTime: Date;
 63:   endTime?: Date;
 64:   duration?: number;
 65:   groupStartTime?: Date;
 66:   imageStartTime?: Date;
 67:   lastUpdateTime?: Date;
 68: }
 69: 
 70: export interface SyncResult {
 71:   success: boolean;
 72:   itemsProcessed: number;
 73:   itemsUpdated: number;
 74:   errors: string[];
 75:   timing: SyncTiming;
 76: }
 77: 
 78: export interface CardHashData {
 79:   name: string;
 80:   cleanName: string;
 81:   modifiedOn: string;
 82:   extendedData: Array<{
 83:     name: string;
 84:     displayName: string;
 85:     value: string;
 86:   }>;
 87: }
 88: 
 89: export interface SyncOptions {
 90:   groupId?: string;
 91:   forceUpdate?: boolean;
 92:   skipImages?: boolean;
 93:   imagesOnly?: boolean;
 94:   silent?: boolean;
 95:   dryRun?: boolean;
 96: }
 97: 
 98: export interface CardChanges {
 99:   productId: number;
100:   name: string;
101:   cleanName: string;
102:   fullResUrl: string;
103:   highResUrl: string;
104:   lowResUrl: string;
105:   lastUpdated: FieldValue;
106:   groupId: number;
107:   isNonCard: boolean;
108:   cardNumbers: string[];
109:   primaryCardNumber: string;
110: }
111: 
112: export interface PriceChanges {
113:   productId: number;
114:   lastUpdated: FieldValue;
115:   groupId: number;
116:   normal?: {
117:     directLowPrice: number | null;
118:     highPrice: number;
119:     lowPrice: number;
120:     marketPrice: number;
121:     midPrice: number;
122:     subTypeName: "Normal";
123:   };
124:   foil?: {
125:     directLowPrice: number | null;
126:     highPrice: number;
127:     lowPrice: number;
128:     marketPrice: number;
129:     midPrice: number;
130:     subTypeName: "Foil";
131:   };
132: }
</file>

<file path="src/utils/api.ts">
  1: // src/utils/api.ts
  2: import axios, { AxiosError } from "axios";
  3: import { CardProduct, CardPrice } from "../types";
  4: import { logger } from "./logger";
  5: import { Cache } from "./cache";
  6: import { RateLimiter } from "./rateLimiter";
  7: import { RetryWithBackoff } from "./retry";
  8: 
  9: export class TcgcsvApi {
 10:   private readonly baseUrl = "https://tcgcsv.com/tcgplayer";
 11:   private readonly categoryId = "24"; // Final Fantasy TCG
 12:   private readonly requestQueue = new Map<string, Promise<unknown>>();
 13:   private readonly resultCache = new Cache<unknown>(5); // 5-minute cache
 14:   private readonly rateLimiter = new RateLimiter();
 15:   private readonly retry = new RetryWithBackoff();
 16: 
 17:   private async _makeRequest<T>(endpoint: string): Promise<T> {
 18:     const url = `${this.baseUrl}/${endpoint}`;
 19:     logger.info(`Making request to: ${url}`);
 20: 
 21:     return this.rateLimiter.add(async () => {
 22:       try {
 23:         const response = await this.retry.execute(() =>
 24:           axios.get<T>(url, {
 25:             timeout: 30000,
 26:             headers: {
 27:               "Accept": "application/json",
 28:               "User-Agent": "FFTCG-Sync-Service/1.0",
 29:             },
 30:           })
 31:         );
 32:         return response.data;
 33:       } catch (error) {
 34:         if (error instanceof AxiosError && error.response?.status === 403) {
 35:           throw new Error(`Access denied to TCGCSV API at path: ${endpoint}`);
 36:         }
 37:         throw error;
 38:       }
 39:     });
 40:   }
 41: 
 42:   private async makeRequest<T>(endpoint: string): Promise<T> {
 43:     const cacheKey = `api_${endpoint}`;
 44:     const cached = this.resultCache.get(cacheKey);
 45:     if (cached) {
 46:       logger.info(`Cache hit for ${endpoint}`);
 47:       return cached as T;
 48:     }
 49: 
 50:     const existing = this.requestQueue.get(endpoint);
 51:     if (existing) {
 52:       logger.info(`Using existing request for ${endpoint}`);
 53:       return existing as Promise<T>;
 54:     }
 55: 
 56:     const promise = this._makeRequest<T>(endpoint);
 57:     this.requestQueue.set(endpoint, promise);
 58: 
 59:     try {
 60:       const result = await promise;
 61:       this.resultCache.set(cacheKey, result);
 62:       return result;
 63:     } finally {
 64:       this.requestQueue.delete(endpoint);
 65:     }
 66:   }
 67: 
 68:   async getGroups(): Promise<Array<{ groupId: string }>> {
 69:     const response = await this.makeRequest<{ results: Array<{ groupId: string }> }>(`${this.categoryId}/groups`);
 70:     logger.info(`Retrieved ${response.results.length} groups`);
 71:     return response.results;
 72:   }
 73: 
 74:   async getGroupProducts(groupId: string): Promise<CardProduct[]> {
 75:     const response = await this.makeRequest<{ results: CardProduct[] }>(`${this.categoryId}/${groupId}/products`);
 76:     logger.info(`Retrieved ${response.results.length} products for group ${groupId}`);
 77:     return response.results;
 78:   }
 79: 
 80:   async getGroupPrices(groupId: string): Promise<CardPrice[]> {
 81:     interface RawPriceData {
 82:       productId: number;
 83:       lowPrice: number | null;
 84:       midPrice: number | null;
 85:       highPrice: number | null;
 86:       marketPrice: number | null;
 87:       directLowPrice: number | null;
 88:       subTypeName: string;
 89:     }
 90: 
 91:     interface PriceResponse {
 92:       success: boolean;
 93:       errors: string[];
 94:       results: RawPriceData[];
 95:     }
 96: 
 97:     const response = await this.makeRequest<PriceResponse>(`${this.categoryId}/${groupId}/prices`);
 98:     logger.info(`Retrieved ${response.results.length} prices for group ${groupId}`);
 99: 
100:     const priceMap = new Map<number, CardPrice>();
101: 
102:     response.results.forEach((price) => {
103:       const existing = priceMap.get(price.productId) || {
104:         productId: price.productId,
105:         lastUpdated: new Date(),
106:       };
107: 
108:       if (price.subTypeName === "Normal") {
109:         existing.normal = {
110:           directLowPrice: price.directLowPrice,
111:           highPrice: price.highPrice || 0,
112:           lowPrice: price.lowPrice || 0,
113:           marketPrice: price.marketPrice || 0,
114:           midPrice: price.midPrice || 0,
115:           subTypeName: "Normal",
116:         };
117:       } else if (price.subTypeName === "Foil") {
118:         existing.foil = {
119:           directLowPrice: price.directLowPrice,
120:           highPrice: price.highPrice || 0,
121:           lowPrice: price.lowPrice || 0,
122:           marketPrice: price.marketPrice || 0,
123:           midPrice: price.midPrice || 0,
124:           subTypeName: "Foil",
125:         };
126:       }
127: 
128:       priceMap.set(price.productId, existing);
129:     });
130: 
131:     return Array.from(priceMap.values());
132:   }
133: }
134: 
135: export const tcgcsvApi = new TcgcsvApi();
</file>

<file path="src/utils/cache.ts">
  1: // src/utils/cache.ts
  2: import { logger } from "./logger";
  3: 
  4: export class Cache<T> {
  5:   private cache = new Map<
  6:     string,
  7:     {
  8:       data: T;
  9:       timestamp: number;
 10:       lastAccessed: number;
 11:     }
 12:   >();
 13:   private readonly ttl: number;
 14:   private readonly maxSize: number;
 15:   private readonly statistics = {
 16:     hits: 0,
 17:     misses: 0,
 18:     evictions: 0,
 19:   };
 20: 
 21:   constructor(ttlMinutes = 15, maxSize = 5000) {
 22:     this.ttl = ttlMinutes * 60 * 1000;
 23:     this.maxSize = maxSize;
 24:     this.startPeriodicCleanup();
 25:   }
 26: 
 27:   private startPeriodicCleanup(): void {
 28:     setInterval(() => {
 29:       this.evictExpired();
 30:       this.logStatistics();
 31:     }, Math.min(this.ttl / 2, 5 * 60 * 1000)); // Run every 5 minutes or half TTL, whichever is shorter
 32:   }
 33: 
 34:   private evictExpired(): void {
 35:     const now = Date.now();
 36:     let evicted = 0;
 37: 
 38:     for (const [key, value] of this.cache.entries()) {
 39:       if (now - value.timestamp > this.ttl) {
 40:         this.cache.delete(key);
 41:         evicted++;
 42:         this.statistics.evictions++;
 43:       }
 44:     }
 45: 
 46:     if (evicted > 0) {
 47:       logger.info(`Cache cleanup: evicted ${evicted} expired items`);
 48:     }
 49:   }
 50: 
 51:   private evictLRU(): void {
 52:     const entries = Array.from(this.cache.entries());
 53:     const toEvict = entries
 54:       .sort(([, a], [, b]) => a.lastAccessed - b.lastAccessed)
 55:       .slice(0, Math.floor(this.maxSize * 0.2)); // Evict 20% of oldest entries
 56: 
 57:     toEvict.forEach(([key]) => {
 58:       this.cache.delete(key);
 59:       this.statistics.evictions++;
 60:     });
 61: 
 62:     logger.info(`Cache LRU eviction: removed ${toEvict.length} items`);
 63:   }
 64: 
 65:   set(key: string, value: T): void {
 66:     if (this.cache.size >= this.maxSize) {
 67:       this.evictLRU();
 68:     }
 69: 
 70:     this.cache.set(key, {
 71:       data: value,
 72:       timestamp: Date.now(),
 73:       lastAccessed: Date.now(),
 74:     });
 75:   }
 76: 
 77:   setBulk(entries: Array<[string, T]>): void {
 78:     entries.forEach(([key, value]) => this.set(key, value));
 79:   }
 80: 
 81:   get(key: string): T | null {
 82:     const cached = this.cache.get(key);
 83:     if (!cached) {
 84:       this.statistics.misses++;
 85:       return null;
 86:     }
 87: 
 88:     if (Date.now() - cached.timestamp > this.ttl) {
 89:       this.cache.delete(key);
 90:       this.statistics.evictions++;
 91:       this.statistics.misses++;
 92:       return null;
 93:     }
 94: 
 95:     cached.lastAccessed = Date.now();
 96:     this.statistics.hits++;
 97:     return cached.data;
 98:   }
 99: 
100:   getBulk(keys: string[]): Map<string, T> {
101:     const results = new Map<string, T>();
102:     keys.forEach((key) => {
103:       const value = this.get(key);
104:       if (value !== null) {
105:         results.set(key, value);
106:       }
107:     });
108:     return results;
109:   }
110: 
111:   clear(): void {
112:     this.cache.clear();
113:     this.resetStatistics();
114:   }
115: 
116:   has(key: string): boolean {
117:     return this.get(key) !== null;
118:   }
119: 
120:   private resetStatistics(): void {
121:     this.statistics.hits = 0;
122:     this.statistics.misses = 0;
123:     this.statistics.evictions = 0;
124:   }
125: 
126:   private logStatistics(): void {
127:     const total = this.statistics.hits + this.statistics.misses;
128:     const hitRate = total > 0 ? (this.statistics.hits / total) * 100 : 0;
129: 
130:     logger.info("Cache statistics", {
131:       size: this.cache.size,
132:       hits: this.statistics.hits,
133:       misses: this.statistics.misses,
134:       evictions: this.statistics.evictions,
135:       hitRate: `${hitRate.toFixed(2)}%`,
136:     });
137:   }
138: 
139:   getStatistics() {
140:     return { ...this.statistics };
141:   }
142: }
</file>

<file path="src/utils/logger.ts">
 1: // src/utils/logger.ts
 2: import { db } from "../config/firebase";
 3: import { environment } from "../config/environment";
 4: import { SyncResult } from "../types";
 5: 
 6: export type LogData = Record<string, unknown>;
 7: 
 8: export interface SyncStats {
 9:   startTime: Date;
10:   endTime?: Date;
11:   totalItems: number;
12:   successCount: number;
13:   errorCount: number;
14:   duration?: number;
15: }
16: 
17: export class Logger {
18:   private readonly COLLECTION = "logs";
19: 
20:   async info(message: string, data?: LogData | SyncResult): Promise<void> {
21:     await this.log("INFO", message, data);
22:   }
23: 
24:   async error(message: string, data?: LogData | { error: unknown }): Promise<void> {
25:     await this.log("ERROR", message, data);
26:   }
27: 
28:   async logSyncStats(stats: SyncStats): Promise<void> {
29:     const duration = stats.endTime ? (stats.endTime.getTime() - stats.startTime.getTime()) / 1000 : undefined;
30: 
31:     const successRate = ((stats.successCount / stats.totalItems) * 100).toFixed(1);
32: 
33:     console.log({
34:       duration: duration ? `${duration}s` : "unknown",
35:       successRate: `${successRate}%`,
36:       totalItems: stats.totalItems,
37:       successful: stats.successCount,
38:       errors: stats.errorCount,
39:     });
40: 
41:     if (!environment.isLocal) {
42:       await db.collection(this.COLLECTION).add({
43:         type: "SYNC_STATS",
44:         timestamp: new Date(),
45:         stats: {
46:           ...stats,
47:           duration,
48:           successRate: parseFloat(successRate),
49:         },
50:       });
51:     }
52:   }
53: 
54:   async warn(message: string, data?: LogData | { error: unknown }): Promise<void> {
55:     await this.log("WARN", message, data);
56:   }
57: 
58:   async log(
59:     level: "INFO" | "ERROR" | "WARN",
60:     message: string,
61:     metadata?: LogData | SyncResult | { error: unknown }
62:   ): Promise<void> {
63:     const entry = {
64:       timestamp: new Date(),
65:       level,
66:       message,
67:       metadata: metadata || null,
68:       environment: environment.nodeEnv,
69:     };
70: 
71:     // Always log to console with appropriate level
72:     const logFn = level === "ERROR" ? console.error : level === "WARN" ? console.warn : console.log;
73:     logFn(`[${level}] ${message}`, metadata || "");
74: 
75:     // Only log to Firestore if not in local development
76:     if (!environment.isLocal) {
77:       try {
78:         await db.collection(this.COLLECTION).add(entry);
79:       } catch (error) {
80:         console.error("Failed to write log to Firestore:", error);
81:         // Don't throw the error to prevent disrupting the application
82:       }
83:     }
84:   }
85: }
86: 
87: export const logger = new Logger();
</file>

<file path="src/utils/rateLimiter.ts">
  1: // src/utils/rateLimiter.ts
  2: import { logger } from "./logger";
  3: 
  4: export class RateLimiter {
  5:   private queue: Array<() => Promise<unknown>> = [];
  6:   private processing = false;
  7:   private readonly maxRate: number;
  8:   private readonly interval: number;
  9:   private readonly maxConcurrent: number;
 10:   private currentConcurrent = 0;
 11: 
 12:   private readonly tokenBucket = {
 13:     tokens: 0,
 14:     lastRefill: Date.now(),
 15:   };
 16: 
 17:   private readonly statistics = {
 18:     totalProcessed: 0,
 19:     totalQueued: 0,
 20:     maxQueueLength: 0,
 21:     totalWaitTime: 0,
 22:   };
 23: 
 24:   constructor(maxRate = 500, intervalMs = 1000, maxConcurrent = 5) {
 25:     this.maxRate = maxRate;
 26:     this.interval = intervalMs;
 27:     this.maxConcurrent = maxConcurrent;
 28:     this.tokenBucket.tokens = maxRate;
 29: 
 30:     // Start periodic statistics logging
 31:     setInterval(() => this.logStatistics(), 5 * 60 * 1000); // Every 5 minutes
 32:   }
 33: 
 34:   private refillTokens(): number {
 35:     const now = Date.now();
 36:     const timePassed = now - this.tokenBucket.lastRefill;
 37:     const refillAmount = Math.floor((timePassed / this.interval) * this.maxRate);
 38: 
 39:     this.tokenBucket.tokens = Math.min(this.maxRate, this.tokenBucket.tokens + refillAmount);
 40:     this.tokenBucket.lastRefill = now;
 41: 
 42:     return this.tokenBucket.tokens;
 43:   }
 44: 
 45:   private async acquireToken(): Promise<void> {
 46:     while (this.tokenBucket.tokens <= 0) {
 47:       const sleepTime = Math.ceil(this.interval / this.maxRate);
 48:       await new Promise((resolve) => setTimeout(resolve, sleepTime));
 49:       this.refillTokens();
 50:     }
 51:     this.tokenBucket.tokens--;
 52:   }
 53: 
 54:   async add<T>(operation: () => Promise<T>): Promise<T> {
 55:     const queueStartTime = Date.now();
 56:     this.statistics.totalQueued++;
 57:     this.statistics.maxQueueLength = Math.max(this.statistics.maxQueueLength, this.queue.length + 1);
 58: 
 59:     return new Promise<T>((resolve, reject) => {
 60:       const wrappedOperation = async () => {
 61:         try {
 62:           await this.acquireToken();
 63:           const result = await operation();
 64: 
 65:           this.statistics.totalProcessed++;
 66:           this.statistics.totalWaitTime += Date.now() - queueStartTime;
 67: 
 68:           resolve(result);
 69:           return result;
 70:         } catch (error) {
 71:           reject(error);
 72:           throw error;
 73:         }
 74:       };
 75: 
 76:       this.queue.push(wrappedOperation);
 77: 
 78:       if (!this.processing) {
 79:         void this.process();
 80:       }
 81:     });
 82:   }
 83: 
 84:   private async process(): Promise<void> {
 85:     this.processing = true;
 86:     const batchSize = Math.floor(this.maxRate / (this.interval / 1000));
 87: 
 88:     while (this.queue.length > 0) {
 89:       if (this.currentConcurrent >= this.maxConcurrent) {
 90:         await new Promise((resolve) => setTimeout(resolve, 100));
 91:         continue;
 92:       }
 93: 
 94:       const batch = this.queue.splice(0, Math.min(batchSize, this.queue.length));
 95:       this.currentConcurrent++;
 96: 
 97:       try {
 98:         await Promise.all(
 99:           batch.map((op) =>
100:             op().finally(() => {
101:               this.currentConcurrent--;
102:             })
103:           )
104:         );
105:       } catch (error) {
106:         logger.error("Error processing rate-limited batch", { error });
107:       }
108: 
109:       if (this.queue.length > 0) {
110:         await new Promise((resolve) => setTimeout(resolve, this.interval));
111:       }
112:     }
113: 
114:     this.processing = false;
115:   }
116: 
117:   private logStatistics(): void {
118:     const avgWaitTime =
119:       this.statistics.totalProcessed > 0 ? this.statistics.totalWaitTime / this.statistics.totalProcessed : 0;
120: 
121:     logger.info("Rate limiter statistics", {
122:       totalProcessed: this.statistics.totalProcessed,
123:       totalQueued: this.statistics.totalQueued,
124:       maxQueueLength: this.statistics.maxQueueLength,
125:       averageWaitTime: `${(avgWaitTime / 1000).toFixed(2)}s`,
126:       currentQueueLength: this.queue.length,
127:       currentConcurrent: this.currentConcurrent,
128:       availableTokens: this.tokenBucket.tokens,
129:     });
130:   }
131: 
132:   getStatistics() {
133:     return { ...this.statistics };
134:   }
135: }
</file>

<file path="src/utils/retention.ts">
 1: import { db } from "../config/firebase";
 2: import { logger } from "./logger";
 3: 
 4: export class RetentionService {
 5:   private readonly RETENTION_CONFIG = {
 6:     logs: 7,
 7:     cardHashes: 7,
 8:     priceHashes: 7,
 9:     syncMetadata: 7,
10:   };
11: 
12:   async cleanOldData(): Promise<void> {
13:     try {
14:       logger.info("Starting data retention cleanup");
15: 
16:       for (const [collection, days] of Object.entries(this.RETENTION_CONFIG)) {
17:         const cutoff = new Date();
18:         cutoff.setDate(cutoff.getDate() - days);
19: 
20:         const snapshot = await db.collection(collection).where("lastUpdated", "<", cutoff).get();
21: 
22:         if (!snapshot.empty) {
23:           const batch = db.batch();
24:           snapshot.docs.forEach((doc) => batch.delete(doc.ref));
25:           await batch.commit();
26: 
27:           logger.info(`Cleaned up ${snapshot.size} documents from ${collection}`);
28:         }
29:       }
30: 
31:       logger.info("Data retention cleanup completed");
32:     } catch (error) {
33:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
34:       logger.error("Data retention cleanup failed", { error: errorMessage });
35:       throw error;
36:     }
37:   }
38: }
39: 
40: export const retention = new RetentionService();
</file>

<file path="src/utils/retry.ts">
  1: // src/utils/retry.ts
  2: import { logger } from "./logger";
  3: 
  4: interface CircuitBreakerConfig {
  5:   failureThreshold: number;
  6:   resetTimeout: number;
  7: }
  8: 
  9: interface RetryConfig {
 10:   maxRetries: number;
 11:   initialDelay: number;
 12:   maxDelay: number;
 13:   backoffFactor: number;
 14: }
 15: 
 16: export class RetryWithBackoff {
 17:   private readonly config: RetryConfig;
 18:   private readonly circuitBreaker: CircuitBreakerConfig;
 19:   private readonly retryableStatusCodes = new Set([408, 429, 500, 502, 503, 504]);
 20: 
 21:   private circuitState = {
 22:     failures: 0,
 23:     lastFailure: 0,
 24:     isOpen: false,
 25:   };
 26: 
 27:   private statistics = {
 28:     totalAttempts: 0,
 29:     totalRetries: 0,
 30:     totalFailures: 0,
 31:     totalSuccesses: 0,
 32:     circuitBreaksCount: 0,
 33:   };
 34: 
 35:   constructor(retryConfig?: Partial<RetryConfig>, circuitBreakerConfig?: Partial<CircuitBreakerConfig>) {
 36:     this.config = {
 37:       maxRetries: retryConfig?.maxRetries ?? 3,
 38:       initialDelay: retryConfig?.initialDelay ?? 1000,
 39:       maxDelay: retryConfig?.maxDelay ?? 10000,
 40:       backoffFactor: retryConfig?.backoffFactor ?? 2,
 41:     };
 42: 
 43:     this.circuitBreaker = {
 44:       failureThreshold: circuitBreakerConfig?.failureThreshold ?? 5,
 45:       resetTimeout: circuitBreakerConfig?.resetTimeout ?? 60000,
 46:     };
 47: 
 48:     // Start periodic statistics logging
 49:     setInterval(() => this.logStatistics(), 5 * 60 * 1000); // Every 5 minutes
 50:   }
 51: 
 52:   private checkCircuitBreaker(): boolean {
 53:     if (!this.circuitState.isOpen) {
 54:       return true;
 55:     }
 56: 
 57:     const timeSinceLastFailure = Date.now() - this.circuitState.lastFailure;
 58:     if (timeSinceLastFailure >= this.circuitBreaker.resetTimeout) {
 59:       this.circuitState.isOpen = false;
 60:       this.circuitState.failures = 0;
 61:       return true;
 62:     }
 63: 
 64:     return false;
 65:   }
 66: 
 67:   private updateCircuitBreaker(failed: boolean): void {
 68:     if (failed) {
 69:       this.circuitState.failures++;
 70:       this.circuitState.lastFailure = Date.now();
 71: 
 72:       if (this.circuitState.failures >= this.circuitBreaker.failureThreshold) {
 73:         this.circuitState.isOpen = true;
 74:         this.statistics.circuitBreaksCount++;
 75:         logger.warn("Circuit breaker opened", {
 76:           failures: this.circuitState.failures,
 77:           resetTimeout: this.circuitBreaker.resetTimeout,
 78:         });
 79:       }
 80:     } else {
 81:       this.circuitState.failures = 0;
 82:     }
 83:   }
 84: 
 85:   private isRetryableError(error: Error): boolean {
 86:     // Check if it's an HTTP error with status code
 87:     const httpError = error as { response?: { status?: number } };
 88:     const statusCode = httpError.response?.status;
 89:     if (statusCode && this.retryableStatusCodes.has(statusCode)) {
 90:       return true;
 91:     }
 92: 
 93:     // Check for network-related errors
 94:     const errorMessage = error.message.toLowerCase();
 95:     return (
 96:       errorMessage.includes("timeout") ||
 97:       errorMessage.includes("network") ||
 98:       errorMessage.includes("connection") ||
 99:       errorMessage.includes("econnrefused") ||
100:       errorMessage.includes("econnreset")
101:     );
102:   }
103: 
104:   async execute<T>(operation: () => Promise<T>): Promise<T> {
105:     if (!this.checkCircuitBreaker()) {
106:       throw new Error("Circuit breaker is open");
107:     }
108: 
109:     let lastError: Error | null = null;
110:     let delay = this.config.initialDelay;
111: 
112:     for (let attempt = 0; attempt <= this.config.maxRetries; attempt++) {
113:       this.statistics.totalAttempts++;
114: 
115:       try {
116:         const result = await operation();
117:         this.updateCircuitBreaker(false);
118:         this.statistics.totalSuccesses++;
119:         return result;
120:       } catch (error) {
121:         lastError = error instanceof Error ? error : new Error(String(error));
122:         this.statistics.totalFailures++;
123: 
124:         if (attempt === this.config.maxRetries) {
125:           this.updateCircuitBreaker(true);
126:           break;
127:         }
128: 
129:         if (!this.isRetryableError(lastError)) {
130:           throw lastError;
131:         }
132: 
133:         this.statistics.totalRetries++;
134:         logger.info(`Retry attempt ${attempt + 1} of ${this.config.maxRetries}`, {
135:           error: lastError.message,
136:           delay,
137:         });
138: 
139:         await new Promise((resolve) => setTimeout(resolve, delay));
140:         delay = Math.min(delay * this.config.backoffFactor, this.config.maxDelay);
141:       }
142:     }
143: 
144:     throw lastError || new Error("Operation failed after retries");
145:   }
146: 
147:   private logStatistics(): void {
148:     const totalOperations = this.statistics.totalSuccesses + this.statistics.totalFailures;
149:     const successRate = totalOperations > 0 ? (this.statistics.totalSuccesses / totalOperations) * 100 : 0;
150: 
151:     logger.info("Retry statistics", {
152:       totalAttempts: this.statistics.totalAttempts,
153:       totalRetries: this.statistics.totalRetries,
154:       totalSuccesses: this.statistics.totalSuccesses,
155:       totalFailures: this.statistics.totalFailures,
156:       circuitBreaks: this.statistics.circuitBreaksCount,
157:       successRate: `${successRate.toFixed(2)}%`,
158:       circuitBreakerStatus: this.circuitState.isOpen ? "OPEN" : "CLOSED",
159:       currentFailures: this.circuitState.failures,
160:     });
161:   }
162: 
163:   getStatistics() {
164:     return { ...this.statistics };
165:   }
166: 
167:   resetStatistics(): void {
168:     this.statistics = {
169:       totalAttempts: 0,
170:       totalRetries: 0,
171:       totalFailures: 0,
172:       totalSuccesses: 0,
173:       circuitBreaksCount: 0,
174:     };
175:   }
176: }
</file>

<file path="src/utils/timeout.ts">
 1: // src/utils/timeout.ts
 2: export class TimeoutError extends Error {
 3:   constructor(message: string) {
 4:     super(message);
 5:     this.name = "TimeoutError";
 6:   }
 7: }
 8: 
 9: export function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
10:   return Promise.race([
11:     promise,
12:     new Promise<T>((_, reject) => {
13:       setTimeout(() => {
14:         reject(new TimeoutError(`Operation timed out after ${timeoutMs}ms`));
15:       }, timeoutMs);
16:     }),
17:   ]);
18: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "include": [
3:     ".eslintrc.js"
4:   ]
5: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "moduleResolution": "node",
 5:     "noImplicitReturns": true,
 6:     "noUnusedLocals": true,
 7:     "outDir": "lib",
 8:     "sourceMap": true,
 9:     "strict": true,
10:     "target": "es2017",
11:     "skipLibCheck": true, // Add this line
12:     "esModuleInterop": true, // Make sure this is present
13:     "resolveJsonModule": true, // Add this line
14:     "baseUrl": "./src", // Add this line
15:     "paths": {
16:       // Add this section
17:       "*": ["*"]
18:     }
19:   },
20:   "compileOnSave": true,
21:   "include": ["src"],
22:   "exclude": ["node_modules", "lib"]
23: }
</file>

</repository_files>
