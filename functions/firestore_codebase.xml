This file is a merged representation of the entire codebase, combining all repository files into a single document.
Generated by Repomix on: 2025-01-28T06:28:27.672Z

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Repository structure
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's
  configuration.
- Binary files are not included in this packed representation. Please refer to
  the Repository Structure section for a complete list of file paths, including
  binary files.

- Line numbers have been added to the beginning of each line.
</notes>

<additional_info>

For more information about Repomix, visit: https://github.com/yamadashy/repomix
</additional_info>

</file_summary>

<repository_structure>
.env.local
.eslintignore
.eslintrc.base.cjs
.eslintrc.fix.js
.eslintrc.js
.firebaserc
.gitignore
.npmrc
.npmrc.backup
.prettierrc
.repomixignore
firebase.json
firestore.indexes.json
firestore.rules
package.json
repomix.config.json
src/config/environment.ts
src/config/firebase.ts
src/config/r2Config.ts
src/index.ts
src/scripts/cleanup.ts
src/scripts/cleanupElements.ts
src/scripts/prodSync.ts
src/scripts/setenv.ts
src/scripts/syncAll.ts
src/scripts/syncCards.ts
src/scripts/syncGroups.ts
src/scripts/syncPrices.ts
src/scripts/testSync.ts
src/services/batchProcessor.ts
src/services/cardSync.ts
src/services/cardSync.ts.txt
src/services/groupSync.ts
src/services/groupSync.ts.txt
src/services/priceSync.ts
src/services/priceSync.ts.txt
src/services/storageService.ts
src/types/index.ts
src/utils/api.ts
src/utils/batch.ts
src/utils/cache.ts
src/utils/logger.ts
src/utils/rateLimiter.ts
src/utils/retention.ts
src/utils/retry.ts
src/utils/tasks.ts
src/utils/timeout.ts
tsconfig.dev.json
tsconfig.json
</repository_structure>

<repository_files>
This section contains the contents of the repository's files.

<file path=".env.local">
1: # Exported firebase functions:config:export command on 1/20/2025
2: # .env.local file contains environment variables for the Functions Emulator.
</file>

<file path=".eslintignore">
1: node_modules/
2: lib/
3: coverage/
4: *.d.ts
5: *.cjs
</file>

<file path=".eslintrc.base.cjs">
1: module.exports = {
2:     rules: {
3:       "valid-jsdoc": "off",
4:       "require-jsdoc": "off"
5:     }
6:   };
</file>

<file path=".eslintrc.fix.js">
 1: module.exports = {
 2:   extends: "./.eslintrc.js",
 3:   rules: {
 4:     "max-len": ["error", {"code": 120}],
 5:     "valid-jsdoc": 0,
 6:     "require-jsdoc": 0,
 7:     "@typescript-eslint/no-explicit-any": 0,
 8:     "@typescript-eslint/explicit-function-return-type": 0,
 9:     "@typescript-eslint/explicit-module-boundary-types": 0,
10:     "@typescript-eslint/no-unused-vars": ["error", {
11:       "argsIgnorePattern": "^_",
12:       "varsIgnorePattern": "^_",
13:     }],
14:     // Add these additional rules to be extra sure
15:     "jsdoc/require-jsdoc": 0,
16:     "jsdoc/valid-jsdoc": 0,
17:     "jsdoc/require-param-type": 0,
18:     "jsdoc/require-returns": 0,
19:   },
20: };
</file>

<file path=".eslintrc.js">
 1: module.exports = {
 2:   root: true,
 3:   env: {
 4:     es6: true,
 5:     node: true,
 6:   },
 7:   extends: [
 8:     "eslint:recommended",
 9:     "plugin:import/errors",
10:     "plugin:import/warnings",
11:     "plugin:import/typescript",
12:     "google",
13:     "plugin:@typescript-eslint/recommended",
14:   ],
15:   parser: "@typescript-eslint/parser",
16:   parserOptions: {
17:     project: ["tsconfig.json", "tsconfig.dev.json"],
18:     sourceType: "module",
19:   },
20:   ignorePatterns: [
21:     "/lib/**/*",
22:     "/generated/**/*",
23:     "*.js", // Add this line to ignore JS files
24:   ],
25:   plugins: ["@typescript-eslint", "import"],
26:   rules: {
27:     quotes: ["error", "double"],
28:     "import/no-unresolved": 0,
29:     indent: ["error", 2],
30:     "linebreak-style": 0, // Disable linebreak-style checks
31:     "object-curly-spacing": ["error", "always"],
32:     "max-len": ["error", { code: 120 }],
33:     "@typescript-eslint/no-explicit-any": "warn",
34:     "require-jsdoc": 0,
35:     "valid-jsdoc": 0,
36:     "@typescript-eslint/no-var-requires": 0,
37:     camelcase: 0,
38:   },
39: };
</file>

<file path=".firebaserc">
1: {
2:   "projects": {
3:     "default": "fftcg-sync-service"
4:   }
5: }
</file>

<file path=".gitignore">
 1: # Dependencies
 2: node_modules/
 3: 
 4: # Build output
 5: lib/
 6: dist/
 7: 
 8: # Environment variables
 9: .env
10: .env.local
11: .env.*.local
12: 
13: # Service account keys
14: service_account_key.json
15: *-service-account.json
16: 
17: # Firebase
18: .firebase/
19: firebase-debug.log
20: firebase-debug.*.log
21: 
22: # IDE
23: .vscode/
24: .idea/
25: 
26: # Logs
27: *.log
28: 
29: codebase.xml
</file>

<file path=".npmrc">
1: registry=https://registry.npmjs.org/
2: @google-cloud:registry=https://registry.npmjs.org/
</file>

<file path=".npmrc.backup">
1: //us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/:_authToken=${NPM_TOKEN}
2: @google-cloud:registry=https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/
</file>

<file path=".prettierrc">
1: {
2:   "singleQuote": false,
3:   "trailingComma": "es5",
4:   "bracketSpacing": true,
5:   "semi": true,
6:   "printWidth": 120,
7:   "tabWidth": 2,
8:   "endOfLine": "auto"
9: }
</file>

<file path=".repomixignore">
1: lib/**
2: !*/
3: !.gitignore
4: service_account_key.json
5: !src/**
</file>

<file path="firebase.json">
 1: {
 2:   "functions": {
 3:     "source": ".",
 4:     "codebase": "default",
 5:     "runtime": "nodejs18",
 6:     "ignore": [
 7:       "node_modules",
 8:       ".git",
 9:       "firebase-debug.log",
10:       "firebase-debug.*.log",
11:       "*.local"
12:     ],
13:     "predeploy": [
14:       "npm run lint",
15:       "npm run build"
16:     ]
17:   },
18:   "firestore": {
19:     "rules": "firestore.rules",
20:     "indexes": "firestore.indexes.json"
21:   },
22:   "emulators": {
23:     "functions": {
24:       "port": 5001
25:     },
26:     "firestore": {
27:       "port": 8080
28:     },
29:     "ui": {
30:       "enabled": true
31:     },
32:     "singleProjectMode": true
33:   }
34: }
</file>

<file path="firestore.indexes.json">
 1: {
 2:   "indexes": [],
 3:   "fieldOverrides": [
 4:     {
 5:       "collectionGroup": "cards",
 6:       "fieldPath": "imageMetadata",
 7:       "indexes": []
 8:     },
 9:     {
10:       "collectionGroup": "cards",
11:       "fieldPath": "extendedData",
12:       "indexes": []
13:     },
14:     {
15:       "collectionGroup": "cards",
16:       "fieldPath": "lastUpdated",
17:       "indexes": []
18:     },
19:     {
20:       "collectionGroup": "prices",
21:       "fieldPath": "lastUpdated",
22:       "indexes": []
23:     },
24:     {
25:       "collectionGroup": "historicalPrices",
26:       "fieldPath": "lastUpdated",
27:       "indexes": []
28:     }
29:   ]
30: }
</file>

<file path="firestore.rules">
1: rules_version = '2';
2: service cloud.firestore {
3:   match /databases/{database}/documents {
4:     match /{document=**} {
5:       allow read, write: if false;
6:     }
7:   }
8: }
</file>

<file path="package.json">
 1: {
 2:   "name": "functions",
 3:   "scripts": {
 4:     "lint": "eslint --ext .js,.ts .",
 5:     "lint:fix": "eslint --ext .js,.ts . --fix",
 6:     "build": "rimraf lib && tsc",
 7:     "build:watch": "tsc --watch",
 8:     "serve": "npm run build && firebase emulators:start --only functions,firestore",
 9:     "shell": "npm run build && firebase functions:shell",
10:     "start": "npm run shell",
11:     "deploy": "firebase deploy --only functions",
12:     "logs": "firebase functions:log",
13:     "cleanup:elements": "ts-node src/scripts/cleanupElements.ts",
14:     "sync:groups": "ts-node src/scripts/syncGroups.ts"
15:   },
16:   "engines": {
17:     "node": "18"
18:   },
19:   "main": "lib/index.js",
20:   "dependencies": {
21:     "@aws-sdk/client-s3": "^3.485.0",
22:     "@aws-sdk/s3-request-presigner": "^3.485.0",
23:     "axios": "^1.7.7",
24:     "cors": "^2.8.5",
25:     "dotenv": "^16.4.7",
26:     "express": "^4.18.2",
27:     "firebase-admin": "^12.0.0",
28:     "firebase-functions": "^6.2.0",
29:     "lru-cache": "^7.14.1"
30:   },
31:   "devDependencies": {
32:     "@types/cors": "^2.8.17",
33:     "@types/express": "^4.17.21",
34:     "@typescript-eslint/eslint-plugin": "^5.12.0",
35:     "@typescript-eslint/parser": "^5.12.0",
36:     "eslint": "^8.9.0",
37:     "eslint-config-google": "^0.14.0",
38:     "eslint-plugin-import": "^2.25.4",
39:     "firebase-functions-test": "^3.1.0",
40:     "rimraf": "^5.0.0",
41:     "ts-node": "^10.9.1",
42:     "typescript": "^4.9.0"
43:   },
44:   "private": true,
45:   "publishConfig": {
46:     "registry": "https://us-central1-npm.pkg.dev/fftcg-sync-service/gcf-artifacts/"
47:   }
48: }
</file>

<file path="repomix.config.json">
 1: {
 2:   "output": {
 3:     "filePath": "firestore_codebase.xml",
 4:     "style": "xml",
 5:     "removeComments": false,
 6:     "removeEmptyLines": false,
 7:     "topFilesLength": 5,
 8:     "showLineNumbers": true,
 9:     "copyToClipboard": false
10:   },
11:   "include": [],
12:   "ignore": {
13:     "useGitignore": false,
14:     "useDefaultPatterns": true,
15:     "customPatterns": []
16:   },
17:   "security": {
18:     "enableSecurityCheck": true
19:   }
20: }
</file>

<file path="src/config/environment.ts">
 1: // src/config/environment.ts
 2: interface Environment {
 3:   isLocal: boolean;
 4:   nodeEnv: string;
 5: }
 6: 
 7: export const environment: Environment = {
 8:   isLocal: process.env.NODE_ENV === "development" || process.env.NODE_ENV === "test",
 9:   nodeEnv: process.env.NODE_ENV || "development",
10: };
</file>

<file path="src/config/firebase.ts">
 1: // src/config/firebase.ts
 2: import * as admin from "firebase-admin";
 3: 
 4: const app = !admin.apps.length ? admin.initializeApp() : admin.app();
 5: const db = admin.firestore(app);
 6: 
 7: // Enable ignoreUndefinedProperties and other settings
 8: db.settings({
 9:   ignoreUndefinedProperties: true,
10:   timestampsInSnapshots: true,
11: });
12: 
13: export { db };
14: 
15: export const COLLECTION = {
16:   CARDS: "cards",
17:   PRICES: "prices",
18:   SYNC_METADATA: "syncMetadata",
19:   LOGS: "logs",
20:   CARD_HASHES: "cardHashes",
21:   PRICE_HASHES: "priceHashes",
22:   IMAGE_METADATA: "imageMetadata",
23:   HISTORICAL_PRICES: "historicalPrices",
24:   CARD_DELTAS: "cardDeltas",
25:   PRICE_DELTAS: "priceDeltas",
26:   GROUPS: "groups",
27:   GROUP_HASHES: "groupHashes",
28:   SYNC_STATE: "syncState",
29: } as const;
30: 
31: export const BASE_URL = "https://tcgcsv.com/tcgplayer";
32: export const FFTCG_CATEGORY_ID = "24";
33: 
34: export const runtimeOpts = {
35:   timeoutSeconds: 540,
36:   memory: "1GiB",
37: } as const;
</file>

<file path="src/config/r2Config.ts">
 1: // src/config/r2Config.ts
 2: import * as dotenv from "dotenv";
 3: 
 4: // Load .env file
 5: dotenv.config();
 6: 
 7: interface R2Config {
 8:     ACCOUNT_ID: string;
 9:     ACCESS_KEY_ID: string;
10:     SECRET_ACCESS_KEY: string;
11:     BUCKET_NAME: string;
12:     STORAGE_PATH: string;
13:     CUSTOM_DOMAIN: string;
14: }
15: 
16: type R2ConfigKey = keyof R2Config;
17: 
18: const getConfig = (): R2Config => {
19:   try {
20:     const configuration: R2Config = {
21:       ACCOUNT_ID: process.env.R2_ACCOUNT_ID || "",
22:       ACCESS_KEY_ID: process.env.R2_ACCESS_KEY_ID || "",
23:       SECRET_ACCESS_KEY: process.env.R2_SECRET_ACCESS_KEY || "",
24:       BUCKET_NAME: process.env.R2_BUCKET_NAME || "",
25:       STORAGE_PATH: process.env.R2_STORAGE_PATH || "card-images",
26:       CUSTOM_DOMAIN: process.env.R2_CUSTOM_DOMAIN || "",
27:     };
28: 
29:     // Debug logging
30:     console.log("Loading R2 Configuration:", {
31:       ...configuration,
32:       ACCESS_KEY_ID: configuration.ACCESS_KEY_ID ? "***" : "not set",
33:       SECRET_ACCESS_KEY: configuration.SECRET_ACCESS_KEY ? "***" : "not set",
34:     });
35: 
36:     // Validate required fields
37:     const requiredFields: R2ConfigKey[] = ["ACCOUNT_ID", "ACCESS_KEY_ID", "SECRET_ACCESS_KEY", "BUCKET_NAME"];
38:     for (const field of requiredFields) {
39:       if (!configuration[field]) {
40:         throw new Error(`Missing required R2 configuration: ${field}`);
41:       }
42:     }
43: 
44:     return configuration;
45:   } catch (error) {
46:     console.error("Error loading R2 config:", error);
47:     throw error;
48:   }
49: };
50: 
51: export const R2_CONFIG = getConfig();
52: 
53: // Add this to help with debugging
54: console.log("R2 Configuration loaded:", {
55:   ACCOUNT_ID: R2_CONFIG.ACCOUNT_ID,
56:   BUCKET_NAME: R2_CONFIG.BUCKET_NAME,
57:   STORAGE_PATH: R2_CONFIG.STORAGE_PATH,
58:   CUSTOM_DOMAIN: R2_CONFIG.CUSTOM_DOMAIN,
59:   // Hide sensitive data
60:   ACCESS_KEY_ID: R2_CONFIG.ACCESS_KEY_ID ? "***" : "not set",
61:   SECRET_ACCESS_KEY: R2_CONFIG.SECRET_ACCESS_KEY ? "***" : "not set",
62: });
</file>

<file path="src/index.ts">
  1: // src/index.ts
  2: import { onRequest } from "firebase-functions/v2/https";
  3: import { onSchedule } from "firebase-functions/v2/scheduler";
  4: import { Request, Response } from "express";
  5: import { cardSync } from "./services/cardSync";
  6: import { priceSync } from "./services/priceSync";
  7: import { retention } from "./utils/retention";
  8: import { runtimeOpts } from "./config/firebase";
  9: import { logger } from "./utils/logger";
 10: import { tcgcsvApi } from "./utils/api";
 11: import { CardProduct } from "types";
 12: 
 13: // Keep your existing scheduledCardSync function
 14: export const scheduledCardSync = onSchedule({
 15:   schedule: "0 21 * * *", // Daily at 21:00 UTC
 16:   timeZone: "UTC",
 17:   region: "us-central1",
 18:   memory: "2GiB",
 19:   timeoutSeconds: 540,
 20:   retryCount: 3,
 21:   maxInstances: 1,
 22: }, async (): Promise<void> => {
 23:   try {
 24:     console.log("Function triggered"); // Added console.log
 25:     logger.info("Starting scheduled card sync");
 26:     const result = await cardSync.syncCards();
 27:     logger.info("Scheduled card sync completed", result);
 28:   } catch (error) {
 29:     console.error("Function error:", error); // Added console.error
 30:     logger.error("Scheduled card sync failed", { error });
 31:     throw error;
 32:   }
 33: });
 34: 
 35: export const testApi = onRequest({
 36:   timeoutSeconds: 30,
 37:   memory: "128MiB",
 38:   region: "us-central1",
 39: }, async (_req: Request, res: Response) => {
 40:   try {
 41:     console.log("Testing API connectivity...");
 42: 
 43:     // Test groups endpoint
 44:     console.log("Testing groups endpoint...");
 45:     const groups = await tcgcsvApi.getGroups();
 46: 
 47:     // Test products endpoint with first group
 48:     console.log("Testing products endpoint...");
 49:     let products: CardProduct[] = [];
 50:     if (groups.length > 0) {
 51:       products = await tcgcsvApi.getGroupProducts(groups[0].groupId);
 52:     }
 53: 
 54:     res.json({
 55:       success: true,
 56:       timestamp: new Date().toISOString(),
 57:       results: {
 58:         groups: {
 59:           count: groups.length,
 60:           firstGroup: groups[0],
 61:         },
 62:         products: {
 63:           count: products.length,
 64:           firstProduct: products[0],
 65:         },
 66:       },
 67:     });
 68:   } catch (error) {
 69:     console.error("API test failed:", error);
 70:     res.status(500).json({
 71:       success: false,
 72:       timestamp: new Date().toISOString(),
 73:       error: error instanceof Error ? {
 74:         message: error.message,
 75:         stack: error.stack,
 76:         name: error.name,
 77:       } : String(error),
 78:     });
 79:   }
 80: });
 81: 
 82: // Add the new HTTP endpoint for testing
 83: export const testScheduledCardSync = onRequest({
 84:   timeoutSeconds: 540,
 85:   memory: "2GiB",
 86:   region: "us-central1",
 87: }, async (req: Request, res: Response) => {
 88:   try {
 89:     console.log("Test endpoint triggered", { query: req.query });
 90: 
 91:     // Parse optional parameters from query string
 92:     const options = {
 93:       dryRun: req.query.dryRun === "true",
 94:       groupId: req.query.groupId as string,
 95:       forceUpdate: req.query.forceUpdate === "true",
 96:     };
 97: 
 98:     logger.info("Starting manual card sync test", { options });
 99: 
100:     // Test API connectivity first
101:     try {
102:       const groups = await tcgcsvApi.getGroups();
103:       console.log("API Groups response:", {
104:         groupCount: groups.length,
105:         firstGroup: groups[0],
106:       });
107: 
108:       if (groups.length > 0 && !options.groupId) {
109:         // Test getting products for the first group
110:         const firstGroupProducts = await tcgcsvApi.getGroupProducts(groups[0].groupId);
111:         console.log("First group products:", {
112:           groupId: groups[0].groupId,
113:           productCount: firstGroupProducts.length,
114:           firstProduct: firstGroupProducts[0],
115:         });
116:       }
117:     } catch (apiError) {
118:       console.error("API Test Failed:", apiError);
119:       throw new Error(`API Connectivity Test Failed: ${apiError instanceof Error ?
120:         apiError.message : String(apiError)}`);
121:     }
122: 
123:     // Proceed with sync
124:     const result = await cardSync.syncCards(options);
125:     logger.info("Manual card sync completed", result);
126: 
127:     // Send detailed response
128:     res.json({
129:       success: true,
130:       timestamp: new Date().toISOString(),
131:       options,
132:       result,
133:       debug: {
134:         environment: process.env.NODE_ENV,
135:         functionRegion: "us-central1",
136:         memoryLimit: "2GiB",
137:         timeoutSeconds: 540,
138:       },
139:     });
140:   } catch (error) {
141:     console.error("Test endpoint error:", error);
142:     logger.error("Manual card sync failed", { error });
143: 
144:     res.status(500).json({
145:       success: false,
146:       timestamp: new Date().toISOString(),
147:       error: error instanceof Error ? {
148:         message: error.message,
149:         stack: error.stack,
150:         name: error.name,
151:       } : String(error),
152:       options: req.query,
153:       debug: {
154:         environment: process.env.NODE_ENV,
155:         functionRegion: "us-central1",
156:       },
157:     });
158:   }
159: });
160: 
161: // Manual card sync endpoint for testing
162: export const testCardSync = onRequest({
163:   timeoutSeconds: runtimeOpts.timeoutSeconds,
164:   memory: runtimeOpts.memory,
165:   maxInstances: 1,
166: }, async (req: Request, res: Response) => {
167:   const options = {
168:     dryRun: true, // Always true for test endpoint
169:     limit: req.query.limit ? parseInt(req.query.limit as string) : 5, // Default to 5
170:     groupId: req.query.groupId as string,
171:   };
172: 
173:   const result = await cardSync.syncCards(options);
174:   res.json(result);
175: });
176: 
177: export const manualCardSync = onRequest({
178:   timeoutSeconds: runtimeOpts.timeoutSeconds,
179:   memory: runtimeOpts.memory,
180:   maxInstances: 1,
181: }, async (_req: Request, res: Response) => {
182:   const result = await cardSync.syncCards({ dryRun: false }); // Full sync
183:   res.json(result);
184: });
185: 
186: // Scheduled price sync
187: export const scheduledPriceSync = onSchedule({
188:   schedule: "30 21 * * *", // Daily at 21:30 UTC
189:   timeZone: "UTC",
190:   region: "us-central1",
191:   memory: runtimeOpts.memory,
192:   timeoutSeconds: runtimeOpts.timeoutSeconds,
193:   retryCount: 3,
194: }, async () => { // Removed _context parameter since it's unused
195:   await priceSync.syncPrices();
196: });
197: 
198: // Manual price sync endpoint for testing
199: export const testPriceSync = onRequest({
200:   timeoutSeconds: runtimeOpts.timeoutSeconds,
201:   memory: runtimeOpts.memory,
202:   maxInstances: 1,
203: }, async (req: Request, res: Response) => {
204:   const options = {
205:     dryRun: req.query.dryRun === "true",
206:     limit: req.query.limit ? parseInt(req.query.limit as string) : undefined,
207:     groupId: req.query.groupId as string,
208:     productId: req.query.productId ? parseInt(req.query.productId as string) : undefined,
209:     showAll: req.query.showAll === "true",
210:   };
211: 
212:   const result = await priceSync.syncPrices(options);
213:   res.json(result);
214: });
215: 
216: // For manually triggering full price sync
217: export const manualPriceSync = onRequest({
218:   timeoutSeconds: runtimeOpts.timeoutSeconds,
219:   memory: runtimeOpts.memory,
220:   maxInstances: 1,
221: }, async (_req: Request, res: Response) => {
222:   const result = await priceSync.syncPrices();
223:   res.json(result);
224: });
225: 
226: // Health check endpoint
227: export const healthCheck = onRequest({
228:   timeoutSeconds: 10,
229:   memory: "128MiB",
230:   region: "us-central1",
231: }, async (_req: Request, res: Response) => {
232:   res.status(200).json({
233:     status: "healthy",
234:     timestamp: new Date().toISOString(),
235:     version: "1.0.0",
236:   });
237: });
238: 
239: // Scheduled cleanup
240: export const scheduledCleanup = onSchedule({
241:   schedule: "0 22 * * *", // Daily at 22:00 UTC
242:   timeZone: "UTC",
243:   region: "us-central1",
244:   memory: runtimeOpts.memory,
245:   timeoutSeconds: runtimeOpts.timeoutSeconds,
246:   retryCount: 3,
247: }, async () => {
248:   await retention.cleanOldData();
249: });
250: 
251: // Manual cleanup endpoint
252: export const manualCleanup = onRequest({
253:   timeoutSeconds: runtimeOpts.timeoutSeconds,
254:   memory: runtimeOpts.memory,
255:   maxInstances: 1,
256: }, async (_req: Request, res: Response) => {
257:   await retention.cleanOldData();
258:   res.json({ success: true });
259: });
</file>

<file path="src/scripts/cleanup.ts">
 1: import { retention } from "../utils/retention";
 2: 
 3: async function main() {
 4:   console.log("Starting manual cleanup...");
 5:   try {
 6:     await retention.cleanOldData();
 7:     console.log("Cleanup completed successfully");
 8:   } catch (error) {
 9:     console.error("Cleanup failed:", error);
10:     process.exit(1);
11:   }
12: }
13: 
14: main();
</file>

<file path="src/scripts/cleanupElements.ts">
 1: // src/scripts/cleanupElements.ts
 2: import { db } from "../config/firebase";
 3: import { logger } from "../utils/logger";
 4: import { FieldValue } from "firebase-admin/firestore";
 5: 
 6: async function cleanupElementsData(): Promise<void> {
 7:   try {
 8:     logger.info("Starting elements cleanup...");
 9:     const cardsSnapshot = await db.collection("cards").get();
10:     const totalCards = cardsSnapshot.size;
11: 
12:     logger.info(`Found ${totalCards} cards to process`);
13: 
14:     // Process in batches of 500 (Firestore batch limit)
15:     const batchSize = 500;
16:     let batchCount = 0;
17:     let processedCount = 0;
18:     let batch = db.batch();
19:     let changes = 0;
20: 
21:     for (const doc of cardsSnapshot.docs) {
22:       const data = doc.data();
23: 
24:       // Only process if elements array exists
25:       if (data.elements !== undefined) {
26:         batch.update(doc.ref, {
27:           elements: FieldValue.delete(),
28:         });
29:         changes++;
30:       }
31: 
32:       // Delete Element document in extendedData
33:       const elementRef = doc.ref.collection("extendedData").doc("Element");
34:       batch.delete(elementRef);
35:       changes++;
36: 
37:       batchCount++;
38:       processedCount++;
39: 
40:       // Commit when batch is full
41:       if (batchCount >= batchSize) {
42:         await batch.commit();
43:         logger.info(`Processed ${processedCount}/${totalCards} cards (${changes} changes)`);
44:         batch = db.batch();
45:         batchCount = 0;
46:       }
47:     }
48: 
49:     // Commit any remaining operations
50:     if (batchCount > 0) {
51:       await batch.commit();
52:       logger.info(`Processed ${processedCount}/${totalCards} cards (${changes} changes)`);
53:     }
54: 
55:     logger.info("Elements cleanup completed successfully", {
56:       totalProcessed: processedCount,
57:       totalChanges: changes,
58:     });
59:   } catch (error) {
60:     logger.error("Elements cleanup failed", { error });
61:     throw error;
62:   }
63: }
64: 
65: // Execute if run directly
66: if (require.main === module) {
67:   cleanupElementsData()
68:     .then(() => {
69:       console.log("Cleanup completed successfully!");
70:       process.exit(0);
71:     })
72:     .catch((error) => {
73:       console.error("Cleanup failed:", error);
74:       process.exit(1);
75:     });
76: }
</file>

<file path="src/scripts/prodSync.ts">
  1: // src/scripts/prodSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger, LogData } from "../utils/logger";
  5: 
  6: 
  7: interface SyncStats {
  8:   success: boolean;
  9:   itemsProcessed: number;
 10:   itemsUpdated: number;
 11:   errors: string[];
 12:   duration: number;
 13: }
 14: 
 15: interface SyncOptions {
 16:   forceUpdate?: boolean;
 17:   groupId?: string;
 18:   cardsOnly?: boolean;
 19:   pricesOnly?: boolean;
 20: }
 21: 
 22: // Move runProductionSync into a class for better organization
 23: class ProductionSync {
 24:   async run(options: SyncOptions = {}) {
 25:     const startTime = Date.now();
 26:     const results: {
 27:       cards?: SyncStats;
 28:       prices?: SyncStats;
 29:     } = {};
 30: 
 31:     try {
 32:       logger.info("Starting production sync", { options } as LogData);
 33: 
 34:       // Run card sync if not prices-only
 35:       if (!options.pricesOnly) {
 36:         logger.info("Starting card sync...");
 37:         const cardResult = await cardSync.syncCards({
 38:           forceUpdate: options.forceUpdate,
 39:           groupId: options.groupId,
 40:         });
 41: 
 42:         results.cards = {
 43:           success: cardResult.success,
 44:           itemsProcessed: cardResult.itemsProcessed,
 45:           itemsUpdated: cardResult.itemsUpdated,
 46:           errors: cardResult.errors,
 47:           duration: cardResult.timing.duration || 0,
 48:         };
 49: 
 50:         logger.info("Card sync completed", { stats: results.cards } as LogData);
 51:       }
 52: 
 53:       // Run price sync if not cards-only
 54:       if (!options.cardsOnly) {
 55:         logger.info("Starting price sync...");
 56:         const priceResult = await priceSync.syncPrices({
 57:           forceUpdate: options.forceUpdate,
 58:           groupId: options.groupId,
 59:         });
 60: 
 61:         results.prices = {
 62:           success: priceResult.success,
 63:           itemsProcessed: priceResult.itemsProcessed,
 64:           itemsUpdated: priceResult.itemsUpdated,
 65:           errors: priceResult.errors,
 66:           duration: priceResult.timing.duration || 0,
 67:         };
 68: 
 69:         logger.info("Price sync completed", { stats: results.prices } as LogData);
 70:       }
 71: 
 72:       const totalDuration = (Date.now() - startTime) / 1000;
 73:       logger.info(`Full sync completed in ${totalDuration}s`, { results } as LogData);
 74: 
 75:       return results;
 76:     } catch (error) {
 77:       logger.error("Production sync failed", { error } as LogData);
 78:       throw error;
 79:     }
 80:   }
 81: }
 82: 
 83: function parseArgs(args: string[]): SyncOptions {
 84:   const options: SyncOptions = {};
 85: 
 86:   for (let i = 0; i < args.length; i++) {
 87:     switch (args[i]) {
 88:     case "--force":
 89:       options.forceUpdate = true;
 90:       break;
 91:     case "--group":
 92:       options.groupId = args[++i];
 93:       break;
 94:     case "--cards-only":
 95:       options.cardsOnly = true;
 96:       break;
 97:     case "--prices-only":
 98:       options.pricesOnly = true;
 99:       break;
100:     case "--help":
101:       printHelp();
102:       process.exit(0);
103:     }
104:   }
105: 
106:   return options;
107: }
108: 
109: function printHelp() {
110:   console.log(`
111: Usage: npx ts-node src/scripts/prodSync.ts [options]
112: 
113: Options:
114:   --force         Force update all items regardless of changes
115:   --group <id>    Sync specific group ID only
116:   --cards-only    Only sync card data
117:   --prices-only   Only sync price data
118:   --help          Show this help message
119:   
120: Examples:
121:   npx ts-node src/scripts/prodSync.ts
122:   npx ts-node src/scripts/prodSync.ts --force
123:   npx ts-node src/scripts/prodSync.ts --group 23244
124:   npx ts-node src/scripts/prodSync.ts --cards-only
125:   `);
126: }
127: 
128: // Create singleton instance
129: export const productionSync = new ProductionSync();
130: 
131: // Command line execution
132: async function main() {
133:   const args = process.argv.slice(2);
134:   const options = parseArgs(args);
135: 
136:   console.log("Starting production sync with options:", options);
137: 
138:   try {
139:     const results = await productionSync.run(options);
140:     console.log("Sync completed successfully!");
141:     console.log(JSON.stringify(results, null, 2));
142:     process.exit(0);
143:   } catch (error) {
144:     console.error("Sync failed:", error);
145:     process.exit(1);
146:   }
147: }
148: 
149: // Run if called directly
150: if (require.main === module) {
151:   main();
152: }
</file>

<file path="src/scripts/setenv.ts">
 1: // scripts/setenv.ts
 2: import * as dotenv from "dotenv";
 3: import { exec } from "child_process";
 4: import { promisify } from "util";
 5: 
 6: const execAsync = promisify(exec);
 7: 
 8: async function setFirebaseConfig() {
 9:   try {
10:     dotenv.config();
11: 
12:     const config = {
13:       account_id: process.env.R2_ACCOUNT_ID,
14:       access_key_id: process.env.R2_ACCESS_KEY_ID,
15:       secret_access_key: process.env.R2_SECRET_ACCESS_KEY,
16:       bucket_name: process.env.R2_BUCKET_NAME,
17:       storage_path: process.env.R2_STORAGE_PATH,
18:       custom_domain: process.env.R2_CUSTOM_DOMAIN,
19:     };
20: 
21:     // Remove existing config
22:     await execAsync("firebase functions:config:unset r2");
23: 
24:     // Set new config
25:     const configString = Object.entries(config)
26:       .map(([key, value]) => `r2.${key}="${value}"`)
27:       .join(" ");
28: 
29:     await execAsync(`firebase functions:config:set ${configString}`);
30:     console.log("Firebase config updated successfully");
31:   } catch (error) {
32:     console.error("Error setting Firebase config:", error);
33:   }
34: }
35: 
36: setFirebaseConfig();
</file>

<file path="src/scripts/syncAll.ts">
 1: import { cardSync } from "../services/cardSync";
 2: import { priceSync } from "../services/priceSync";
 3: 
 4: async function main() {
 5:   console.log("Starting full sync...");
 6: 
 7:   try {
 8:     console.log("\n1. Running card sync...");
 9:     const cardResult = await cardSync.syncCards();
10:     console.log("Card sync completed:", {
11:       success: cardResult.success,
12:       processed: cardResult.itemsProcessed,
13:       updated: cardResult.itemsUpdated,
14:       errors: cardResult.errors.length,
15:     });
16: 
17:     console.log("\n2. Running price sync...");
18:     const priceResult = await priceSync.syncPrices();
19:     console.log("Price sync completed:", {
20:       success: priceResult.success,
21:       processed: priceResult.itemsProcessed,
22:       updated: priceResult.itemsUpdated,
23:       errors: priceResult.errors.length,
24:     });
25: 
26:     const allErrors = [...cardResult.errors, ...priceResult.errors];
27:     if (allErrors.length > 0) {
28:       console.log("\nErrors encountered:");
29:       allErrors.forEach((error) => console.log(`- ${error}`));
30:     }
31: 
32:     console.log("\nFull sync completed!");
33:   } catch (error) {
34:     console.error("Full sync failed:", error);
35:     process.exit(1);
36:   }
37: }
38: 
39: main();
</file>

<file path="src/scripts/syncCards.ts">
 1: // src/scripts/syncCards.ts
 2: import { cardSync } from "../services/cardSync";
 3: 
 4: function parseArgs(args: string[]): { forceUpdate?: boolean; groupId?: string } {
 5:   const options: { forceUpdate?: boolean; groupId?: string } = {};
 6: 
 7:   for (let i = 0; i < args.length; i++) {
 8:     switch (args[i]) {
 9:     case "--force":
10:       options.forceUpdate = true;
11:       break;
12:     case "--group":
13:       options.groupId = args[++i];
14:       break;
15:     }
16:   }
17: 
18:   return options;
19: }
20: 
21: async function main() {
22:   try {
23:     const args = process.argv.slice(2);
24:     const options = parseArgs(args);
25: 
26:     console.log("Starting manual card sync with options:", options);
27:     const result = await cardSync.syncCards(options);
28:     console.log("Card sync completed:", {
29:       success: result.success,
30:       processed: result.itemsProcessed,
31:       updated: result.itemsUpdated,
32:       errors: result.errors.length,
33:       duration: `${result.timing.duration}s`,
34:     });
35: 
36:     if (result.errors.length > 0) {
37:       console.log("\nErrors encountered:");
38:       result.errors.forEach((error) => console.log(`- ${error}`));
39:     }
40:   } catch (error) {
41:     console.error("Card sync failed:", error);
42:     process.exit(1);
43:   } finally {
44:     // Force exit after a short delay to allow final logs to be written
45:     setTimeout(() => process.exit(0), 1000);
46:   }
47: }
48: 
49: main();
</file>

<file path="src/scripts/syncGroups.ts">
 1: // src/scripts/syncGroups.ts
 2: import { groupSync } from "../services/groupSync";
 3: 
 4: async function main() {
 5:   try {
 6:     const args = process.argv.slice(2);
 7:     const forceUpdate = args.includes("--force");
 8: 
 9:     console.log("Starting group sync", { forceUpdate });
10:     const result = await groupSync.syncGroups({ forceUpdate });
11:     console.log("Group sync completed:", {
12:       success: result.success,
13:       processed: result.itemsProcessed,
14:       updated: result.itemsUpdated,
15:       errors: result.errors.length,
16:       duration: `${result.timing.duration}s`,
17:     });
18: 
19:     if (result.errors.length > 0) {
20:       console.log("\nErrors encountered:");
21:       result.errors.forEach((error) => console.log(`- ${error}`));
22:     }
23:   } catch (error) {
24:     console.error("Group sync failed:", error);
25:     process.exit(1);
26:   }
27: }
28: 
29: main();
</file>

<file path="src/scripts/syncPrices.ts">
 1: import { priceSync } from "../services/priceSync";
 2: 
 3: async function main() {
 4:   console.log("Starting manual price sync...");
 5:   try {
 6:     const result = await priceSync.syncPrices();
 7:     console.log("Price sync completed:", {
 8:       success: result.success,
 9:       processed: result.itemsProcessed,
10:       updated: result.itemsUpdated,
11:       errors: result.errors.length,
12:       duration: `${result.timing.duration}s`,
13:     });
14: 
15:     if (result.errors.length > 0) {
16:       console.log("\nErrors encountered:");
17:       result.errors.forEach((error) => console.log(`- ${error}`));
18:     }
19:   } catch (error) {
20:     console.error("Price sync failed:", error);
21:     process.exit(1);
22:   }
23: }
24: 
25: main();
</file>

<file path="src/scripts/testSync.ts">
  1: // src/scripts/testSync.ts
  2: import { cardSync } from "../services/cardSync";
  3: import { priceSync } from "../services/priceSync";
  4: import { logger } from "../utils/logger";
  5: import { withTimeout, TimeoutError } from "../utils/timeout";
  6: import { storageService } from "../services/storageService";
  7: 
  8: const MAX_SYNC_TIME = 30 * 60 * 1000; // 30 minutes
  9: const TEST_GROUP_ID = "23244"; // Dawn of Heroes
 10: const TEST_PRODUCT_ID = 508343; // Example product ID
 11: const IMAGE_BASE_URL = "https://fftcgcompanion.com/card-images";
 12: 
 13: async function testImageProcessing() {
 14:   try {
 15:     logger.info("Testing image processing...");
 16: 
 17:     // Test with a valid image URL using correct format
 18:     const validImageResult = await storageService.processAndStoreImage(
 19:       `${IMAGE_BASE_URL}/${TEST_GROUP_ID}/${TEST_PRODUCT_ID}_200w.jpg`,
 20:       TEST_PRODUCT_ID,
 21:       TEST_GROUP_ID,
 22:       "1-001" // Example card number
 23:     );
 24: 
 25:     logger.info("Valid image processing result:", {
 26:       highResUrl: validImageResult.highResUrl,
 27:       lowResUrl: validImageResult.lowResUrl,
 28:       isPlaceholder: validImageResult.metadata.isPlaceholder,
 29:       originalUrl: validImageResult.metadata.originalUrl,
 30:     });
 31: 
 32:     // Verify the image URLs follow the correct pattern
 33:     const urlPattern = new RegExp(`^${IMAGE_BASE_URL}/.*_[24]00w.jpg$`);
 34:     const isValidImageUrl = urlPattern.test(validImageResult.metadata.originalUrl || "");
 35: 
 36:     if (!isValidImageUrl) {
 37:       logger.error("Image URL pattern does not match expected format", {
 38:         url: validImageResult.metadata.originalUrl,
 39:         expectedPattern: `${IMAGE_BASE_URL}/{groupId}/{productId}_200w.jpg`,
 40:       });
 41:     }
 42: 
 43:     // Test with invalid/missing image (should return placeholder)
 44:     const placeholderResult = await storageService.processAndStoreImage(
 45:       undefined,
 46:       TEST_PRODUCT_ID,
 47:       TEST_GROUP_ID,
 48:       "1-001"
 49:     );
 50: 
 51:     logger.info("Placeholder image result:", {
 52:       highResUrl: placeholderResult.highResUrl,
 53:       lowResUrl: placeholderResult.lowResUrl,
 54:       isPlaceholder: placeholderResult.metadata.isPlaceholder,
 55:     });
 56: 
 57:     return {
 58:       validImage: {
 59:         success: validImageResult.metadata.isPlaceholder !== true,
 60:         correctUrlPattern: isValidImageUrl,
 61:         urls: {
 62:           original: validImageResult.metadata.originalUrl,
 63:           highRes: validImageResult.highResUrl,
 64:           lowRes: validImageResult.lowResUrl,
 65:         },
 66:       },
 67:       placeholderImage: {
 68:         success: placeholderResult.metadata.isPlaceholder === true,
 69:         urls: {
 70:           highRes: placeholderResult.highResUrl,
 71:           lowRes: placeholderResult.lowResUrl,
 72:         },
 73:       },
 74:     };
 75:   } catch (error) {
 76:     logger.error("Image processing test failed:", { error });
 77:     throw error;
 78:   }
 79: }
 80: 
 81: async function testSync() {
 82:   try {
 83:     logger.info("Starting test sync with group " + TEST_GROUP_ID);
 84: 
 85:     // Test image processing first
 86:     logger.info("Testing image processing capabilities...");
 87:     const imageResults = await testImageProcessing();
 88:     logger.info("Image processing test results:", imageResults);
 89: 
 90:     // Monitor card sync with timeout
 91:     const cardResult = await withTimeout(
 92:       cardSync.syncCards({
 93:         groupId: TEST_GROUP_ID,
 94:         forceUpdate: true,
 95:       }),
 96:       MAX_SYNC_TIME
 97:     );
 98: 
 99:     logger.info("Card sync results:", {
100:       processed: cardResult.itemsProcessed,
101:       updated: cardResult.itemsUpdated,
102:       errors: cardResult.errors,
103:       timing: cardResult.timing,
104:     });
105: 
106:     // Monitor price sync with timeout
107:     const priceResult = await withTimeout(
108:       priceSync.syncPrices({
109:         groupId: TEST_GROUP_ID,
110:         forceUpdate: true,
111:       }),
112:       MAX_SYNC_TIME
113:     );
114: 
115:     logger.info("Price sync results:", {
116:       processed: priceResult.itemsProcessed,
117:       updated: priceResult.itemsUpdated,
118:       errors: priceResult.errors,
119:       timing: priceResult.timing,
120:     });
121: 
122:     // Validate results
123:     const validationResults = {
124:       imageProcessing: imageResults,
125:       cardSync: {
126:         success: cardResult.success,
127:         hasUpdates: cardResult.itemsUpdated > 0,
128:         hasErrors: cardResult.errors.length > 0,
129:       },
130:       priceSync: {
131:         success: priceResult.success,
132:         hasUpdates: priceResult.itemsUpdated > 0,
133:         hasErrors: priceResult.errors.length > 0,
134:       },
135:     };
136: 
137:     logger.info("Test validation results:", validationResults);
138: 
139:     // Log any errors
140:     const allErrors = [...cardResult.errors, ...priceResult.errors];
141:     if (allErrors.length > 0) {
142:       logger.error("Errors during sync:", { errors: allErrors });
143:     }
144: 
145:     return validationResults;
146:   } catch (error) {
147:     if (error instanceof TimeoutError) {
148:       logger.error("Sync operation timed out", { error });
149:     } else {
150:       logger.error("Test sync failed:", { error });
151:     }
152:     throw error;
153:   }
154: }
155: 
156: // Execute if run directly
157: if (require.main === module) {
158:   testSync()
159:     .then((results) => {
160:       console.log("Test sync completed successfully!");
161:       console.log("Results:", JSON.stringify(results, null, 2));
162:       process.exit(0);
163:     })
164:     .catch((error) => {
165:       console.error("Test failed:", error);
166:       process.exit(1);
167:     });
168: }
169: 
170: export { testSync, testImageProcessing };
</file>

<file path="src/services/batchProcessor.ts">
  1: import { Firestore, WriteBatch } from "firebase-admin/firestore";
  2: 
  3: export class OptimizedBatchProcessor {
  4:   private batchPool: WriteBatch[] = [];
  5:   private operationsInBatch: Map<WriteBatch, number> = new Map();
  6:   private activePromises: Promise<void>[] = [];
  7: 
  8:   constructor(
  9:     private readonly db: Firestore,
 10:     private readonly maxConcurrentBatches: number = 50,
 11:     private readonly maxOperationsPerBatch: number = 450
 12:   ) {
 13:     this.initializeBatchPool();
 14:   }
 15: 
 16:   private initializeBatchPool(): void {
 17:     this.batchPool = [];
 18:     this.operationsInBatch.clear();
 19:     
 20:     for (let i = 0; i < this.maxConcurrentBatches; i++) {
 21:       const batch = this.db.batch();
 22:       this.batchPool.push(batch);
 23:       this.operationsInBatch.set(batch, 0);
 24:     }
 25:   }
 26: 
 27:   private getAvailableBatch(): WriteBatch {
 28:     // Try to find a batch with room
 29:     for (const batch of this.batchPool) {
 30:       const operations = this.operationsInBatch.get(batch) || 0;
 31:       if (operations < this.maxOperationsPerBatch) {
 32:         return batch;
 33:       }
 34:     }
 35:     
 36:     // If all batches are full, create a new one
 37:     const newBatch = this.db.batch();
 38:     
 39:     // Find the index of a full batch to replace
 40:     const indexToReplace = this.batchPool.findIndex(batch => 
 41:       (this.operationsInBatch.get(batch) || 0) >= this.maxOperationsPerBatch
 42:     );
 43:     
 44:     if (indexToReplace >= 0) {
 45:       // Commit the full batch
 46:       const batchToCommit = this.batchPool[indexToReplace];
 47:       const commitPromise = this.commitBatch(batchToCommit);
 48:       this.activePromises.push(commitPromise);
 49:       
 50:       // Replace it with the new batch
 51:       this.batchPool[indexToReplace] = newBatch;
 52:     } else {
 53:       // If no full batch found, add to pool if there's room
 54:       if (this.batchPool.length < this.maxConcurrentBatches) {
 55:         this.batchPool.push(newBatch);
 56:       } else {
 57:         // Replace the first batch
 58:         const batchToCommit = this.batchPool[0];
 59:         const commitPromise = this.commitBatch(batchToCommit);
 60:         this.activePromises.push(commitPromise);
 61:         this.batchPool[0] = newBatch;
 62:       }
 63:     }
 64:     
 65:     this.operationsInBatch.set(newBatch, 0);
 66:     return newBatch;
 67:   }
 68: 
 69:   async addOperation(operation: (batch: WriteBatch) => void): Promise<void> {
 70:     const batch = this.getAvailableBatch();
 71:     operation(batch);
 72:     this.operationsInBatch.set(batch, (this.operationsInBatch.get(batch) || 0) + 1);
 73: 
 74:     // Clean up completed promises
 75:     const newActivePromises: Promise<void>[] = [];
 76:     
 77:     await Promise.all(
 78:       this.activePromises.map(async (promise) => {
 79:         try {
 80:           const isCompleted = await Promise.race([
 81:             promise.then(() => true),
 82:             Promise.resolve(false)
 83:           ]);
 84:           
 85:           if (!isCompleted) {
 86:             newActivePromises.push(promise);
 87:           }
 88:         } catch (error) {
 89:           newActivePromises.push(promise);
 90:         }
 91:       })
 92:     );
 93: 
 94:     this.activePromises = newActivePromises;
 95: 
 96:     // If we have too many active promises, wait for one to complete
 97:     if (this.activePromises.length >= this.maxConcurrentBatches) {
 98:       await Promise.race(this.activePromises);
 99:     }
100:   }
101: 
102:   private async commitBatch(batch: WriteBatch): Promise<void> {
103:     try {
104:       await batch.commit();
105:       this.operationsInBatch.delete(batch); // Remove the committed batch from tracking
106:     } catch (error) {
107:       const typedError = error as { code?: string };
108:       if (typedError.code === 'unavailable') {
109:         await new Promise(resolve => setTimeout(resolve, 1000));
110:         await this.commitBatch(batch);
111:       } else {
112:         throw error;
113:       }
114:     }
115:   }
116: 
117:   async commitAll(): Promise<void> {
118:     // Gather all uncommitted batches
119:     const uncommittedBatches = this.batchPool.filter(batch => 
120:       this.operationsInBatch.has(batch) && 
121:       (this.operationsInBatch.get(batch) || 0) > 0
122:     );
123: 
124:     // Create commit promises for each uncommitted batch
125:     const commitPromises = uncommittedBatches.map(batch => this.commitBatch(batch));
126:     
127:     // Wait for all commits to complete
128:     await Promise.all([...this.activePromises, ...commitPromises]);
129:     
130:     // Reset the state
131:     this.activePromises = [];
132:     this.initializeBatchPool();
133:   }
134: }
</file>

<file path="src/services/cardSync.ts">
  1: // src/services/cardSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { storageService } from "./storageService";
  5: import { CardProduct, SyncResult, CardHashData, SyncOptions } from "../types";
  6: import { logger } from "../utils/logger";
  7: import { Cache } from "../utils/cache";
  8: import { RetryWithBackoff } from "../utils/retry";
  9: import * as crypto from "crypto";
 10: import { FieldValue } from "firebase-admin/firestore";
 11: import { OptimizedBatchProcessor } from "./batchProcessor";
 12: 
 13: export class CardSyncService {
 14:   private readonly CHUNK_SIZE = 1000;
 15:   private readonly MAX_EXECUTION_TIME = 510; // 8.5 minutes
 16:   
 17:   private readonly cache = new Cache<string>(15);
 18:   private readonly retry = new RetryWithBackoff();
 19:   private readonly batchProcessor: OptimizedBatchProcessor;
 20: 
 21:   constructor() {
 22:     this.batchProcessor = new OptimizedBatchProcessor(db);
 23:   }
 24: 
 25:   private isApproachingTimeout(startTime: Date, safetyMarginSeconds = 30): boolean {
 26:     const executionTime = (new Date().getTime() - startTime.getTime()) / 1000;
 27:     return executionTime > (this.MAX_EXECUTION_TIME - safetyMarginSeconds);
 28:   }
 29: 
 30:   private getElements(card: CardProduct): string[] {
 31:     const elementField = card.extendedData.find((data) => data.name === "Element");
 32:     if (!elementField?.value) return [];
 33: 
 34:     const valueStr = String(elementField.value);
 35:     return valueStr
 36:       .split(/[;,]/)
 37:       .map((element: string) => element.trim())
 38:       .filter((element: string) => element.length > 0)
 39:       .map((element: string) => element.charAt(0).toUpperCase() + element.slice(1).toLowerCase());
 40:   }
 41: 
 42:   private getExtendedValue(card: CardProduct, fieldName: string): string | null {
 43:     const field = card.extendedData.find(data => data.name === fieldName);
 44:     return field?.value?.toString() || null;
 45:   }
 46: 
 47:   private normalizeNumericValue(value: string | number | null | undefined): number | null {
 48:     if (value === undefined || value === null || value === "") return null;
 49:     const num = typeof value === "number" ? value : parseFloat(String(value));
 50:     return isNaN(num) ? null : num;
 51:   }
 52: 
 53:   private normalizeName(name: string | number): string {
 54:     const nameStr = String(name);
 55:     return nameStr.charAt(0).toUpperCase() + nameStr.slice(1);
 56:   }
 57: 
 58:   private normalizeCardNumber(number: string): string {
 59:     const clean = number.replace(/[-\s]/g, "");
 60: 
 61:     if (clean.startsWith("PR")) {
 62:       const num = clean.slice(2);
 63:       return `PR-${num}`;
 64:     }
 65: 
 66:     const match = clean.match(/^(\d{1,2})(\d{3}[A-Za-z]?)$/);
 67:     if (match) {
 68:       const [, prefix, rest] = match;
 69:       return `${prefix}-${rest}`;
 70:     }
 71: 
 72:     return clean;
 73:   }
 74: 
 75:   private getCardNumbers(card: CardProduct): string[] {
 76:     const numbers: string[] = [];
 77:     card.extendedData
 78:       .filter((data) => data.name === "Number")
 79:       .forEach((numberField) => {
 80:         const valueStr = String(numberField.value);
 81:         const vals = valueStr.split(/[,;/]/).map((n: string) => n.trim());
 82:         numbers.push(...vals.map((num: string) => this.normalizeCardNumber(num)));
 83:       });
 84: 
 85:     if (numbers.length === 0) {
 86:       numbers.push(this.normalizeCardNumber(`P${card.productId}`));
 87:     }
 88: 
 89:     return [...new Set(numbers)];
 90:   }
 91: 
 92:   private isNonCardProduct(card: CardProduct): boolean {
 93:     const cardType = card.extendedData.find((data) => data.name === "CardType")?.value;
 94:     return !cardType || String(cardType).toLowerCase() === "sealed product";
 95:   }
 96: 
 97:   private calculateHash(data: CardHashData): string {
 98:     return crypto
 99:       .createHash("md5")
100:       .update(JSON.stringify(data))
101:       .digest("hex");
102:   }
103: 
104:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
105:     const hashMap = new Map<number, string>();
106:     const uncachedIds: number[] = [];
107: 
108:     productIds.forEach((id) => {
109:       const cacheKey = `hash_${id}`;
110:       const cached = this.cache.get(cacheKey);
111:       if (cached) {
112:         hashMap.set(id, cached);
113:       } else {
114:         uncachedIds.push(id);
115:       }
116:     });
117: 
118:     if (uncachedIds.length === 0) {
119:       return hashMap;
120:     }
121: 
122:     const chunks = [];
123:     for (let i = 0; i < uncachedIds.length; i += 10) {
124:       chunks.push(uncachedIds.slice(i, i + 10));
125:     }
126: 
127:     await Promise.all(chunks.map(async (chunk) => {
128:       const refs = chunk.map((id) =>
129:         db.collection(COLLECTION.CARD_HASHES).doc(id.toString())
130:       );
131: 
132:       const snapshots = await this.retry.execute(() =>
133:         db.getAll(...refs)
134:       );
135: 
136:       snapshots.forEach((snap, index) => {
137:         const id = chunk[index];
138:         const hash = snap.exists ? snap.data()?.hash : null;
139:         if (hash) {
140:           hashMap.set(id, hash);
141:           this.cache.set(`hash_${id}`, hash);
142:         }
143:       });
144:     }));
145: 
146:     return hashMap;
147:   }
148: 
149:   private async processCards(
150:     cards: CardProduct[],
151:     groupId: string,
152:     options: { forceUpdate?: boolean } = {}
153:   ): Promise<{
154:     processed: number;
155:     updated: number;
156:     errors: string[];
157:   }> {
158:     const result = {
159:       processed: 0,
160:       updated: 0,
161:       errors: [] as string[],
162:     };
163: 
164:     try {
165:       const productIds = cards.map((card) => card.productId);
166:       const hashMap = await this.getStoredHashes(productIds);
167: 
168:       await Promise.all(cards.map(async (card) => {
169:         try {
170:           result.processed++;
171: 
172:           const cardNumbers = this.getCardNumbers(card);
173:           const primaryCardNumber = cardNumbers[0];
174: 
175:           const imageResult = await this.retry.execute(() =>
176:             storageService.processAndStoreImage(
177:               card.imageUrl,
178:               card.productId,
179:               groupId,
180:               primaryCardNumber
181:             )
182:           );
183: 
184:           const relevantData: CardHashData = {
185:             name: card.name,
186:             cleanName: card.cleanName,
187:             modifiedOn: card.modifiedOn,
188:             extendedData: card.extendedData,
189:           };
190: 
191:           const currentHash = this.calculateHash(relevantData);
192:           const storedHash = hashMap.get(card.productId);
193: 
194:           if (currentHash === storedHash && !options.forceUpdate) {
195:             return;
196:           }
197: 
198:           const cardDoc = {
199:             productId: card.productId,
200:             name: this.normalizeName(card.name),
201:             cleanName: this.normalizeName(card.cleanName),
202:             fullResUrl: imageResult.fullResUrl,
203:             highResUrl: imageResult.highResUrl,
204:             lowResUrl: imageResult.lowResUrl,
205:             lastUpdated: FieldValue.serverTimestamp(),
206:             groupId: parseInt(groupId),
207:             isNonCard: this.isNonCardProduct(card),
208:             cardNumbers,
209:             primaryCardNumber,
210:             
211:             // Flattened extended data
212:             cardType: this.getExtendedValue(card, "CardType"),
213:             category: this.getExtendedValue(card, "Category"),
214:             cost: this.normalizeNumericValue(this.getExtendedValue(card, "Cost")),
215:             description: this.getExtendedValue(card, "Description"),
216:             elements: this.getElements(card),
217:             job: this.getExtendedValue(card, "Job"),
218:             number: this.getExtendedValue(card, "Number"),
219:             power: this.normalizeNumericValue(this.getExtendedValue(card, "Power")),
220:             rarity: this.getExtendedValue(card, "Rarity"),
221:           };
222: 
223:           // Add main card document
224:           await this.batchProcessor.addOperation(batch => {
225:             const cardRef = db.collection(COLLECTION.CARDS).doc(card.productId.toString());
226:             batch.set(cardRef, cardDoc, { merge: true });
227:           });
228: 
229:           // Add image metadata
230:           await this.batchProcessor.addOperation(batch => {
231:             const cardRef = db.collection(COLLECTION.CARDS).doc(card.productId.toString());
232:             batch.set(
233:               cardRef.collection("metadata").doc("image"),
234:               imageResult.metadata,
235:               { merge: true }
236:             );
237:           });
238: 
239:           // Update hash
240:           await this.batchProcessor.addOperation(batch => {
241:             const hashRef = db.collection(COLLECTION.CARD_HASHES).doc(card.productId.toString());
242:             batch.set(hashRef, {
243:               hash: currentHash,
244:               lastUpdated: FieldValue.serverTimestamp(),
245:             }, { merge: true });
246:           });
247: 
248:           // Save delta
249:           await this.batchProcessor.addOperation(batch => {
250:             const deltaRef = db.collection(COLLECTION.CARD_DELTAS).doc();
251:             batch.set(deltaRef, {
252:               productId: card.productId,
253:               changes: cardDoc,
254:               timestamp: FieldValue.serverTimestamp(),
255:             });
256:           });
257: 
258:           this.cache.set(`hash_${card.productId}`, currentHash);
259:           result.updated++;
260: 
261:         } catch (error) {
262:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
263:           result.errors.push(`Error processing card ${card.productId}: ${errorMessage}`);
264:           logger.error(`Error processing card ${card.productId}`, { error: errorMessage });
265:         }
266:       }));
267: 
268:       await this.batchProcessor.commitAll();
269:     } catch (error) {
270:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
271:       result.errors.push(`Batch processing error: ${errorMessage}`);
272:       logger.error("Batch processing error", { error: errorMessage });
273:     }
274: 
275:     return result;
276:   }
277: 
278:   async syncCards(options: SyncOptions = {}): Promise<SyncResult> {
279:   const result: SyncResult = {
280:     success: true,
281:     itemsProcessed: 0,
282:     itemsUpdated: 0,
283:     errors: [],
284:     timing: {
285:       startTime: new Date(),
286:     },
287:   };
288: 
289:   try {
290:     logger.info("Starting card sync", { options });
291: 
292:     const groups = options.groupId ?
293:       [{ groupId: options.groupId }] :
294:       await this.retry.execute(() => tcgcsvApi.getGroups());
295: 
296:     logger.info(`Found ${groups.length} groups to process`);
297: 
298:     for (const group of groups) {
299:       if (this.isApproachingTimeout(result.timing.startTime)) {
300:         logger.warn("Approaching function timeout, stopping processing");
301:         break;
302:       }
303: 
304:       result.timing.groupStartTime = new Date();
305: 
306:       try {
307:         logger.info(`Processing group ${group.groupId}`);
308: 
309:         const cards = await this.retry.execute(() =>
310:           tcgcsvApi.getGroupProducts(group.groupId)
311:         );
312: 
313:         logger.info(`Retrieved ${cards.length} cards for group ${group.groupId}`);
314: 
315:         for (let i = 0; i < cards.length; i += this.CHUNK_SIZE) {
316:           if (this.isApproachingTimeout(result.timing.startTime)) {
317:             logger.warn("Approaching function timeout, stopping chunk processing");
318:             break;
319:           }
320: 
321:           const cardChunk = cards.slice(i, i + this.CHUNK_SIZE);
322:           const batchResults = await this.processCards(cardChunk, group.groupId, options);
323: 
324:           result.itemsProcessed += batchResults.processed;
325:           result.itemsUpdated += batchResults.updated;
326:           result.errors.push(...batchResults.errors);
327:         }
328: 
329:         logger.info(`Completed group ${group.groupId}`, {
330:           processed: result.itemsProcessed,
331:           updated: result.itemsUpdated,
332:           errors: result.errors.length,
333:         });
334: 
335:       } catch (error) {
336:         const errorMessage = error instanceof Error ? error.message : "Unknown error";
337:         result.errors.push(`Error processing group ${group.groupId}: ${errorMessage}`);
338:         logger.error(`Error processing group ${group.groupId}`, { error: errorMessage });
339:       }
340:     }
341: 
342:     result.timing.endTime = new Date();
343:     result.timing.duration =
344:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
345: 
346:     logger.info(`Card sync completed in ${result.timing.duration}s`, {
347:       processed: result.itemsProcessed,
348:       updated: result.itemsUpdated,
349:       errors: result.errors.length,
350:     });
351: 
352:   } catch (error) {
353:     result.success = false;
354:     const errorMessage = error instanceof Error ? error.message : "Unknown error";
355:     result.errors.push(`Card sync failed: ${errorMessage}`);
356:     logger.error("Card sync failed", { error: errorMessage });
357:   }
358: 
359:   return result;
360: }
361: }
362: 
363: export const cardSync = new CardSyncService();
</file>

<file path="src/services/cardSync.ts.txt">
  1: // src/services/cardSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { storageService } from "./storageService";
  5: import { CardProduct, SyncResult, CardHashData, SyncOptions } from "../types";
  6: import { logger } from "../utils/logger";
  7: import { Cache } from "../utils/cache";
  8: import { RetryWithBackoff } from "../utils/retry";
  9: import * as crypto from "crypto";
 10: import { FieldValue } from "firebase-admin/firestore";
 11: import { OptimizedBatchProcessor } from "./batchProcessor";
 12: 
 13: interface SyncState {
 14:   lastProcessedGroup?: string;
 15:   lastProcessedIndex?: number;
 16:   timestamp: Date;
 17: }
 18: 
 19: 
 20: export class CardSyncService {
 21:   private readonly CHUNK_SIZE = 1000;
 22:   private readonly MAX_EXECUTION_TIME = 510; // 8.5 minutes
 23:   
 24:   private readonly cache = new Cache<string>(15);
 25:   private readonly retry = new RetryWithBackoff();
 26:   private readonly batchProcessor: OptimizedBatchProcessor;
 27: 
 28:   constructor() {
 29:     this.batchProcessor = new OptimizedBatchProcessor(db);
 30:   }
 31: 
 32:   private isApproachingTimeout(startTime: Date, safetyMarginSeconds = 30): boolean {
 33:     const executionTime = (new Date().getTime() - startTime.getTime()) / 1000;
 34:     return executionTime > (this.MAX_EXECUTION_TIME - safetyMarginSeconds);
 35:   }
 36: 
 37:   private async saveSyncState(state: SyncState): Promise<void> {
 38:     await db.collection(COLLECTION.SYNC_STATE).doc("cardSync").set({
 39:       ...state,
 40:       timestamp: FieldValue.serverTimestamp(),
 41:     });
 42:   }
 43: 
 44:   private async loadSyncState(): Promise<SyncState | null> {
 45:     const doc = await db.collection(COLLECTION.SYNC_STATE).doc("cardSync").get();
 46:     return doc.exists ? doc.data() as SyncState : null;
 47:   }
 48: 
 49:   private getElements(card: CardProduct): string[] {
 50:     const elementField = card.extendedData.find((data) => data.name === "Element");
 51:     if (!elementField?.value) return [];
 52: 
 53:     const valueStr = String(elementField.value);
 54:     return valueStr
 55:       .split(/[;,]/)
 56:       .map((element: string) => element.trim())
 57:       .filter((element: string) => element.length > 0)
 58:       .map((element: string) => element.charAt(0).toUpperCase() + element.slice(1).toLowerCase());
 59:   }
 60: 
 61:   private getExtendedValue(card: CardProduct, fieldName: string): string | null {
 62:     const field = card.extendedData.find(data => data.name === fieldName);
 63:     return field?.value?.toString() || null;
 64:   }
 65: 
 66:   private normalizeNumericValue(value: string | number | null | undefined): number | null {
 67:     if (value === undefined || value === null || value === "") return null;
 68:     const num = typeof value === "number" ? value : parseFloat(String(value));
 69:     return isNaN(num) ? null : num;
 70:   }
 71: 
 72:   private normalizeName(name: string | number): string {
 73:     const nameStr = String(name);
 74:     return nameStr.charAt(0).toUpperCase() + nameStr.slice(1);
 75:   }
 76: 
 77:   private normalizeCardNumber(number: string): string {
 78:     const clean = number.replace(/[-\s]/g, "");
 79: 
 80:     if (clean.startsWith("PR")) {
 81:       const num = clean.slice(2);
 82:       return `PR-${num}`;
 83:     }
 84: 
 85:     const match = clean.match(/^(\d{1,2})(\d{3}[A-Za-z]?)$/);
 86:     if (match) {
 87:       const [, prefix, rest] = match;
 88:       return `${prefix}-${rest}`;
 89:     }
 90: 
 91:     return clean;
 92:   }
 93: 
 94:   private getCardNumbers(card: CardProduct): string[] {
 95:     const numbers: string[] = [];
 96:     card.extendedData
 97:       .filter((data) => data.name === "Number")
 98:       .forEach((numberField) => {
 99:         const valueStr = String(numberField.value);
100:         const vals = valueStr.split(/[,;/]/).map((n: string) => n.trim());
101:         numbers.push(...vals.map((num: string) => this.normalizeCardNumber(num)));
102:       });
103: 
104:     if (numbers.length === 0) {
105:       numbers.push(this.normalizeCardNumber(`P${card.productId}`));
106:     }
107: 
108:     return [...new Set(numbers)];
109:   }
110: 
111:   private isNonCardProduct(card: CardProduct): boolean {
112:     const cardType = card.extendedData.find((data) => data.name === "CardType")?.value;
113:     return !cardType || String(cardType).toLowerCase() === "sealed product";
114:   }
115: 
116:   private calculateHash(data: CardHashData): string {
117:     return crypto
118:       .createHash("md5")
119:       .update(JSON.stringify(data))
120:       .digest("hex");
121:   }
122: 
123:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
124:     const hashMap = new Map<number, string>();
125:     const uncachedIds: number[] = [];
126: 
127:     productIds.forEach((id) => {
128:       const cacheKey = `hash_${id}`;
129:       const cached = this.cache.get(cacheKey);
130:       if (cached) {
131:         hashMap.set(id, cached);
132:       } else {
133:         uncachedIds.push(id);
134:       }
135:     });
136: 
137:     if (uncachedIds.length === 0) {
138:       return hashMap;
139:     }
140: 
141:     const chunks = [];
142:     for (let i = 0; i < uncachedIds.length; i += 10) {
143:       chunks.push(uncachedIds.slice(i, i + 10));
144:     }
145: 
146:     await Promise.all(chunks.map(async (chunk) => {
147:       const refs = chunk.map((id) =>
148:         db.collection(COLLECTION.CARD_HASHES).doc(id.toString())
149:       );
150: 
151:       const snapshots = await this.retry.execute(() =>
152:         db.getAll(...refs)
153:       );
154: 
155:       snapshots.forEach((snap, index) => {
156:         const id = chunk[index];
157:         const hash = snap.exists ? snap.data()?.hash : null;
158:         if (hash) {
159:           hashMap.set(id, hash);
160:           this.cache.set(`hash_${id}`, hash);
161:         }
162:       });
163:     }));
164: 
165:     return hashMap;
166:   }
167: 
168:   private async processCards(
169:     cards: CardProduct[],
170:     groupId: string,
171:     options: { forceUpdate?: boolean } = {}
172:   ): Promise<{
173:     processed: number;
174:     updated: number;
175:     errors: string[];
176:   }> {
177:     const result = {
178:       processed: 0,
179:       updated: 0,
180:       errors: [] as string[],
181:     };
182: 
183:     try {
184:       const productIds = cards.map((card) => card.productId);
185:       const hashMap = await this.getStoredHashes(productIds);
186: 
187:       await Promise.all(cards.map(async (card) => {
188:         try {
189:           result.processed++;
190: 
191:           const cardNumbers = this.getCardNumbers(card);
192:           const primaryCardNumber = cardNumbers[0];
193: 
194:           const imageResult = await this.retry.execute(() =>
195:             storageService.processAndStoreImage(
196:               card.imageUrl,
197:               card.productId,
198:               groupId,
199:               primaryCardNumber
200:             )
201:           );
202: 
203:           const relevantData: CardHashData = {
204:             name: card.name,
205:             cleanName: card.cleanName,
206:             modifiedOn: card.modifiedOn,
207:             extendedData: card.extendedData,
208:           };
209: 
210:           const currentHash = this.calculateHash(relevantData);
211:           const storedHash = hashMap.get(card.productId);
212: 
213:           if (currentHash === storedHash && !options.forceUpdate) {
214:             return;
215:           }
216: 
217:           const cardDoc = {
218:             productId: card.productId,
219:             name: this.normalizeName(card.name),
220:             cleanName: this.normalizeName(card.cleanName),
221:             fullResUrl: imageResult.fullResUrl,
222:             highResUrl: imageResult.highResUrl,
223:             lowResUrl: imageResult.lowResUrl,
224:             lastUpdated: FieldValue.serverTimestamp(),
225:             groupId: parseInt(groupId),
226:             isNonCard: this.isNonCardProduct(card),
227:             cardNumbers,
228:             primaryCardNumber,
229:             
230:             // Flattened extended data
231:             cardType: this.getExtendedValue(card, "CardType"),
232:             category: this.getExtendedValue(card, "Category"),
233:             cost: this.normalizeNumericValue(this.getExtendedValue(card, "Cost")),
234:             description: this.getExtendedValue(card, "Description"),
235:             elements: this.getElements(card),
236:             job: this.getExtendedValue(card, "Job"),
237:             number: this.getExtendedValue(card, "Number"),
238:             power: this.normalizeNumericValue(this.getExtendedValue(card, "Power")),
239:             rarity: this.getExtendedValue(card, "Rarity"),
240:           };
241: 
242:           // Add main card document
243:           await this.batchProcessor.addOperation(batch => {
244:             const cardRef = db.collection(COLLECTION.CARDS).doc(card.productId.toString());
245:             batch.set(cardRef, cardDoc, { merge: true });
246:           });
247: 
248:           // Add image metadata
249:           await this.batchProcessor.addOperation(batch => {
250:             const cardRef = db.collection(COLLECTION.CARDS).doc(card.productId.toString());
251:             batch.set(
252:               cardRef.collection("metadata").doc("image"),
253:               imageResult.metadata,
254:               { merge: true }
255:             );
256:           });
257: 
258:           // Update hash
259:           await this.batchProcessor.addOperation(batch => {
260:             const hashRef = db.collection(COLLECTION.CARD_HASHES).doc(card.productId.toString());
261:             batch.set(hashRef, {
262:               hash: currentHash,
263:               lastUpdated: FieldValue.serverTimestamp(),
264:             }, { merge: true });
265:           });
266: 
267:           // Save delta
268:           await this.batchProcessor.addOperation(batch => {
269:             const deltaRef = db.collection(COLLECTION.CARD_DELTAS).doc();
270:             batch.set(deltaRef, {
271:               productId: card.productId,
272:               changes: cardDoc,
273:               timestamp: FieldValue.serverTimestamp(),
274:             });
275:           });
276: 
277:           this.cache.set(`hash_${card.productId}`, currentHash);
278:           result.updated++;
279: 
280:         } catch (error) {
281:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
282:           result.errors.push(`Error processing card ${card.productId}: ${errorMessage}`);
283:           logger.error(`Error processing card ${card.productId}`, { error: errorMessage });
284:         }
285:       }));
286: 
287:       await this.batchProcessor.commitAll();
288:     } catch (error) {
289:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
290:       result.errors.push(`Batch processing error: ${errorMessage}`);
291:       logger.error("Batch processing error", { error: errorMessage });
292:     }
293: 
294:     return result;
295:   }
296: 
297:   async syncCards(options: SyncOptions = {}): Promise<SyncResult> {
298:   const result: SyncResult = {
299:     success: true,
300:     itemsProcessed: 0,
301:     itemsUpdated: 0,
302:     errors: [],
303:     timing: {
304:       startTime: new Date(),
305:     },
306:   };
307: 
308:   try {
309:     logger.info("Starting card sync", { options });
310: 
311:     const previousState = await this.loadSyncState();
312:     const groups = options.groupId ?
313:       [{ groupId: options.groupId }] :
314:       await this.retry.execute(() => tcgcsvApi.getGroups());
315: 
316:     logger.info(`Found ${groups.length} groups to process`);
317: 
318:     let startIndex = 0;
319:     if (previousState?.lastProcessedGroup && !options.groupId) {
320:       const lastGroupIndex = groups.findIndex((g) => g.groupId === previousState.lastProcessedGroup);
321:       if (lastGroupIndex !== -1) {
322:         startIndex = lastGroupIndex + 1;
323:       }
324:     }
325: 
326:     for (let groupIndex = startIndex; groupIndex < groups.length; groupIndex++) {
327:       if (this.isApproachingTimeout(result.timing.startTime)) {
328:         logger.warn("Approaching function timeout, stopping processing");
329:         break;
330:       }
331: 
332:       const group = groups[groupIndex];
333:       result.timing.groupStartTime = new Date();
334: 
335:       try {
336:         logger.info(`Processing group ${group.groupId}`); // Added logging
337: 
338:         const cards = await this.retry.execute(() =>
339:           tcgcsvApi.getGroupProducts(group.groupId)
340:         );
341: 
342:         logger.info(`Retrieved ${cards.length} cards for group ${group.groupId}`); // Added logging
343: 
344:         for (let i = 0; i < cards.length; i += this.CHUNK_SIZE) {
345:           if (this.isApproachingTimeout(result.timing.startTime)) {
346:             logger.warn("Approaching function timeout, stopping chunk processing");
347:             await this.saveSyncState({
348:               lastProcessedGroup: group.groupId,
349:               lastProcessedIndex: i,
350:               timestamp: new Date(),
351:             });
352:             break;
353:           }
354: 
355:           const cardChunk = cards.slice(i, i + this.CHUNK_SIZE);
356:           const batchResults = await this.processCards(cardChunk, group.groupId, options);
357: 
358:           result.itemsProcessed += batchResults.processed;
359:           result.itemsUpdated += batchResults.updated;
360:           result.errors.push(...batchResults.errors);
361:         }
362: 
363:         await this.saveSyncState({
364:           lastProcessedGroup: group.groupId,
365:           timestamp: new Date(),
366:         });
367: 
368:         logger.info(`Completed group ${group.groupId}`, {
369:           processed: result.itemsProcessed,
370:           updated: result.itemsUpdated,
371:           errors: result.errors.length,
372:         });
373: 
374:       } catch (error) {
375:         const errorMessage = error instanceof Error ? error.message : "Unknown error";
376:         result.errors.push(`Error processing group ${group.groupId}: ${errorMessage}`);
377:         logger.error(`Error processing group ${group.groupId}`, { error: errorMessage });
378:       }
379:     }
380: 
381:     result.timing.endTime = new Date();
382:     result.timing.duration =
383:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
384: 
385:     logger.info(`Card sync completed in ${result.timing.duration}s`, {
386:       processed: result.itemsProcessed,
387:       updated: result.itemsUpdated,
388:       errors: result.errors.length,
389:     });
390: 
391:   } catch (error) {
392:     result.success = false;
393:     const errorMessage = error instanceof Error ? error.message : "Unknown error";
394:     result.errors.push(`Card sync failed: ${errorMessage}`);
395:     logger.error("Card sync failed", { error: errorMessage });
396:   }
397: 
398:   return result;
399: }
400: }
401: 
402: export const cardSync = new CardSyncService();
</file>

<file path="src/services/groupSync.ts">
  1: // src/services/groupSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { logger } from "../utils/logger";
  5: import { RateLimiter } from "../utils/rateLimiter";
  6: import { Cache } from "../utils/cache";
  7: import { RetryWithBackoff } from "../utils/retry";
  8: import * as crypto from "crypto";
  9: import { FieldValue } from "firebase-admin/firestore";
 10: 
 11: interface Group {
 12:   groupId: number;
 13:   name: string;
 14:   abbreviation: string;
 15:   publishedOn: string;
 16:   modifiedOn: string;
 17: }
 18: 
 19: interface GroupHashData {
 20:   groupId: number;
 21:   modifiedOn: string;
 22: }
 23: 
 24: interface SyncResult {
 25:   success: boolean;
 26:   itemsProcessed: number;
 27:   itemsUpdated: number;
 28:   errors: string[];
 29:   timing: {
 30:     startTime: Date;
 31:     endTime?: Date;
 32:     duration?: number;
 33:   };
 34: }
 35: 
 36: export class GroupSyncService {
 37:   private readonly BATCH_SIZE = 500;
 38:   private readonly rateLimiter = new RateLimiter();
 39:   private readonly cache = new Cache<string>(15);
 40:   private readonly retry = new RetryWithBackoff();
 41: 
 42:   private calculateHash(data: GroupHashData): string {
 43:     return crypto
 44:       .createHash("md5")
 45:       .update(JSON.stringify(data))
 46:       .digest("hex");
 47:   }
 48: 
 49:   private async getStoredHashes(groupIds: number[]): Promise<Map<number, string>> {
 50:     const hashMap = new Map<number, string>();
 51:     const uncachedIds: number[] = [];
 52: 
 53:     // Check cache first
 54:     groupIds.forEach((id) => {
 55:       const cacheKey = `group_hash_${id}`;
 56:       const cached = this.cache.get(cacheKey);
 57:       if (cached) {
 58:         hashMap.set(id, cached);
 59:       } else {
 60:         uncachedIds.push(id);
 61:       }
 62:     });
 63: 
 64:     if (uncachedIds.length === 0) {
 65:       return hashMap;
 66:     }
 67: 
 68:     // Batch get uncached hashes
 69:     const chunks = [];
 70:     for (let i = 0; i < uncachedIds.length; i += 10) {
 71:       chunks.push(uncachedIds.slice(i, i + 10));
 72:     }
 73: 
 74:     await Promise.all(
 75:       chunks.map(async (chunk) => {
 76:         const refs = chunk.map((id) =>
 77:           db.collection("groupHashes").doc(id.toString())
 78:         );
 79: 
 80:         const snapshots = await this.retry.execute(() => db.getAll(...refs));
 81: 
 82:         snapshots.forEach((snap, index) => {
 83:           const id = chunk[index];
 84:           const hash = snap.exists ? snap.data()?.hash : null;
 85:           if (hash) {
 86:             hashMap.set(id, hash);
 87:             this.cache.set(`group_hash_${id}`, hash);
 88:           }
 89:         });
 90:       })
 91:     );
 92: 
 93:     return hashMap;
 94:   }
 95: 
 96:   private async processGroupBatch(
 97:     groups: Group[],
 98:     options: { forceUpdate?: boolean } = {}
 99:   ): Promise<{
100:     processed: number;
101:     updated: number;
102:     errors: string[];
103:   }> {
104:     const result = {
105:       processed: 0,
106:       updated: 0,
107:       errors: [] as string[],
108:     };
109: 
110:     try {
111:       // Pre-fetch all hashes in one go
112:       const groupIds = groups.map((group) => group.groupId);
113:       const hashMap = await this.getStoredHashes(groupIds);
114: 
115:       let batch = db.batch();
116:       let batchCount = 0;
117: 
118:       for (const group of groups) {
119:         try {
120:           result.processed++;
121: 
122:           const hashData: GroupHashData = {
123:             groupId: group.groupId,
124:             modifiedOn: group.modifiedOn,
125:           };
126: 
127:           const currentHash = this.calculateHash(hashData);
128:           const storedHash = hashMap.get(group.groupId);
129: 
130:           if (currentHash === storedHash && !options.forceUpdate) {
131:             logger.info(`Skipping group ${group.groupId} - no changes`);
132:             continue;
133:           }
134: 
135:           // Prepare group document
136:           const groupDoc = {
137:             groupId: group.groupId,
138:             name: group.name,
139:             abbreviation: group.abbreviation,
140:             publishedOn: group.publishedOn,
141:             modifiedOn: group.modifiedOn,
142:             lastUpdated: FieldValue.serverTimestamp(),
143:           };
144: 
145:           // Add to batch
146:           const groupRef = db.collection(COLLECTION.GROUPS).doc(group.groupId.toString());
147:           batch.set(groupRef, groupDoc, { merge: true });
148:           batchCount++;
149: 
150:           // Update hash
151:           const hashRef = db.collection(COLLECTION.GROUP_HASHES).doc(group.groupId.toString());
152:           batch.set(
153:             hashRef,
154:             {
155:               hash: currentHash,
156:               lastUpdated: FieldValue.serverTimestamp(),
157:             },
158:             { merge: true }
159:           );
160:           batchCount++;
161: 
162:           // Update cache
163:           this.cache.set(`group_hash_${group.groupId}`, currentHash);
164: 
165:           // Commit batch if reaching limit
166:           if (batchCount >= this.BATCH_SIZE) {
167:             await this.rateLimiter.add(() =>
168:               this.retry.execute(() => batch.commit())
169:             );
170:             batch = db.batch();
171:             batchCount = 0;
172:           }
173: 
174:           result.updated++;
175:           logger.info(`Updated group ${group.groupId}: ${group.name}`);
176:         } catch (error) {
177:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
178:           result.errors.push(
179:             `Error processing group ${group.groupId}: ${errorMessage}`
180:           );
181:         }
182:       }
183: 
184:       // Commit any remaining operations
185:       if (batchCount > 0) {
186:         await this.rateLimiter.add(() =>
187:           this.retry.execute(() => batch.commit())
188:         );
189:       }
190:     } catch (error) {
191:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
192:       result.errors.push(`Batch processing error: ${errorMessage}`);
193:     }
194: 
195:     return result;
196:   }
197: 
198:   async syncGroups(options: {
199:     forceUpdate?: boolean;
200:   } = {}): Promise<SyncResult> {
201:     const result: SyncResult = {
202:       success: true,
203:       itemsProcessed: 0,
204:       itemsUpdated: 0,
205:       errors: [],
206:       timing: {
207:         startTime: new Date(),
208:       },
209:     };
210: 
211:     try {
212:       logger.info("Starting group sync", { options });
213: 
214:       const groups = await tcgcsvApi.getGroups();
215:       logger.info(`Found ${groups.length} groups to process`);
216: 
217:       const batchResults = await this.processGroupBatch(
218:         groups as unknown as Group[],
219:         options
220:       );
221: 
222:       result.itemsProcessed = batchResults.processed;
223:       result.itemsUpdated = batchResults.updated;
224:       result.errors.push(...batchResults.errors);
225:     } catch (error) {
226:       result.success = false;
227:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
228:       result.errors.push(`Group sync failed: ${errorMessage}`);
229:       logger.error("Group sync failed", { error: errorMessage });
230:     }
231: 
232:     // Calculate final timing
233:     result.timing.endTime = new Date();
234:     result.timing.duration =
235:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
236: 
237:     logger.info(`Group sync completed in ${result.timing.duration}s`, {
238:       processed: result.itemsProcessed,
239:       updated: result.itemsUpdated,
240:       errors: result.errors.length,
241:       timing: result.timing,
242:     });
243: 
244:     return result;
245:   }
246: }
247: 
248: export const groupSync = new GroupSyncService();
</file>

<file path="src/services/groupSync.ts.txt">
  1: // src/services/groupSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { logger } from "../utils/logger";
  5: import { RateLimiter } from "../utils/rateLimiter";
  6: import { Cache } from "../utils/cache";
  7: import { RetryWithBackoff } from "../utils/retry";
  8: import * as crypto from "crypto";
  9: import { FieldValue } from "firebase-admin/firestore";
 10: 
 11: interface Group {
 12:   groupId: number;
 13:   name: string;
 14:   abbreviation: string;
 15:   publishedOn: string;
 16:   modifiedOn: string;
 17: }
 18: 
 19: interface GroupHashData {
 20:   groupId: number;
 21:   modifiedOn: string;
 22: }
 23: 
 24: interface SyncResult {
 25:   success: boolean;
 26:   itemsProcessed: number;
 27:   itemsUpdated: number;
 28:   errors: string[];
 29:   timing: {
 30:     startTime: Date;
 31:     endTime?: Date;
 32:     duration?: number;
 33:   };
 34: }
 35: 
 36: export class GroupSyncService {
 37:   private readonly BATCH_SIZE = 500;
 38:   private readonly rateLimiter = new RateLimiter();
 39:   private readonly cache = new Cache<string>(15);
 40:   private readonly retry = new RetryWithBackoff();
 41: 
 42:   private calculateHash(data: GroupHashData): string {
 43:     return crypto
 44:       .createHash("md5")
 45:       .update(JSON.stringify(data))
 46:       .digest("hex");
 47:   }
 48: 
 49:   private async getStoredHashes(groupIds: number[]): Promise<Map<number, string>> {
 50:     const hashMap = new Map<number, string>();
 51:     const uncachedIds: number[] = [];
 52: 
 53:     // Check cache first
 54:     groupIds.forEach((id) => {
 55:       const cacheKey = `group_hash_${id}`;
 56:       const cached = this.cache.get(cacheKey);
 57:       if (cached) {
 58:         hashMap.set(id, cached);
 59:       } else {
 60:         uncachedIds.push(id);
 61:       }
 62:     });
 63: 
 64:     if (uncachedIds.length === 0) {
 65:       return hashMap;
 66:     }
 67: 
 68:     // Batch get uncached hashes
 69:     const chunks = [];
 70:     for (let i = 0; i < uncachedIds.length; i += 10) {
 71:       chunks.push(uncachedIds.slice(i, i + 10));
 72:     }
 73: 
 74:     await Promise.all(
 75:       chunks.map(async (chunk) => {
 76:         const refs = chunk.map((id) =>
 77:           db.collection("groupHashes").doc(id.toString())
 78:         );
 79: 
 80:         const snapshots = await this.retry.execute(() => db.getAll(...refs));
 81: 
 82:         snapshots.forEach((snap, index) => {
 83:           const id = chunk[index];
 84:           const hash = snap.exists ? snap.data()?.hash : null;
 85:           if (hash) {
 86:             hashMap.set(id, hash);
 87:             this.cache.set(`group_hash_${id}`, hash);
 88:           }
 89:         });
 90:       })
 91:     );
 92: 
 93:     return hashMap;
 94:   }
 95: 
 96:   private async processGroupBatch(
 97:     groups: Group[],
 98:     options: { forceUpdate?: boolean } = {}
 99:   ): Promise<{
100:     processed: number;
101:     updated: number;
102:     errors: string[];
103:   }> {
104:     const result = {
105:       processed: 0,
106:       updated: 0,
107:       errors: [] as string[],
108:     };
109: 
110:     try {
111:       // Pre-fetch all hashes in one go
112:       const groupIds = groups.map((group) => group.groupId);
113:       const hashMap = await this.getStoredHashes(groupIds);
114: 
115:       let batch = db.batch();
116:       let batchCount = 0;
117: 
118:       for (const group of groups) {
119:         try {
120:           result.processed++;
121: 
122:           const hashData: GroupHashData = {
123:             groupId: group.groupId,
124:             modifiedOn: group.modifiedOn,
125:           };
126: 
127:           const currentHash = this.calculateHash(hashData);
128:           const storedHash = hashMap.get(group.groupId);
129: 
130:           if (currentHash === storedHash && !options.forceUpdate) {
131:             logger.info(`Skipping group ${group.groupId} - no changes`);
132:             continue;
133:           }
134: 
135:           // Prepare group document
136:           const groupDoc = {
137:             groupId: group.groupId,
138:             name: group.name,
139:             abbreviation: group.abbreviation,
140:             publishedOn: group.publishedOn,
141:             modifiedOn: group.modifiedOn,
142:             lastUpdated: FieldValue.serverTimestamp(),
143:           };
144: 
145:           // Add to batch
146:           const groupRef = db.collection(COLLECTION.GROUPS).doc(group.groupId.toString());
147:           batch.set(groupRef, groupDoc, { merge: true });
148:           batchCount++;
149: 
150:           // Update hash
151:           const hashRef = db.collection(COLLECTION.GROUP_HASHES).doc(group.groupId.toString());
152:           batch.set(
153:             hashRef,
154:             {
155:               hash: currentHash,
156:               lastUpdated: FieldValue.serverTimestamp(),
157:             },
158:             { merge: true }
159:           );
160:           batchCount++;
161: 
162:           // Update cache
163:           this.cache.set(`group_hash_${group.groupId}`, currentHash);
164: 
165:           // Commit batch if reaching limit
166:           if (batchCount >= this.BATCH_SIZE) {
167:             await this.rateLimiter.add(() =>
168:               this.retry.execute(() => batch.commit())
169:             );
170:             batch = db.batch();
171:             batchCount = 0;
172:           }
173: 
174:           result.updated++;
175:           logger.info(`Updated group ${group.groupId}: ${group.name}`);
176:         } catch (error) {
177:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
178:           result.errors.push(
179:             `Error processing group ${group.groupId}: ${errorMessage}`
180:           );
181:         }
182:       }
183: 
184:       // Commit any remaining operations
185:       if (batchCount > 0) {
186:         await this.rateLimiter.add(() =>
187:           this.retry.execute(() => batch.commit())
188:         );
189:       }
190:     } catch (error) {
191:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
192:       result.errors.push(`Batch processing error: ${errorMessage}`);
193:     }
194: 
195:     return result;
196:   }
197: 
198:   async syncGroups(options: {
199:     forceUpdate?: boolean;
200:   } = {}): Promise<SyncResult> {
201:     const result: SyncResult = {
202:       success: true,
203:       itemsProcessed: 0,
204:       itemsUpdated: 0,
205:       errors: [],
206:       timing: {
207:         startTime: new Date(),
208:       },
209:     };
210: 
211:     try {
212:       logger.info("Starting group sync", { options });
213: 
214:       const groups = await tcgcsvApi.getGroups();
215:       logger.info(`Found ${groups.length} groups to process`);
216: 
217:       const batchResults = await this.processGroupBatch(
218:         groups as unknown as Group[],
219:         options
220:       );
221: 
222:       result.itemsProcessed = batchResults.processed;
223:       result.itemsUpdated = batchResults.updated;
224:       result.errors.push(...batchResults.errors);
225:     } catch (error) {
226:       result.success = false;
227:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
228:       result.errors.push(`Group sync failed: ${errorMessage}`);
229:       logger.error("Group sync failed", { error: errorMessage });
230:     }
231: 
232:     // Calculate final timing
233:     result.timing.endTime = new Date();
234:     result.timing.duration =
235:       (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
236: 
237:     logger.info(`Group sync completed in ${result.timing.duration}s`, {
238:       processed: result.itemsProcessed,
239:       updated: result.itemsUpdated,
240:       errors: result.errors.length,
241:       timing: result.timing,
242:     });
243: 
244:     return result;
245:   }
246: }
247: 
248: export const groupSync = new GroupSyncService();
</file>

<file path="src/services/priceSync.ts">
  1: // src/services/priceSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { CardPrice, SyncResult, SyncOptions } from "../types";
  5: import { logger } from "../utils/logger";
  6: import { Cache } from "../utils/cache";
  7: import { RetryWithBackoff } from "../utils/retry";
  8: import * as crypto from "crypto";
  9: import { FieldValue } from "firebase-admin/firestore";
 10: import { OptimizedBatchProcessor } from "./batchProcessor";
 11: 
 12: export class PriceSyncService {
 13:   private readonly CHUNK_SIZE = 2000;
 14:   private readonly MAX_EXECUTION_TIME = 510; // 8.5 minutes
 15:   
 16:   private readonly cache = new Cache<string>(15);
 17:   private readonly retry = new RetryWithBackoff();
 18:   private readonly batchProcessor: OptimizedBatchProcessor;
 19: 
 20:   constructor() {
 21:     this.batchProcessor = new OptimizedBatchProcessor(db);
 22:   }
 23: 
 24:   private isApproachingTimeout(startTime: Date, safetyMarginSeconds = 30): boolean {
 25:     const executionTime = (new Date().getTime() - startTime.getTime()) / 1000;
 26:     return executionTime > (this.MAX_EXECUTION_TIME - safetyMarginSeconds);
 27:   }
 28: 
 29:   private calculateHash(price: CardPrice): string {
 30:     const relevantData = {
 31:       normal: price.normal,
 32:       foil: price.foil,
 33:       lastUpdated: price.lastUpdated,
 34:     };
 35:     return crypto.createHash("md5").update(JSON.stringify(relevantData)).digest("hex");
 36:   }
 37: 
 38:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 39:     const hashMap = new Map<number, string>();
 40:     const uncachedIds: number[] = [];
 41: 
 42:     productIds.forEach((id) => {
 43:       const cacheKey = `price_hash_${id}`;
 44:       const cached = this.cache.get(cacheKey);
 45:       if (cached) {
 46:         hashMap.set(id, cached);
 47:       } else {
 48:         uncachedIds.push(id);
 49:       }
 50:     });
 51: 
 52:     if (uncachedIds.length === 0) {
 53:       return hashMap;
 54:     }
 55: 
 56:     const chunks = [];
 57:     for (let i = 0; i < uncachedIds.length; i += 10) {
 58:       chunks.push(uncachedIds.slice(i, i + 10));
 59:     }
 60: 
 61:     await Promise.all(chunks.map(async (chunk) => {
 62:       const refs = chunk.map((id) =>
 63:         db.collection(COLLECTION.PRICE_HASHES).doc(id.toString())
 64:       );
 65: 
 66:       const snapshots = await this.retry.execute(() =>
 67:         db.getAll(...refs)
 68:       );
 69: 
 70:       snapshots.forEach((snap, index) => {
 71:         const id = chunk[index];
 72:         const hash = snap.exists ? snap.data()?.hash : null;
 73:         if (hash) {
 74:           hashMap.set(id, hash);
 75:           this.cache.set(`price_hash_${id}`, hash);
 76:         }
 77:       });
 78:     }));
 79: 
 80:     return hashMap;
 81:   }
 82: 
 83:   private normalizePriceValue(value: number | null): number | null {
 84:     if (value === null || value === undefined) return null;
 85:     return Math.round(parseFloat(value.toString()) * 100);
 86:   }
 87: 
 88:   private validatePriceData(data: {
 89:     directLowPrice: number | null;
 90:     highPrice: number;
 91:     lowPrice: number;
 92:     marketPrice: number;
 93:     midPrice: number;
 94:   } | null | undefined): boolean {
 95:     if (!data) return false;
 96:     
 97:     return (
 98:       Number.isInteger(this.normalizePriceValue(data.marketPrice)) &&
 99:       Number.isInteger(this.normalizePriceValue(data.lowPrice)) &&
100:       Number.isInteger(this.normalizePriceValue(data.highPrice)) &&
101:       Number.isInteger(this.normalizePriceValue(data.midPrice)) &&
102:       (data.directLowPrice === null || Number.isInteger(this.normalizePriceValue(data.directLowPrice)))
103:     );
104:   }
105: 
106:   private validatePrice(price: CardPrice): boolean {
107:     return this.validatePriceData(price.normal) || this.validatePriceData(price.foil);
108:   }
109: 
110:   private normalizePrice(price: CardPrice): CardPrice {
111:     const normalized: CardPrice = {
112:       productId: price.productId,
113:       lastUpdated: price.lastUpdated,
114:     };
115: 
116:     if (price.normal) {
117:       normalized.normal = {
118:         directLowPrice: this.normalizePriceValue(price.normal.directLowPrice),
119:         highPrice: this.normalizePriceValue(price.normal.highPrice) || 0,
120:         lowPrice: this.normalizePriceValue(price.normal.lowPrice) || 0,
121:         marketPrice: this.normalizePriceValue(price.normal.marketPrice) || 0,
122:         midPrice: this.normalizePriceValue(price.normal.midPrice) || 0,
123:         subTypeName: "Normal",
124:       };
125:     }
126: 
127:     if (price.foil) {
128:       normalized.foil = {
129:         directLowPrice: this.normalizePriceValue(price.foil.directLowPrice),
130:         highPrice: this.normalizePriceValue(price.foil.highPrice) || 0,
131:         lowPrice: this.normalizePriceValue(price.foil.lowPrice) || 0,
132:         marketPrice: this.normalizePriceValue(price.foil.marketPrice) || 0,
133:         midPrice: this.normalizePriceValue(price.foil.midPrice) || 0,
134:         subTypeName: "Foil",
135:       };
136:     }
137: 
138:     return normalized;
139:   }
140: 
141:   private async processPrices(
142:     prices: CardPrice[],
143:     groupId: string,
144:     options: { forceUpdate?: boolean } = {}
145:   ): Promise<{
146:     processed: number;
147:     updated: number;
148:     errors: string[];
149:   }> {
150:     const result = {
151:       processed: 0,
152:       updated: 0,
153:       errors: [] as string[],
154:     };
155: 
156:     try {
157:       const productIds = prices.map((price) => price.productId);
158:       const hashMap = await this.getStoredHashes(productIds);
159:       const today = new Date();
160:       today.setHours(0, 0, 0, 0);
161: 
162:       await Promise.all(prices.map(async (price) => {
163:         try {
164:           result.processed++;
165: 
166:           const normalizedPrice = this.normalizePrice(price);
167:           if (!this.validatePrice(normalizedPrice)) {
168:             return;
169:           }
170: 
171:           const currentHash = this.calculateHash(normalizedPrice);
172:           const storedHash = hashMap.get(price.productId);
173: 
174:           if (currentHash === storedHash && !options.forceUpdate) {
175:             return;
176:           }
177: 
178:           const priceDoc = {
179:             productId: normalizedPrice.productId,
180:             lastUpdated: FieldValue.serverTimestamp(),
181:             groupId: parseInt(groupId),
182:             ...(normalizedPrice.normal && { normal: normalizedPrice.normal }),
183:             ...(normalizedPrice.foil && { foil: normalizedPrice.foil }),
184:           };
185: 
186:           const historicalDoc = {
187:             productId: normalizedPrice.productId,
188:             groupId,
189:             date: today,
190:             timestamp: FieldValue.serverTimestamp(),
191:             ...(normalizedPrice.normal && {
192:               normal: {
193:                 directLow: normalizedPrice.normal.directLowPrice,
194:                 high: normalizedPrice.normal.highPrice,
195:                 low: normalizedPrice.normal.lowPrice,
196:                 market: normalizedPrice.normal.marketPrice,
197:                 mid: normalizedPrice.normal.midPrice,
198:               },
199:             }),
200:             ...(normalizedPrice.foil && {
201:               foil: {
202:                 directLow: normalizedPrice.foil.directLowPrice,
203:                 high: normalizedPrice.foil.highPrice,
204:                 low: normalizedPrice.foil.lowPrice,
205:                 market: normalizedPrice.foil.marketPrice,
206:                 mid: normalizedPrice.foil.midPrice,
207:               },
208:             }),
209:           };
210: 
211:           // Add main price document
212:           await this.batchProcessor.addOperation(batch => {
213:             const priceRef = db.collection(COLLECTION.PRICES).doc(price.productId.toString());
214:             batch.set(priceRef, priceDoc, { merge: true });
215:           });
216: 
217:           // Add hash document
218:           await this.batchProcessor.addOperation(batch => {
219:             const hashRef = db.collection(COLLECTION.PRICE_HASHES).doc(price.productId.toString());
220:             batch.set(hashRef, {
221:               hash: currentHash,
222:               lastUpdated: FieldValue.serverTimestamp(),
223:             }, { merge: true });
224:           });
225: 
226:           // Add historical price document
227:           await this.batchProcessor.addOperation(batch => {
228:             const docId = `${price.productId}_${today.toISOString().split("T")[0]}`;
229:             const historicalRef = db.collection(COLLECTION.HISTORICAL_PRICES).doc(docId);
230:             batch.set(historicalRef, historicalDoc, { merge: true });
231:           });
232: 
233:           this.cache.set(`price_hash_${price.productId}`, currentHash);
234:           result.updated++;
235: 
236:         } catch (error) {
237:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
238:           result.errors.push(`Error processing price for product ${price.productId}: ${errorMessage}`);
239:           logger.error(`Error processing price for product ${price.productId}`, { error: errorMessage });
240:         }
241:       }));
242: 
243:       await this.batchProcessor.commitAll();
244:     } catch (error) {
245:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
246:       result.errors.push(`Batch processing error: ${errorMessage}`);
247:       logger.error("Batch processing error", { error: errorMessage });
248:     }
249: 
250:     return result;
251:   }
252: 
253:   async syncPrices(options: SyncOptions = {}): Promise<SyncResult> {
254:     const result: SyncResult = {
255:       success: true,
256:       itemsProcessed: 0,
257:       itemsUpdated: 0,
258:       errors: [],
259:       timing: {
260:         startTime: new Date(),
261:       },
262:     };
263: 
264:     try {
265:       logger.info("Starting price sync", { options });
266: 
267:       const groups = options.groupId ?
268:         [{ groupId: options.groupId }] :
269:         await this.retry.execute(() => tcgcsvApi.getGroups());
270: 
271:       logger.info(`Found ${groups.length} groups to process`);
272: 
273:       for (const group of groups) {
274:         if (this.isApproachingTimeout(result.timing.startTime)) {
275:           logger.warn("Approaching function timeout, stopping processing");
276:           break;
277:         }
278: 
279:         result.timing.groupStartTime = new Date();
280: 
281:         try {
282:           const prices = await this.retry.execute(() =>
283:             tcgcsvApi.getGroupPrices(group.groupId)
284:           );
285: 
286:           logger.info(`Processing ${prices.length} prices for group ${group.groupId}`);
287: 
288:           for (let i = 0; i < prices.length; i += this.CHUNK_SIZE) {
289:             if (this.isApproachingTimeout(result.timing.startTime)) {
290:               logger.warn("Approaching function timeout, stopping chunk processing");
291:               break;
292:             }
293: 
294:             const priceChunk = prices.slice(i, i + this.CHUNK_SIZE);
295:             const batchResults = await this.processPrices(
296:               priceChunk,
297:               group.groupId,
298:               options
299:             );
300: 
301:             result.itemsProcessed += batchResults.processed;
302:             result.itemsUpdated += batchResults.updated;
303:             result.errors.push(...batchResults.errors);
304:           }
305: 
306:           logger.info(`Completed group ${group.groupId}`, {
307:             processed: result.itemsProcessed,
308:             updated: result.itemsUpdated,
309:             errors: result.errors.length,
310:           });
311: 
312:         } catch (error) {
313:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
314:           result.errors.push(`Error processing prices for group ${
315:           group.groupId}: ${errorMessage}`);
316:           logger.error(`Error processing prices for group ${group.groupId}`, {
317:             error: errorMessage,
318:           });
319:         }
320:       }
321: 
322:       result.timing.endTime = new Date();
323:       result.timing.duration =
324:         (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
325: 
326:       logger.info(`Price sync completed in ${result.timing.duration}s`, {
327:         processed: result.itemsProcessed,
328:         updated: result.itemsUpdated,
329:         errors: result.errors.length,
330:         timing: result.timing,
331:       });
332: 
333:     } catch (error) {
334:       result.success = false;
335:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
336:       result.errors.push(`Price sync failed: ${errorMessage}`);
337:       logger.error("Price sync failed", { error: errorMessage });
338:     }
339: 
340:     return result;
341:   }
342: }
343: 
344: export const priceSync = new PriceSyncService();
</file>

<file path="src/services/priceSync.ts.txt">
  1: // src/services/priceSync.ts
  2: import { db, COLLECTION } from "../config/firebase";
  3: import { tcgcsvApi } from "../utils/api";
  4: import { CardPrice, SyncResult, SyncOptions } from "../types";
  5: import { logger } from "../utils/logger";
  6: import { Cache } from "../utils/cache";
  7: import { RetryWithBackoff } from "../utils/retry";
  8: import * as crypto from "crypto";
  9: import { FieldValue } from "firebase-admin/firestore";
 10: import { OptimizedBatchProcessor } from "./batchProcessor";
 11: 
 12: export class PriceSyncService {
 13:   private readonly CHUNK_SIZE = 2000;
 14:   private readonly MAX_EXECUTION_TIME = 510; // 8.5 minutes
 15:   
 16:   private readonly cache = new Cache<string>(15);
 17:   private readonly retry = new RetryWithBackoff();
 18:   private readonly batchProcessor: OptimizedBatchProcessor;
 19: 
 20:   constructor() {
 21:     this.batchProcessor = new OptimizedBatchProcessor(db);
 22:   }
 23: 
 24:   private isApproachingTimeout(startTime: Date, safetyMarginSeconds = 30): boolean {
 25:     const executionTime = (new Date().getTime() - startTime.getTime()) / 1000;
 26:     return executionTime > (this.MAX_EXECUTION_TIME - safetyMarginSeconds);
 27:   }
 28: 
 29:   private calculateHash(price: CardPrice): string {
 30:     const relevantData = {
 31:       normal: price.normal,
 32:       foil: price.foil,
 33:       lastUpdated: price.lastUpdated,
 34:     };
 35:     return crypto.createHash("md5").update(JSON.stringify(relevantData)).digest("hex");
 36:   }
 37: 
 38:   private async getStoredHashes(productIds: number[]): Promise<Map<number, string>> {
 39:     const hashMap = new Map<number, string>();
 40:     const uncachedIds: number[] = [];
 41: 
 42:     productIds.forEach((id) => {
 43:       const cacheKey = `price_hash_${id}`;
 44:       const cached = this.cache.get(cacheKey);
 45:       if (cached) {
 46:         hashMap.set(id, cached);
 47:       } else {
 48:         uncachedIds.push(id);
 49:       }
 50:     });
 51: 
 52:     if (uncachedIds.length === 0) {
 53:       return hashMap;
 54:     }
 55: 
 56:     const chunks = [];
 57:     for (let i = 0; i < uncachedIds.length; i += 10) {
 58:       chunks.push(uncachedIds.slice(i, i + 10));
 59:     }
 60: 
 61:     await Promise.all(chunks.map(async (chunk) => {
 62:       const refs = chunk.map((id) =>
 63:         db.collection(COLLECTION.PRICE_HASHES).doc(id.toString())
 64:       );
 65: 
 66:       const snapshots = await this.retry.execute(() =>
 67:         db.getAll(...refs)
 68:       );
 69: 
 70:       snapshots.forEach((snap, index) => {
 71:         const id = chunk[index];
 72:         const hash = snap.exists ? snap.data()?.hash : null;
 73:         if (hash) {
 74:           hashMap.set(id, hash);
 75:           this.cache.set(`price_hash_${id}`, hash);
 76:         }
 77:       });
 78:     }));
 79: 
 80:     return hashMap;
 81:   }
 82: 
 83:   private normalizePriceValue(value: number | null): number | null {
 84:     if (value === null || value === undefined) return null;
 85:     return Math.round(parseFloat(value.toString()) * 100);
 86:   }
 87: 
 88:   private validatePriceData(data: {
 89:     directLowPrice: number | null;
 90:     highPrice: number;
 91:     lowPrice: number;
 92:     marketPrice: number;
 93:     midPrice: number;
 94:   } | null | undefined): boolean {
 95:     if (!data) return false;
 96:     
 97:     return (
 98:       Number.isInteger(this.normalizePriceValue(data.marketPrice)) &&
 99:       Number.isInteger(this.normalizePriceValue(data.lowPrice)) &&
100:       Number.isInteger(this.normalizePriceValue(data.highPrice)) &&
101:       Number.isInteger(this.normalizePriceValue(data.midPrice)) &&
102:       (data.directLowPrice === null || Number.isInteger(this.normalizePriceValue(data.directLowPrice)))
103:     );
104:   }
105: 
106:   private validatePrice(price: CardPrice): boolean {
107:     return this.validatePriceData(price.normal) || this.validatePriceData(price.foil);
108:   }
109: 
110:   private normalizePrice(price: CardPrice): CardPrice {
111:     const normalized: CardPrice = {
112:       productId: price.productId,
113:       lastUpdated: price.lastUpdated,
114:     };
115: 
116:     if (price.normal) {
117:       normalized.normal = {
118:         directLowPrice: this.normalizePriceValue(price.normal.directLowPrice),
119:         highPrice: this.normalizePriceValue(price.normal.highPrice) || 0,
120:         lowPrice: this.normalizePriceValue(price.normal.lowPrice) || 0,
121:         marketPrice: this.normalizePriceValue(price.normal.marketPrice) || 0,
122:         midPrice: this.normalizePriceValue(price.normal.midPrice) || 0,
123:         subTypeName: "Normal",
124:       };
125:     }
126: 
127:     if (price.foil) {
128:       normalized.foil = {
129:         directLowPrice: this.normalizePriceValue(price.foil.directLowPrice),
130:         highPrice: this.normalizePriceValue(price.foil.highPrice) || 0,
131:         lowPrice: this.normalizePriceValue(price.foil.lowPrice) || 0,
132:         marketPrice: this.normalizePriceValue(price.foil.marketPrice) || 0,
133:         midPrice: this.normalizePriceValue(price.foil.midPrice) || 0,
134:         subTypeName: "Foil",
135:       };
136:     }
137: 
138:     return normalized;
139:   }
140: 
141:   private async processPrices(
142:     prices: CardPrice[],
143:     groupId: string,
144:     options: { forceUpdate?: boolean } = {}
145:   ): Promise<{
146:     processed: number;
147:     updated: number;
148:     errors: string[];
149:   }> {
150:     const result = {
151:       processed: 0,
152:       updated: 0,
153:       errors: [] as string[],
154:     };
155: 
156:     try {
157:       const productIds = prices.map((price) => price.productId);
158:       const hashMap = await this.getStoredHashes(productIds);
159:       const today = new Date();
160:       today.setHours(0, 0, 0, 0);
161: 
162:       await Promise.all(prices.map(async (price) => {
163:         try {
164:           result.processed++;
165: 
166:           const normalizedPrice = this.normalizePrice(price);
167:           if (!this.validatePrice(normalizedPrice)) {
168:             return;
169:           }
170: 
171:           const currentHash = this.calculateHash(normalizedPrice);
172:           const storedHash = hashMap.get(price.productId);
173: 
174:           if (currentHash === storedHash && !options.forceUpdate) {
175:             return;
176:           }
177: 
178:           const priceDoc = {
179:             productId: normalizedPrice.productId,
180:             lastUpdated: FieldValue.serverTimestamp(),
181:             groupId: parseInt(groupId),
182:             ...(normalizedPrice.normal && { normal: normalizedPrice.normal }),
183:             ...(normalizedPrice.foil && { foil: normalizedPrice.foil }),
184:           };
185: 
186:           const historicalDoc = {
187:             productId: normalizedPrice.productId,
188:             groupId,
189:             date: today,
190:             timestamp: FieldValue.serverTimestamp(),
191:             ...(normalizedPrice.normal && {
192:               normal: {
193:                 directLow: normalizedPrice.normal.directLowPrice,
194:                 high: normalizedPrice.normal.highPrice,
195:                 low: normalizedPrice.normal.lowPrice,
196:                 market: normalizedPrice.normal.marketPrice,
197:                 mid: normalizedPrice.normal.midPrice,
198:               },
199:             }),
200:             ...(normalizedPrice.foil && {
201:               foil: {
202:                 directLow: normalizedPrice.foil.directLowPrice,
203:                 high: normalizedPrice.foil.highPrice,
204:                 low: normalizedPrice.foil.lowPrice,
205:                 market: normalizedPrice.foil.marketPrice,
206:                 mid: normalizedPrice.foil.midPrice,
207:               },
208:             }),
209:           };
210: 
211:           // Add main price document
212:           await this.batchProcessor.addOperation(batch => {
213:             const priceRef = db.collection(COLLECTION.PRICES).doc(price.productId.toString());
214:             batch.set(priceRef, priceDoc, { merge: true });
215:           });
216: 
217:           // Add hash document
218:           await this.batchProcessor.addOperation(batch => {
219:             const hashRef = db.collection(COLLECTION.PRICE_HASHES).doc(price.productId.toString());
220:             batch.set(hashRef, {
221:               hash: currentHash,
222:               lastUpdated: FieldValue.serverTimestamp(),
223:             }, { merge: true });
224:           });
225: 
226:           // Add historical price document
227:           await this.batchProcessor.addOperation(batch => {
228:             const docId = `${price.productId}_${today.toISOString().split("T")[0]}`;
229:             const historicalRef = db.collection(COLLECTION.HISTORICAL_PRICES).doc(docId);
230:             batch.set(historicalRef, historicalDoc, { merge: true });
231:           });
232: 
233:           this.cache.set(`price_hash_${price.productId}`, currentHash);
234:           result.updated++;
235: 
236:         } catch (error) {
237:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
238:           result.errors.push(`Error processing price for product ${price.productId}: ${errorMessage}`);
239:           logger.error(`Error processing price for product ${price.productId}`, { error: errorMessage });
240:         }
241:       }));
242: 
243:       await this.batchProcessor.commitAll();
244:     } catch (error) {
245:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
246:       result.errors.push(`Batch processing error: ${errorMessage}`);
247:       logger.error("Batch processing error", { error: errorMessage });
248:     }
249: 
250:     return result;
251:   }
252: 
253:   async syncPrices(options: SyncOptions = {}): Promise<SyncResult> {
254:     const result: SyncResult = {
255:       success: true,
256:       itemsProcessed: 0,
257:       itemsUpdated: 0,
258:       errors: [],
259:       timing: {
260:         startTime: new Date(),
261:       },
262:     };
263: 
264:     try {
265:       logger.info("Starting price sync", { options });
266: 
267:       const groups = options.groupId ?
268:         [{ groupId: options.groupId }] :
269:         await this.retry.execute(() => tcgcsvApi.getGroups());
270: 
271:       logger.info(`Found ${groups.length} groups to process`);
272: 
273:       for (const group of groups) {
274:         if (this.isApproachingTimeout(result.timing.startTime)) {
275:           logger.warn("Approaching function timeout, stopping processing");
276:           break;
277:         }
278: 
279:         result.timing.groupStartTime = new Date();
280: 
281:         try {
282:           const prices = await this.retry.execute(() =>
283:             tcgcsvApi.getGroupPrices(group.groupId)
284:           );
285: 
286:           logger.info(`Processing ${prices.length} prices for group ${group.groupId}`);
287: 
288:           for (let i = 0; i < prices.length; i += this.CHUNK_SIZE) {
289:             if (this.isApproachingTimeout(result.timing.startTime)) {
290:               logger.warn("Approaching function timeout, stopping chunk processing");
291:               break;
292:             }
293: 
294:             const priceChunk = prices.slice(i, i + this.CHUNK_SIZE);
295:             const batchResults = await this.processPrices(
296:               priceChunk,
297:               group.groupId,
298:               options
299:             );
300: 
301:             result.itemsProcessed += batchResults.processed;
302:             result.itemsUpdated += batchResults.updated;
303:             result.errors.push(...batchResults.errors);
304:           }
305: 
306:           logger.info(`Completed group ${group.groupId}`, {
307:             processed: result.itemsProcessed,
308:             updated: result.itemsUpdated,
309:             errors: result.errors.length,
310:           });
311: 
312:         } catch (error) {
313:           const errorMessage = error instanceof Error ? error.message : "Unknown error";
314:           result.errors.push(`Error processing prices for group ${
315:           group.groupId}: ${errorMessage}`);
316:           logger.error(`Error processing prices for group ${group.groupId}`, {
317:             error: errorMessage,
318:           });
319:         }
320:       }
321: 
322:       result.timing.endTime = new Date();
323:       result.timing.duration =
324:         (result.timing.endTime.getTime() - result.timing.startTime.getTime()) / 1000;
325: 
326:       logger.info(`Price sync completed in ${result.timing.duration}s`, {
327:         processed: result.itemsProcessed,
328:         updated: result.itemsUpdated,
329:         errors: result.errors.length,
330:         timing: result.timing,
331:       });
332: 
333:     } catch (error) {
334:       result.success = false;
335:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
336:       result.errors.push(`Price sync failed: ${errorMessage}`);
337:       logger.error("Price sync failed", { error: errorMessage });
338:     }
339: 
340:     return result;
341:   }
342: }
343: 
344: export const priceSync = new PriceSyncService();
</file>

<file path="src/services/storageService.ts">
  1: // src/services/storageService.ts
  2: import { S3Client, PutObjectCommand, HeadObjectCommand } from "@aws-sdk/client-s3";
  3: import axios from "axios";
  4: import { R2_CONFIG } from "../config/r2Config";
  5: import { logger } from "../utils/logger";
  6: 
  7: interface ImageResult {
  8:   fullResUrl: string;
  9:   highResUrl: string;
 10:   lowResUrl: string;
 11:   metadata: {
 12:     contentType: string;
 13:     productId: string;
 14:     groupId: string;
 15:     lastUpdated: string;
 16:     isPlaceholder?: boolean;
 17:     originalUrl?: string;
 18:     existingImage?: boolean;
 19:     errorMessage?: string;
 20:   };
 21: }
 22: 
 23: export class StorageService {
 24:   private client: S3Client;
 25:   private readonly bucket: string;
 26:   private readonly customDomain: string;
 27:   private readonly storagePath: string;
 28:   private readonly maxRetries = 3;
 29:   private readonly timeoutMs = 30000; // 30 seconds
 30:   private readonly PLACEHOLDER_URL = "https://fftcgcompanion.com/card-images/image-coming-soon.jpeg";
 31:   private readonly validImagePatterns = [
 32:     "_in_1000x1000.", // Highest priority
 33:     "_400w.", // Medium priority
 34:     "_200w.", // Lowest priority
 35:   ];
 36: 
 37:   constructor() {
 38:     // Debug logging
 39:     console.log("StorageService Configuration:", {
 40:       accountId: R2_CONFIG.ACCOUNT_ID,
 41:       accessKeyId: R2_CONFIG.ACCESS_KEY_ID ? "***" : "not set",
 42:       secretAccessKey: R2_CONFIG.SECRET_ACCESS_KEY ? "***" : "not set",
 43:       bucket: R2_CONFIG.BUCKET_NAME,
 44:       customDomain: R2_CONFIG.CUSTOM_DOMAIN,
 45:       storagePath: R2_CONFIG.STORAGE_PATH,
 46:     });
 47: 
 48:     if (!R2_CONFIG.BUCKET_NAME) {
 49:       throw new Error("R2 bucket name is not configured");
 50:     }
 51: 
 52:     this.client = new S3Client({
 53:       region: "auto",
 54:       endpoint: `https://${R2_CONFIG.ACCOUNT_ID}.r2.cloudflarestorage.com`,
 55:       credentials: {
 56:         accessKeyId: R2_CONFIG.ACCESS_KEY_ID,
 57:         secretAccessKey: R2_CONFIG.SECRET_ACCESS_KEY,
 58:       },
 59:       forcePathStyle: true,
 60:     });
 61: 
 62:     this.bucket = R2_CONFIG.BUCKET_NAME;
 63:     this.customDomain = R2_CONFIG.CUSTOM_DOMAIN;
 64:     this.storagePath = R2_CONFIG.STORAGE_PATH;
 65: 
 66:     // Verify client configuration
 67:     console.log("S3Client Configuration:", {
 68:       endpoint: `https://${R2_CONFIG.ACCOUNT_ID}.r2.cloudflarestorage.com`,
 69:       bucket: this.bucket,
 70:       customDomain: this.customDomain,
 71:       storagePath: this.storagePath,
 72:     });
 73:   }
 74: 
 75:   private isValidImageUrl(url: string | undefined): boolean {
 76:     if (!url) return false;
 77: 
 78:     // Check if it's TCGPlayer's missing image SVG
 79:     if (url.includes("image-missing.svg")) {
 80:       logger.info(`TCGPlayer missing image URL detected: ${url}, using our placeholder`);
 81:       return false;
 82:     }
 83: 
 84:     // If URL contains any of our valid patterns, it's a valid TCGPlayer image URL
 85:     const isValidPattern = this.validImagePatterns.some((pattern) => url.includes(pattern));
 86: 
 87:     // If URL doesn't match our patterns, consider it invalid
 88:     if (!isValidPattern) {
 89:       logger.info(`Invalid image URL pattern: ${url}, using placeholder`);
 90:       return false;
 91:     }
 92: 
 93:     return true;
 94:   }
 95: 
 96:   private async checkImageExists(path: string): Promise<boolean> {
 97:     try {
 98:       await this.client.send(
 99:         new HeadObjectCommand({
100:           Bucket: this.bucket,
101:           Key: path,
102:         })
103:       );
104:       return true;
105:     } catch (error) {
106:       // Check for specific S3 errors
107:       if (error instanceof Error) {
108:         // NoSuchKey or 404 means the image doesn't exist
109:         if (error.name === "NotFound" || error.name === "NoSuchKey") {
110:           return false;
111:         }
112: 
113:         // Log other errors but don't fail the whole process
114:         logger.info(`Image check error for ${path}: ${error.message}`);
115:       }
116:       return false;
117:     }
118:   }
119: 
120:   private async validateImage(buffer: Buffer): Promise<boolean> {
121:     if (buffer.length < 4) return false;
122: 
123:     const header = buffer.slice(0, 4);
124:     // JPEG magic number: FF D8 FF
125:     const isJPEG = header[0] === 0xff && header[1] === 0xd8 && header[2] === 0xff;
126:     // PNG magic number: 89 50 4E 47
127:     const isPNG = header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4e && header[3] === 0x47;
128: 
129:     return isJPEG || isPNG;
130:   }
131: 
132:   private async downloadImage(url: string, retries = this.maxRetries): Promise<Buffer> {
133:     let lastError: Error | null = null;
134: 
135:     for (let attempt = 0; attempt <= retries; attempt++) {
136:       try {
137:         const response = await axios.get(url, {
138:           responseType: "arraybuffer",
139:           timeout: this.timeoutMs,
140:           headers: {
141:             "User-Agent": "FFTCG-Sync-Service/1.0",
142:             "Accept": "image/jpeg,image/png,image/*",
143:           },
144:           maxContentLength: 10 * 1024 * 1024, // 10MB max
145:           validateStatus: (status) => status === 200, // Only accept 200 status
146:         });
147: 
148:         const buffer = Buffer.from(response.data);
149: 
150:         if (await this.validateImage(buffer)) {
151:           return buffer;
152:         } else {
153:           throw new Error("Invalid image format");
154:         }
155:       } catch (unknownError) {
156:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
157:         const axiosError = unknownError as { response?: { status?: number } };
158: 
159:         // If we get a 403, this means the image doesn't exist or access is denied
160:         // Don't retry and don't log as error since this is an expected case
161:         if (axiosError?.response?.status === 403) {
162:           logger.info(`Image not available (403) for URL: ${url}`);
163:           throw new Error("IMAGE_NOT_AVAILABLE");
164:         }
165: 
166:         lastError = error;
167: 
168:         if (attempt === retries) {
169:           logger.error(`Failed to download image after ${retries + 1} attempts`, {
170:             url,
171:             error: error.message,
172:             stack: error.stack,
173:             status: axiosError?.response?.status,
174:           });
175:           break;
176:         }
177: 
178:         // Only log retries for non-403 errors
179:         logger.info(`Retrying image download (attempt ${attempt + 1}/${retries})`, {
180:           url,
181:           status: axiosError?.response?.status,
182:         });
183: 
184:         await new Promise((resolve) => setTimeout(resolve, 2000 * Math.pow(2, attempt)));
185:       }
186:     }
187: 
188:     throw lastError || new Error("Download failed after retries");
189:   }
190: 
191:   private async uploadToR2WithRetry(
192:     buffer: Buffer,
193:     path: string,
194:     metadata: Record<string, string>,
195:     retries = this.maxRetries
196:   ): Promise<string> {
197:     let lastError: Error | null = null;
198: 
199:     const stringMetadata = Object.entries(metadata).reduce(
200:       (acc, [key, value]) => ({
201:         ...acc,
202:         [key]: String(value),
203:       }),
204:       {}
205:     );
206: 
207:     for (let attempt = 0; attempt <= retries; attempt++) {
208:       try {
209:         await this.client.send(
210:           new PutObjectCommand({
211:             Bucket: this.bucket,
212:             Key: path,
213:             Body: buffer,
214:             ContentType: "image/jpeg",
215:             Metadata: stringMetadata,
216:             ContentLength: buffer.length,
217:             CacheControl: "public, max-age=31536000", // Cache for 1 year
218:             ACL: "public-read",
219:           })
220:         );
221:         return `${this.customDomain}/${path}`;
222:       } catch (unknownError) {
223:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
224:         lastError = error;
225: 
226:         logger.error(`Upload attempt ${attempt + 1} failed`, {
227:           path,
228:           error: error.message,
229:           stack: error.stack,
230:         });
231: 
232:         if (attempt === retries) break;
233:         await new Promise((resolve) => setTimeout(resolve, 1000 * (attempt + 1)));
234:       }
235:     }
236: 
237:     throw lastError || new Error("Upload failed after retries");
238:   }
239: 
240:   private getImagePath(groupId: string, cardNumber: string, resolution: "1000x1000" | "400w" | "200w"): string {
241:     const suffix = resolution === "1000x1000" ? "_in_1000x1000" : `_${resolution}`;
242:     return `${this.storagePath}/${groupId}/${cardNumber}${suffix}.jpg`;
243:   }
244: 
245:   private getPlaceholderResult(
246:     baseMetadata: {
247:       contentType: string;
248:       productId: string;
249:       groupId: string;
250:       lastUpdated: string;
251:     },
252:     originalUrl?: string
253:   ): ImageResult {
254:     return {
255:       fullResUrl: this.PLACEHOLDER_URL,
256:       highResUrl: this.PLACEHOLDER_URL,
257:       lowResUrl: this.PLACEHOLDER_URL,
258:       metadata: {
259:         ...baseMetadata,
260:         isPlaceholder: true,
261:         originalUrl,
262:         errorMessage: originalUrl ? "Invalid image URL" : "Image URL missing",
263:       },
264:     };
265:   }
266: 
267:   public async processAndStoreImage(
268:     imageUrl: string | undefined,
269:     productId: number,
270:     groupId: string,
271:     cardNumber: string
272:   ): Promise<ImageResult> {
273:     const baseMetadata = {
274:       productId: productId.toString(),
275:       groupId,
276:       lastUpdated: new Date().toISOString(),
277:       contentType: "image/jpeg",
278:     };
279: 
280:     try {
281:       if (!this.isValidImageUrl(imageUrl)) {
282:         return this.getPlaceholderResult(baseMetadata, imageUrl);
283:       }
284: 
285:       // Check if images already exist in R2
286:       const fullResPath = this.getImagePath(groupId, cardNumber, "1000x1000");
287:       const highResPath = this.getImagePath(groupId, cardNumber, "400w");
288:       const lowResPath = this.getImagePath(groupId, cardNumber, "200w");
289: 
290:       const [fullResExists, highResExists, lowResExists] = await Promise.all([
291:         this.checkImageExists(fullResPath).catch(() => false),
292:         this.checkImageExists(highResPath).catch(() => false),
293:         this.checkImageExists(lowResPath).catch(() => false),
294:       ]);
295: 
296:       // If all images exist, return their URLs
297:       if (fullResExists && highResExists && lowResExists) {
298:         const existingFullResUrl = `${this.customDomain}/${fullResPath}`;
299:         const existingHighResUrl = `${this.customDomain}/${highResPath}`;
300:         const existingLowResUrl = `${this.customDomain}/${lowResPath}`;
301: 
302:         logger.info(`Using existing images for product ${productId}:`, {
303:           fullResUrl: existingFullResUrl,
304:           highResUrl: existingHighResUrl,
305:           lowResUrl: existingLowResUrl,
306:         });
307: 
308:         return {
309:           fullResUrl: existingFullResUrl,
310:           highResUrl: existingHighResUrl,
311:           lowResUrl: existingLowResUrl,
312:           metadata: {
313:             ...baseMetadata,
314:             originalUrl: imageUrl,
315:             existingImage: true,
316:           },
317:         };
318:       }
319: 
320:       try {
321:         const baseUrl = imageUrl || "";
322:         // Create URLs for different resolutions
323:         const fullResTcgUrl = baseUrl.replace(/_[^.]+\./, "_in_1000x1000.");
324:         const highResTcgUrl = baseUrl.replace(/_[^.]+\./, "_400w.");
325:         const lowResTcgUrl = baseUrl.replace(/_[^.]+\./, "_200w.");
326: 
327:         logger.info(`Attempting to download images for product ${productId}:`, {
328:           fullRes: fullResTcgUrl,
329:           highRes: highResTcgUrl,
330:           lowRes: lowResTcgUrl,
331:         });
332: 
333:         // Try to download each resolution
334:         const [fullResBuffer, highResBuffer, lowResBuffer] = await Promise.all([
335:           this.downloadImage(fullResTcgUrl).catch((error) => {
336:             logger.info(`Failed to download full resolution image: ${error.message}`);
337:             return null;
338:           }),
339:           this.downloadImage(highResTcgUrl).catch((error) => {
340:             logger.info(`Failed to download high resolution image: ${error.message}`);
341:             return null;
342:           }),
343:           this.downloadImage(lowResTcgUrl).catch((error) => {
344:             logger.info(`Failed to download low resolution image: ${error.message}`);
345:             return null;
346:           }),
347:         ]);
348: 
349:         // Log which resolutions were successfully downloaded
350:         logger.info(`Download results for product ${productId}:`, {
351:           fullResDownloaded: !!fullResBuffer,
352:           highResDownloaded: !!highResBuffer,
353:           lowResDownloaded: !!lowResBuffer,
354:         });
355: 
356:         // Prepare arrays for successful uploads
357:         const uploadPromises: Promise<string>[] = [];
358:         const uploadPaths: string[] = [];
359: 
360:         // Add available images to upload queue
361:         if (fullResBuffer) {
362:           uploadPromises.push(this.uploadToR2WithRetry(fullResBuffer, fullResPath, baseMetadata));
363:           uploadPaths.push(fullResPath);
364:         }
365:         if (highResBuffer) {
366:           uploadPromises.push(this.uploadToR2WithRetry(highResBuffer, highResPath, baseMetadata));
367:           uploadPaths.push(highResPath);
368:         }
369:         if (lowResBuffer) {
370:           uploadPromises.push(this.uploadToR2WithRetry(lowResBuffer, lowResPath, baseMetadata));
371:           uploadPaths.push(lowResPath);
372:         }
373: 
374:         const uploadedUrls = await Promise.all(uploadPromises);
375: 
376:         // Create a map of paths to URLs
377:         const urlMap = uploadPaths.reduce((map, path, index) => {
378:           map[path] = uploadedUrls[index];
379:           return map;
380:         }, {} as { [key: string]: string });
381: 
382:         // Determine which URLs to use, falling back to the highest available resolution
383:         const result: ImageResult = {
384:           fullResUrl: urlMap[fullResPath] || urlMap[highResPath] || urlMap[lowResPath] || this.PLACEHOLDER_URL,
385:           highResUrl: urlMap[highResPath] || urlMap[fullResPath] || urlMap[lowResPath] || this.PLACEHOLDER_URL,
386:           lowResUrl: urlMap[lowResPath] || urlMap[highResPath] || urlMap[fullResPath] || this.PLACEHOLDER_URL,
387:           metadata: {
388:             ...baseMetadata,
389:             originalUrl: imageUrl,
390:           },
391:         };
392: 
393:         // Log the final URLs being stored
394:         logger.info(`Final image URLs for product ${productId}:`, {
395:           fullResUrl: result.fullResUrl,
396:           highResUrl: result.highResUrl,
397:           lowResUrl: result.lowResUrl,
398:           isPlaceholder: result.fullResUrl === this.PLACEHOLDER_URL,
399:           originalUrl: imageUrl,
400:           fallbacksUsed: {
401:             fullRes: result.fullResUrl !== urlMap[fullResPath],
402:             highRes: result.highResUrl !== urlMap[highResPath],
403:             lowRes: result.lowResUrl !== urlMap[lowResPath],
404:           },
405:         });
406: 
407:         return result;
408:       } catch (unknownError) {
409:         const error = unknownError instanceof Error ? unknownError : new Error(String(unknownError));
410: 
411:         if (error.message !== "IMAGE_NOT_AVAILABLE") {
412:           logger.error(`Failed to process images for ${productId}`, {
413:             error: error.message,
414:             stack: error.stack,
415:           });
416:         }
417: 
418:         return this.getPlaceholderResult(baseMetadata, imageUrl);
419:       }
420:     } catch (error) {
421:       logger.error(`Failed to process images for ${productId}`, {
422:         error: error instanceof Error ? error.message : "Unknown error",
423:         imageUrl,
424:         groupId,
425:         cardNumber,
426:       });
427:       return this.getPlaceholderResult(baseMetadata, imageUrl);
428:     }
429:   }
430: }
431: 
432: export const storageService = new StorageService();
</file>

<file path="src/types/index.ts">
  1: import { FieldValue } from "firebase-admin/firestore";
  2: 
  3: export interface CardProduct {
  4:   productId: number;
  5:   name: string;
  6:   cleanName: string;
  7:   imageUrl?: string;
  8:   categoryId: number;
  9:   groupId: number;
 10:   url: string;
 11:   modifiedOn: string;
 12:   imageCount: number;
 13:   extendedData: Array<{
 14:     name: string;
 15:     displayName: string;
 16:     value: string | number;
 17:   }>;
 18: }
 19: 
 20: export interface CardPrice {
 21:   productId: number;
 22:   normal?: {
 23:     directLowPrice: number | null;
 24:     highPrice: number;
 25:     lowPrice: number;
 26:     marketPrice: number;
 27:     midPrice: number;
 28:     subTypeName: "Normal";
 29:   };
 30:   foil?: {
 31:     directLowPrice: number | null;
 32:     highPrice: number;
 33:     lowPrice: number;
 34:     marketPrice: number;
 35:     midPrice: number;
 36:     subTypeName: "Foil";
 37:   };
 38:   lastUpdated: Date;
 39: }
 40: 
 41: export interface HistoricalPrice {
 42:   productId: number;
 43:   date: Date;
 44:   normal?: {
 45:     directLow: number | null;
 46:     high: number;
 47:     low: number;
 48:     market: number;
 49:     mid: number;
 50:   };
 51:   foil?: {
 52:     directLow: number | null;
 53:     high: number;
 54:     low: number;
 55:     market: number;
 56:     mid: number;
 57:   };
 58:   groupId: string;
 59: }
 60: 
 61: export interface SyncTiming {
 62:   startTime: Date;
 63:   endTime?: Date;
 64:   duration?: number;
 65:   groupStartTime?: Date;
 66:   imageStartTime?: Date;
 67:   lastUpdateTime?: Date;
 68: }
 69: 
 70: export interface SyncResult {
 71:   success: boolean;
 72:   itemsProcessed: number;
 73:   itemsUpdated: number;
 74:   errors: string[];
 75:   timing: SyncTiming;
 76: }
 77: 
 78: export interface CardHashData {
 79:   name: string;
 80:   cleanName: string;
 81:   modifiedOn: string;
 82:   extendedData: Array<{
 83:     name: string;
 84:     displayName: string;
 85:     value: string | number | number | null | string[];
 86:   }>;
 87: }
 88: 
 89: export interface SyncOptions {
 90:   groupId?: string;
 91:   forceUpdate?: boolean;
 92:   skipImages?: boolean;
 93:   imagesOnly?: boolean;
 94:   silent?: boolean;
 95:   dryRun?: boolean;
 96: }
 97: 
 98: export interface CardChanges {
 99:   productId: number;
100:   name: string;
101:   cleanName: string;
102:   fullResUrl: string;
103:   highResUrl: string;
104:   lowResUrl: string;
105:   lastUpdated: FieldValue;
106:   groupId: number;
107:   isNonCard: boolean;
108:   cardNumbers: string[];
109:   primaryCardNumber: string;
110: }
111: 
112: export interface PriceChanges {
113:   productId: number;
114:   lastUpdated: FieldValue;
115:   groupId: number;
116:   normal?: {
117:     directLowPrice: number | null;
118:     highPrice: number;
119:     lowPrice: number;
120:     marketPrice: number;
121:     midPrice: number;
122:     subTypeName: "Normal";
123:   };
124:   foil?: {
125:     directLowPrice: number | null;
126:     highPrice: number;
127:     lowPrice: number;
128:     marketPrice: number;
129:     midPrice: number;
130:     subTypeName: "Foil";
131:   };
132: }
</file>

<file path="src/utils/api.ts">
  1: // src/utils/api.ts
  2: import axios, { AxiosError } from "axios";
  3: import { CardProduct, CardPrice } from "../types";
  4: import { logger } from "./logger";
  5: import { Cache } from "./cache";
  6: import { RateLimiter } from "./rateLimiter";
  7: import { RetryWithBackoff } from "./retry";
  8: 
  9: export class TcgcsvApi {
 10:   private readonly baseUrl = "https://tcgcsv.com/tcgplayer";
 11:   private readonly categoryId = "24"; // Final Fantasy TCG
 12:   private readonly requestQueue = new Map<string, Promise<unknown>>();
 13:   private readonly resultCache = new Cache<unknown>(5);
 14:   private readonly rateLimiter = new RateLimiter();
 15:   private readonly retry = new RetryWithBackoff();
 16: 
 17:   private async _makeRequest<T>(endpoint: string): Promise<T> {
 18:     const url = `${this.baseUrl}/${endpoint}`;
 19:     console.log(`Making API request to: ${url}`); // Added console.log
 20: 
 21:     return this.rateLimiter.add(async () => {
 22:       try {
 23:         console.log(`Sending request to ${url}`); // Added detailed logging
 24:         const response = await this.retry.execute(() =>
 25:           axios.get<T>(url, {
 26:             timeout: 30000,
 27:             headers: {
 28:               "Accept": "application/json",
 29:               "User-Agent": "FFTCG-Sync-Service/1.0",
 30:             },
 31:           })
 32:         );
 33:         console.log(`Response received from ${url}:`, {
 34:           status: response.status,
 35:           dataType: typeof response.data,
 36:           isArray: Array.isArray(response.data),
 37:           dataLength: Array.isArray(response.data) ? response.data.length : null,
 38:         });
 39:         return response.data;
 40:       } catch (error) {
 41:         // Enhanced error logging
 42:         if (error instanceof AxiosError) {
 43:           console.error("API Request Failed:", {
 44:             url,
 45:             status: error.response?.status,
 46:             statusText: error.response?.statusText,
 47:             data: error.response?.data,
 48:             message: error.message,
 49:           });
 50: 
 51:           if (error.response?.status === 403) {
 52:             throw new Error(`Access denied to TCGCSV API at path: ${endpoint}`);
 53:           }
 54:         } else {
 55:           console.error("Non-Axios error occurred:", error);
 56:         }
 57:         throw error;
 58:       }
 59:     });
 60:   }
 61: 
 62:   private async makeRequest<T>(endpoint: string): Promise<T> {
 63:     const cacheKey = `api_${endpoint}`;
 64:     const cached = this.resultCache.get(cacheKey);
 65:     if (cached) {
 66:       console.log(`Cache hit for ${endpoint}`);
 67:       return cached as T;
 68:     }
 69: 
 70:     const existing = this.requestQueue.get(endpoint);
 71:     if (existing) {
 72:       console.log(`Using existing request for ${endpoint}`);
 73:       return existing as Promise<T>;
 74:     }
 75: 
 76:     console.log(`Making new request for ${endpoint}`);
 77:     const promise = this._makeRequest<T>(endpoint);
 78:     this.requestQueue.set(endpoint, promise);
 79: 
 80:     try {
 81:       const result = await promise;
 82:       console.log(`Request successful for ${endpoint}`, {
 83:         resultType: typeof result,
 84:         isArray: Array.isArray(result),
 85:         resultLength: Array.isArray(result) ? result.length : null,
 86:       });
 87:       this.resultCache.set(cacheKey, result);
 88:       return result;
 89:     } finally {
 90:       this.requestQueue.delete(endpoint);
 91:     }
 92:   }
 93: 
 94:   async getGroups(): Promise<Array<{ groupId: string }>> {
 95:     console.log("Getting groups...");
 96:     try {
 97:       const response = await this.makeRequest<{ results: Array<{ groupId: string }> }>(
 98:         `${this.categoryId}/groups`
 99:       );
100:       console.log(`Retrieved ${response.results.length} groups`);
101:       return response.results;
102:     } catch (error) {
103:       console.error("Error getting groups:", error);
104:       throw error;
105:     }
106:   }
107: 
108:   async getGroupProducts(groupId: string): Promise<CardProduct[]> {
109:     console.log(`Getting products for group ${groupId}...`);
110:     try {
111:       const response = await this.makeRequest<{ results: CardProduct[] }>(
112:         `${this.categoryId}/${groupId}/products`
113:       );
114:       console.log(`Retrieved ${response.results.length} products for group ${groupId}`);
115:       return response.results;
116:     } catch (error) {
117:       console.error(`Error getting products for group ${groupId}:`, error);
118:       throw error;
119:     }
120:   }
121: 
122:   async getGroupPrices(groupId: string): Promise<CardPrice[]> {
123:     interface RawPriceData {
124:       productId: number;
125:       lowPrice: number | null;
126:       midPrice: number | null;
127:       highPrice: number | null;
128:       marketPrice: number | null;
129:       directLowPrice: number | null;
130:       subTypeName: string;
131:     }
132: 
133:     interface PriceResponse {
134:       success: boolean;
135:       errors: string[];
136:       results: RawPriceData[];
137:     }
138: 
139:     const response = await this.makeRequest<PriceResponse>(`${this.categoryId}/${groupId}/prices`);
140:     logger.info(`Retrieved ${response.results.length} prices for group ${groupId}`);
141: 
142:     const priceMap = new Map<number, CardPrice>();
143: 
144:     response.results.forEach((price) => {
145:       const existing = priceMap.get(price.productId) || {
146:         productId: price.productId,
147:         lastUpdated: new Date(),
148:       };
149: 
150:       if (price.subTypeName === "Normal") {
151:         existing.normal = {
152:           directLowPrice: price.directLowPrice,
153:           highPrice: price.highPrice || 0,
154:           lowPrice: price.lowPrice || 0,
155:           marketPrice: price.marketPrice || 0,
156:           midPrice: price.midPrice || 0,
157:           subTypeName: "Normal",
158:         };
159:       } else if (price.subTypeName === "Foil") {
160:         existing.foil = {
161:           directLowPrice: price.directLowPrice,
162:           highPrice: price.highPrice || 0,
163:           lowPrice: price.lowPrice || 0,
164:           marketPrice: price.marketPrice || 0,
165:           midPrice: price.midPrice || 0,
166:           subTypeName: "Foil",
167:         };
168:       }
169: 
170:       priceMap.set(price.productId, existing);
171:     });
172: 
173:     return Array.from(priceMap.values());
174:   }
175: }
176: 
177: export const tcgcsvApi = new TcgcsvApi();
</file>

<file path="src/utils/batch.ts">
 1: // src/utils/batch.ts
 2: import { logger } from "./logger";
 3: 
 4: export interface BatchProcessorOptions<T, R = void> {
 5:   batchSize?: number;
 6:   delayBetweenBatches?: number;
 7:   maxParallelBatches?: number;
 8:   onBatchComplete?: (stats: BatchProcessingStats) => Promise<void>;
 9:   processingFunction: (items: T[]) => Promise<R>;
10:   onBatchSuccess?: (result: R) => void;
11: }
12: 
13: export interface BatchProcessingStats {
14:   total: number;
15:   processed: number;
16:   successful: number;
17:   failed: number;
18:   skipped: number;
19: }
20: 
21: export class BatchProcessor<T, R = void> {
22:   private readonly defaultOptions = {
23:     batchSize: 100,
24:     delayBetweenBatches: 1000,
25:     maxParallelBatches: 3,
26:   };
27: 
28:   async processBatches(
29:     items: T[],
30:     options: BatchProcessorOptions<T, R>
31:   ): Promise<BatchProcessingStats> {
32:     const {
33:       batchSize = this.defaultOptions.batchSize,
34:       delayBetweenBatches = this.defaultOptions.delayBetweenBatches,
35:       maxParallelBatches = this.defaultOptions.maxParallelBatches,
36:       onBatchComplete,
37:       processingFunction,
38:       onBatchSuccess,
39:     } = options;
40: 
41:     const stats: BatchProcessingStats = {
42:       total: items.length,
43:       processed: 0,
44:       successful: 0,
45:       failed: 0,
46:       skipped: 0,
47:     };
48: 
49:     // Split items into batches
50:     const batches: T[][] = [];
51:     for (let i = 0; i < items.length; i += batchSize) {
52:       batches.push(items.slice(i, i + batchSize));
53:     }
54: 
55:     // Process batches with controlled parallelism
56:     for (let i = 0; i < batches.length; i += maxParallelBatches) {
57:       const currentBatches = batches.slice(i, i + maxParallelBatches);
58: 
59:       try {
60:         await Promise.all(
61:           currentBatches.map(async (batch) => {
62:             try {
63:               const result = await processingFunction(batch);
64:               if (onBatchSuccess) {
65:                 onBatchSuccess(result);
66:               }
67:               stats.successful += batch.length;
68:             } catch (error) {
69:               logger.error("Batch processing failed", { error });
70:               stats.failed += batch.length;
71:             }
72:             stats.processed += batch.length;
73: 
74:             if (onBatchComplete) {
75:               await onBatchComplete(stats);
76:             }
77:           })
78:         );
79: 
80:         // Add delay between batch groups
81:         if (i + maxParallelBatches < batches.length) {
82:           await new Promise((resolve) => setTimeout(resolve, delayBetweenBatches));
83:         }
84:       } catch (error) {
85:         logger.error("Failed to process batch group", { error });
86:       }
87:     }
88: 
89:     return stats;
90:   }
91: }
92: 
93: export const batchProcessor = new BatchProcessor();
</file>

<file path="src/utils/cache.ts">
  1: // src/utils/cache.ts
  2: import { logger } from "./logger";
  3: 
  4: export class Cache<T> {
  5:   private cache = new Map<
  6:     string,
  7:     {
  8:       data: T;
  9:       timestamp: number;
 10:       lastAccessed: number;
 11:     }
 12:   >();
 13:   private readonly ttl: number;
 14:   private readonly maxSize: number;
 15:   private readonly statistics = {
 16:     hits: 0,
 17:     misses: 0,
 18:     evictions: 0,
 19:   };
 20: 
 21:   constructor(ttlMinutes = 15, maxSize = 5000) {
 22:     this.ttl = ttlMinutes * 60 * 1000;
 23:     this.maxSize = maxSize;
 24:     this.startPeriodicCleanup();
 25:   }
 26: 
 27:   private startPeriodicCleanup(): void {
 28:     setInterval(() => {
 29:       this.evictExpired();
 30:       this.logStatistics();
 31:     }, Math.min(this.ttl / 2, 5 * 60 * 1000)); // Run every 5 minutes or half TTL, whichever is shorter
 32:   }
 33: 
 34:   private evictExpired(): void {
 35:     const now = Date.now();
 36:     let evicted = 0;
 37: 
 38:     for (const [key, value] of this.cache.entries()) {
 39:       if (now - value.timestamp > this.ttl) {
 40:         this.cache.delete(key);
 41:         evicted++;
 42:         this.statistics.evictions++;
 43:       }
 44:     }
 45: 
 46:     if (evicted > 0) {
 47:       logger.info(`Cache cleanup: evicted ${evicted} expired items`);
 48:     }
 49:   }
 50: 
 51:   private evictLRU(): void {
 52:     const entries = Array.from(this.cache.entries());
 53:     const toEvict = entries
 54:       .sort(([, a], [, b]) => a.lastAccessed - b.lastAccessed)
 55:       .slice(0, Math.floor(this.maxSize * 0.2)); // Evict 20% of oldest entries
 56: 
 57:     toEvict.forEach(([key]) => {
 58:       this.cache.delete(key);
 59:       this.statistics.evictions++;
 60:     });
 61: 
 62:     logger.info(`Cache LRU eviction: removed ${toEvict.length} items`);
 63:   }
 64: 
 65:   set(key: string, value: T): void {
 66:     if (this.cache.size >= this.maxSize) {
 67:       this.evictLRU();
 68:     }
 69: 
 70:     this.cache.set(key, {
 71:       data: value,
 72:       timestamp: Date.now(),
 73:       lastAccessed: Date.now(),
 74:     });
 75:   }
 76: 
 77:   setBulk(entries: Array<[string, T]>): void {
 78:     entries.forEach(([key, value]) => this.set(key, value));
 79:   }
 80: 
 81:   get(key: string): T | null {
 82:     const cached = this.cache.get(key);
 83:     if (!cached) {
 84:       this.statistics.misses++;
 85:       return null;
 86:     }
 87: 
 88:     if (Date.now() - cached.timestamp > this.ttl) {
 89:       this.cache.delete(key);
 90:       this.statistics.evictions++;
 91:       this.statistics.misses++;
 92:       return null;
 93:     }
 94: 
 95:     cached.lastAccessed = Date.now();
 96:     this.statistics.hits++;
 97:     return cached.data;
 98:   }
 99: 
100:   getBulk(keys: string[]): Map<string, T> {
101:     const results = new Map<string, T>();
102:     keys.forEach((key) => {
103:       const value = this.get(key);
104:       if (value !== null) {
105:         results.set(key, value);
106:       }
107:     });
108:     return results;
109:   }
110: 
111:   clear(): void {
112:     this.cache.clear();
113:     this.resetStatistics();
114:   }
115: 
116:   has(key: string): boolean {
117:     return this.get(key) !== null;
118:   }
119: 
120:   private resetStatistics(): void {
121:     this.statistics.hits = 0;
122:     this.statistics.misses = 0;
123:     this.statistics.evictions = 0;
124:   }
125: 
126:   private logStatistics(): void {
127:     const total = this.statistics.hits + this.statistics.misses;
128:     const hitRate = total > 0 ? (this.statistics.hits / total) * 100 : 0;
129: 
130:     logger.info("Cache statistics", {
131:       size: this.cache.size,
132:       hits: this.statistics.hits,
133:       misses: this.statistics.misses,
134:       evictions: this.statistics.evictions,
135:       hitRate: `${hitRate.toFixed(2)}%`,
136:     });
137:   }
138: 
139:   getStatistics() {
140:     return { ...this.statistics };
141:   }
142: }
</file>

<file path="src/utils/logger.ts">
 1: // src/utils/logger.ts
 2: import { db } from "../config/firebase";
 3: import { SyncResult } from "../types";
 4: import { environment } from "../config/environment";
 5: 
 6: export type LogData = Record<string, unknown>;
 7: 
 8: export interface SyncStats {
 9:   startTime: Date;
10:   endTime?: Date;
11:   totalItems: number;
12:   successCount: number;
13:   errorCount: number;
14:   duration?: number;
15: }
16: 
17: export class Logger {
18:   private readonly COLLECTION = "logs";
19: 
20:   async info(message: string, data?: LogData | SyncResult): Promise<void> {
21:     await this.log("INFO", message, data);
22:   }
23: 
24:   async error(message: string, data?: LogData | { error: unknown }): Promise<void> {
25:     await this.log("ERROR", message, data);
26:   }
27: 
28:   async logSyncStats(stats: SyncStats): Promise<void> {
29:     const duration = stats.endTime ? (stats.endTime.getTime() - stats.startTime.getTime()) / 1000 : undefined;
30: 
31:     const successRate = ((stats.successCount / stats.totalItems) * 100).toFixed(1);
32: 
33:     console.log({
34:       duration: duration ? `${duration}s` : "unknown",
35:       successRate: `${successRate}%`,
36:       totalItems: stats.totalItems,
37:       successful: stats.successCount,
38:       errors: stats.errorCount,
39:     });
40: 
41:     if (!environment.isLocal) {
42:       await db.collection(this.COLLECTION).add({
43:         type: "SYNC_STATS",
44:         timestamp: new Date(),
45:         stats: {
46:           ...stats,
47:           duration,
48:           successRate: parseFloat(successRate),
49:         },
50:       });
51:     }
52:   }
53: 
54:   async warn(message: string, data?: LogData | { error: unknown }): Promise<void> {
55:     await this.log("WARN", message, data);
56:   }
57: 
58:   async log(
59:     level: "INFO" | "ERROR" | "WARN",
60:     message: string,
61:     metadata?: LogData | SyncResult | { error: unknown }
62:   ): Promise<void> {
63:     const entry = {
64:       timestamp: new Date(),
65:       level,
66:       message,
67:       metadata: metadata || null,
68:       environment: environment.nodeEnv,
69:     };
70: 
71:     // Always log to console with appropriate level
72:     const logFn = level === "ERROR" ? console.error : level === "WARN" ? console.warn : console.log;
73:     logFn(`[${level}] ${message}`, metadata || "");
74: 
75:     // Only log to Firestore if not in local development
76:     if (!environment.isLocal) {
77:       try {
78:         await db.collection(this.COLLECTION).add(entry);
79:       } catch (error) {
80:         console.error("Failed to write log to Firestore:", error);
81:         // Don't throw the error to prevent disrupting the application
82:       }
83:     }
84:   }
85: }
86: 
87: export const logger = new Logger();
</file>

<file path="src/utils/rateLimiter.ts">
  1: // src/utils/rateLimiter.ts
  2: import { logger } from "./logger";
  3: 
  4: export class RateLimiter {
  5:   private queue: Array<() => Promise<unknown>> = [];
  6:   private processing = false;
  7:   private readonly maxRate: number;
  8:   private readonly interval: number;
  9:   private readonly maxConcurrent: number;
 10:   private currentConcurrent = 0;
 11: 
 12:   private readonly tokenBucket = {
 13:     tokens: 0,
 14:     lastRefill: Date.now(),
 15:   };
 16: 
 17:   private readonly statistics = {
 18:     totalProcessed: 0,
 19:     totalQueued: 0,
 20:     maxQueueLength: 0,
 21:     totalWaitTime: 0,
 22:   };
 23: 
 24:   constructor(maxRate = 500, intervalMs = 1000, maxConcurrent = 5) {
 25:     this.maxRate = maxRate;
 26:     this.interval = intervalMs;
 27:     this.maxConcurrent = maxConcurrent;
 28:     this.tokenBucket.tokens = maxRate;
 29: 
 30:     // Start periodic statistics logging
 31:     setInterval(() => this.logStatistics(), 5 * 60 * 1000); // Every 5 minutes
 32:   }
 33: 
 34:   private refillTokens(): number {
 35:     const now = Date.now();
 36:     const timePassed = now - this.tokenBucket.lastRefill;
 37:     const refillAmount = Math.floor((timePassed / this.interval) * this.maxRate);
 38: 
 39:     this.tokenBucket.tokens = Math.min(this.maxRate, this.tokenBucket.tokens + refillAmount);
 40:     this.tokenBucket.lastRefill = now;
 41: 
 42:     return this.tokenBucket.tokens;
 43:   }
 44: 
 45:   private async acquireToken(): Promise<void> {
 46:     while (this.tokenBucket.tokens <= 0) {
 47:       const sleepTime = Math.ceil(this.interval / this.maxRate);
 48:       await new Promise((resolve) => setTimeout(resolve, sleepTime));
 49:       this.refillTokens();
 50:     }
 51:     this.tokenBucket.tokens--;
 52:   }
 53: 
 54:   async add<T>(operation: () => Promise<T>): Promise<T> {
 55:     const queueStartTime = Date.now();
 56:     this.statistics.totalQueued++;
 57:     this.statistics.maxQueueLength = Math.max(this.statistics.maxQueueLength, this.queue.length + 1);
 58: 
 59:     return new Promise<T>((resolve, reject) => {
 60:       const wrappedOperation = async () => {
 61:         try {
 62:           await this.acquireToken();
 63:           const result = await operation();
 64: 
 65:           this.statistics.totalProcessed++;
 66:           this.statistics.totalWaitTime += Date.now() - queueStartTime;
 67: 
 68:           resolve(result);
 69:           return result;
 70:         } catch (error) {
 71:           reject(error);
 72:           throw error;
 73:         }
 74:       };
 75: 
 76:       this.queue.push(wrappedOperation);
 77: 
 78:       if (!this.processing) {
 79:         void this.process();
 80:       }
 81:     });
 82:   }
 83: 
 84:   private async process(): Promise<void> {
 85:     this.processing = true;
 86:     const batchSize = Math.floor(this.maxRate / (this.interval / 1000));
 87: 
 88:     while (this.queue.length > 0) {
 89:       if (this.currentConcurrent >= this.maxConcurrent) {
 90:         await new Promise((resolve) => setTimeout(resolve, 100));
 91:         continue;
 92:       }
 93: 
 94:       const batch = this.queue.splice(0, Math.min(batchSize, this.queue.length));
 95:       this.currentConcurrent++;
 96: 
 97:       try {
 98:         await Promise.all(
 99:           batch.map((op) =>
100:             op().finally(() => {
101:               this.currentConcurrent--;
102:             })
103:           )
104:         );
105:       } catch (error) {
106:         logger.error("Error processing rate-limited batch", { error });
107:       }
108: 
109:       if (this.queue.length > 0) {
110:         await new Promise((resolve) => setTimeout(resolve, this.interval));
111:       }
112:     }
113: 
114:     this.processing = false;
115:   }
116: 
117:   private logStatistics(): void {
118:     const avgWaitTime =
119:       this.statistics.totalProcessed > 0 ? this.statistics.totalWaitTime / this.statistics.totalProcessed : 0;
120: 
121:     logger.info("Rate limiter statistics", {
122:       totalProcessed: this.statistics.totalProcessed,
123:       totalQueued: this.statistics.totalQueued,
124:       maxQueueLength: this.statistics.maxQueueLength,
125:       averageWaitTime: `${(avgWaitTime / 1000).toFixed(2)}s`,
126:       currentQueueLength: this.queue.length,
127:       currentConcurrent: this.currentConcurrent,
128:       availableTokens: this.tokenBucket.tokens,
129:     });
130:   }
131: 
132:   getStatistics() {
133:     return { ...this.statistics };
134:   }
135: }
</file>

<file path="src/utils/retention.ts">
 1: import { db } from "../config/firebase";
 2: import { logger } from "./logger";
 3: 
 4: export class RetentionService {
 5:   private readonly RETENTION_CONFIG = {
 6:     logs: 7,
 7:     cardHashes: 7,
 8:     priceHashes: 7,
 9:     syncMetadata: 7,
10:   };
11: 
12:   async cleanOldData(): Promise<void> {
13:     try {
14:       logger.info("Starting data retention cleanup");
15: 
16:       for (const [collection, days] of Object.entries(this.RETENTION_CONFIG)) {
17:         const cutoff = new Date();
18:         cutoff.setDate(cutoff.getDate() - days);
19: 
20:         const snapshot = await db.collection(collection).where("lastUpdated", "<", cutoff).get();
21: 
22:         if (!snapshot.empty) {
23:           const batch = db.batch();
24:           snapshot.docs.forEach((doc) => batch.delete(doc.ref));
25:           await batch.commit();
26: 
27:           logger.info(`Cleaned up ${snapshot.size} documents from ${collection}`);
28:         }
29:       }
30: 
31:       logger.info("Data retention cleanup completed");
32:     } catch (error) {
33:       const errorMessage = error instanceof Error ? error.message : "Unknown error";
34:       logger.error("Data retention cleanup failed", { error: errorMessage });
35:       throw error;
36:     }
37:   }
38: }
39: 
40: export const retention = new RetentionService();
</file>

<file path="src/utils/retry.ts">
  1: // src/utils/retry.ts
  2: import { logger } from "./logger";
  3: 
  4: interface CircuitBreakerConfig {
  5:   failureThreshold: number;
  6:   resetTimeout: number;
  7: }
  8: 
  9: interface RetryConfig {
 10:   maxRetries: number;
 11:   initialDelay: number;
 12:   maxDelay: number;
 13:   backoffFactor: number;
 14: }
 15: 
 16: export class RetryWithBackoff {
 17:   private readonly config: RetryConfig;
 18:   private readonly circuitBreaker: CircuitBreakerConfig;
 19:   private readonly retryableStatusCodes = new Set([408, 429, 500, 502, 503, 504]);
 20: 
 21:   private circuitState = {
 22:     failures: 0,
 23:     lastFailure: 0,
 24:     isOpen: false,
 25:   };
 26: 
 27:   private statistics = {
 28:     totalAttempts: 0,
 29:     totalRetries: 0,
 30:     totalFailures: 0,
 31:     totalSuccesses: 0,
 32:     circuitBreaksCount: 0,
 33:   };
 34: 
 35:   constructor(retryConfig?: Partial<RetryConfig>, circuitBreakerConfig?: Partial<CircuitBreakerConfig>) {
 36:     this.config = {
 37:       maxRetries: retryConfig?.maxRetries ?? 3,
 38:       initialDelay: retryConfig?.initialDelay ?? 1000,
 39:       maxDelay: retryConfig?.maxDelay ?? 10000,
 40:       backoffFactor: retryConfig?.backoffFactor ?? 2,
 41:     };
 42: 
 43:     this.circuitBreaker = {
 44:       failureThreshold: circuitBreakerConfig?.failureThreshold ?? 5,
 45:       resetTimeout: circuitBreakerConfig?.resetTimeout ?? 60000,
 46:     };
 47: 
 48:     // Start periodic statistics logging
 49:     setInterval(() => this.logStatistics(), 5 * 60 * 1000); // Every 5 minutes
 50:   }
 51: 
 52:   private checkCircuitBreaker(): boolean {
 53:     if (!this.circuitState.isOpen) {
 54:       return true;
 55:     }
 56: 
 57:     const timeSinceLastFailure = Date.now() - this.circuitState.lastFailure;
 58:     if (timeSinceLastFailure >= this.circuitBreaker.resetTimeout) {
 59:       this.circuitState.isOpen = false;
 60:       this.circuitState.failures = 0;
 61:       return true;
 62:     }
 63: 
 64:     return false;
 65:   }
 66: 
 67:   private updateCircuitBreaker(failed: boolean): void {
 68:     if (failed) {
 69:       this.circuitState.failures++;
 70:       this.circuitState.lastFailure = Date.now();
 71: 
 72:       if (this.circuitState.failures >= this.circuitBreaker.failureThreshold) {
 73:         this.circuitState.isOpen = true;
 74:         this.statistics.circuitBreaksCount++;
 75:         logger.warn("Circuit breaker opened", {
 76:           failures: this.circuitState.failures,
 77:           resetTimeout: this.circuitBreaker.resetTimeout,
 78:         });
 79:       }
 80:     } else {
 81:       this.circuitState.failures = 0;
 82:     }
 83:   }
 84: 
 85:   private isRetryableError(error: Error): boolean {
 86:     // Check if it's an HTTP error with status code
 87:     const httpError = error as { response?: { status?: number } };
 88:     const statusCode = httpError.response?.status;
 89:     if (statusCode && this.retryableStatusCodes.has(statusCode)) {
 90:       return true;
 91:     }
 92: 
 93:     // Check for network-related errors
 94:     const errorMessage = error.message.toLowerCase();
 95:     return (
 96:       errorMessage.includes("timeout") ||
 97:       errorMessage.includes("network") ||
 98:       errorMessage.includes("connection") ||
 99:       errorMessage.includes("econnrefused") ||
100:       errorMessage.includes("econnreset")
101:     );
102:   }
103: 
104:   async execute<T>(operation: () => Promise<T>): Promise<T> {
105:     if (!this.checkCircuitBreaker()) {
106:       throw new Error("Circuit breaker is open");
107:     }
108: 
109:     let lastError: Error | null = null;
110:     let delay = this.config.initialDelay;
111: 
112:     for (let attempt = 0; attempt <= this.config.maxRetries; attempt++) {
113:       this.statistics.totalAttempts++;
114: 
115:       try {
116:         const result = await operation();
117:         this.updateCircuitBreaker(false);
118:         this.statistics.totalSuccesses++;
119:         return result;
120:       } catch (error) {
121:         lastError = error instanceof Error ? error : new Error(String(error));
122:         this.statistics.totalFailures++;
123: 
124:         if (attempt === this.config.maxRetries) {
125:           this.updateCircuitBreaker(true);
126:           break;
127:         }
128: 
129:         if (!this.isRetryableError(lastError)) {
130:           throw lastError;
131:         }
132: 
133:         this.statistics.totalRetries++;
134:         logger.info(`Retry attempt ${attempt + 1} of ${this.config.maxRetries}`, {
135:           error: lastError.message,
136:           delay,
137:         });
138: 
139:         await new Promise((resolve) => setTimeout(resolve, delay));
140:         delay = Math.min(delay * this.config.backoffFactor, this.config.maxDelay);
141:       }
142:     }
143: 
144:     throw lastError || new Error("Operation failed after retries");
145:   }
146: 
147:   private logStatistics(): void {
148:     const totalOperations = this.statistics.totalSuccesses + this.statistics.totalFailures;
149:     const successRate = totalOperations > 0 ? (this.statistics.totalSuccesses / totalOperations) * 100 : 0;
150: 
151:     logger.info("Retry statistics", {
152:       totalAttempts: this.statistics.totalAttempts,
153:       totalRetries: this.statistics.totalRetries,
154:       totalSuccesses: this.statistics.totalSuccesses,
155:       totalFailures: this.statistics.totalFailures,
156:       circuitBreaks: this.statistics.circuitBreaksCount,
157:       successRate: `${successRate.toFixed(2)}%`,
158:       circuitBreakerStatus: this.circuitState.isOpen ? "OPEN" : "CLOSED",
159:       currentFailures: this.circuitState.failures,
160:     });
161:   }
162: 
163:   getStatistics() {
164:     return { ...this.statistics };
165:   }
166: 
167:   resetStatistics(): void {
168:     this.statistics = {
169:       totalAttempts: 0,
170:       totalRetries: 0,
171:       totalFailures: 0,
172:       totalSuccesses: 0,
173:       circuitBreaksCount: 0,
174:     };
175:   }
176: }
</file>

<file path="src/utils/tasks.ts">
 1: // src/utils/tasks.ts
 2: import { CloudTasksClient } from "@google-cloud/tasks";
 3: 
 4: let tasksClient: CloudTasksClient | null = null;
 5: 
 6: export async function getTasksClient(): Promise<CloudTasksClient> {
 7:   if (!tasksClient) {
 8:     tasksClient = new CloudTasksClient();
 9:   }
10:   return tasksClient;
11: }
</file>

<file path="src/utils/timeout.ts">
 1: // src/utils/timeout.ts
 2: export class TimeoutError extends Error {
 3:   constructor(message: string) {
 4:     super(message);
 5:     this.name = "TimeoutError";
 6:   }
 7: }
 8: 
 9: export function withTimeout<T>(promise: Promise<T>, timeoutMs: number): Promise<T> {
10:   return Promise.race([
11:     promise,
12:     new Promise<T>((_, reject) => {
13:       setTimeout(() => {
14:         reject(new TimeoutError(`Operation timed out after ${timeoutMs}ms`));
15:       }, timeoutMs);
16:     }),
17:   ]);
18: }
</file>

<file path="tsconfig.dev.json">
1: {
2:   "include": [
3:     ".eslintrc.js"
4:   ]
5: }
</file>

<file path="tsconfig.json">
 1: {
 2:   "compilerOptions": {
 3:     "module": "commonjs",
 4:     "moduleResolution": "node",
 5:     "noImplicitReturns": true,
 6:     "noUnusedLocals": true,
 7:     "outDir": "lib",
 8:     "sourceMap": true,
 9:     "strict": true,
10:     "target": "es2017",
11:     "skipLibCheck": true, // Add this line
12:     "esModuleInterop": true, // Make sure this is present
13:     "resolveJsonModule": true, // Add this line
14:     "baseUrl": "./src", // Add this line
15:     "paths": {
16:       // Add this section
17:       "*": ["*"]
18:     }
19:   },
20:   "compileOnSave": true,
21:   "include": ["src"],
22:   "exclude": ["node_modules", "lib"]
23: }
</file>

</repository_files>
